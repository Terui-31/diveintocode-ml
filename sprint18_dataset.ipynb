{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trying-eleven",
   "metadata": {},
   "source": [
    "### イメージを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import os\n",
    "import glob \n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sprint18_image\n",
    "\n",
    "path = './sprint18_image/training/' \n",
    "flist = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -a .//sprint18_image/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不可視ファイルの.DS_Storeファイルを除いて読み込む\n",
    "\n",
    "'''\n",
    "余談\n",
    "\n",
    ".DS_Storeファイルとは？ 開けるの？\n",
    "\n",
    "https://miloserdov.org/?p=3867\n",
    "\n",
    "'''\n",
    "\n",
    "flist_ignore = [name for name in os.listdir(path) if not name.startswith('.')]\n",
    "flist_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = glob.glob(path + '/*' + \".jpg\")\n",
    "img_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-prerequisite",
   "metadata": {},
   "source": [
    "### イメージのロード、配列化、リサイズ、データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.resizeはだめ、ぜったい\n",
    "\n",
    "dog_img_array = np.empty((0,224,224,3))\n",
    "cat_img_array = np.empty((0,224,224,3))\n",
    "\n",
    "for img in img_list:\n",
    "    \n",
    "    # ファイル名に'dog'が含まれるイメージ\n",
    "    if re.search('dog', img):\n",
    "        \n",
    "        dog_img_ = Image.open(img)\n",
    "        \n",
    "        # サイズを揃える\n",
    "        dog_img_ = dog_img_.resize((224, 224))\n",
    "        \n",
    "        # PIL.Image.Imageからnumpy配列へ\n",
    "        dog_img = np.array(dog_img_)\n",
    "        \n",
    "        # 正規化\n",
    "        dog_img = dog_img / 255.\n",
    "        \n",
    "        # axisの追加\n",
    "        dog_img = dog_img.reshape((1,224,224,3))\n",
    "        \n",
    "        dog_img_array = np.concatenate([dog_img_array, dog_img], axis = 0)\n",
    "        \n",
    "        dog_img_.close()\n",
    "    \n",
    "    # ファイル名に'cat'が含まれるイメージ\n",
    "    if re.search('cat', img):\n",
    "        \n",
    "        cat_img_ = Image.open(img)\n",
    "        \n",
    "        cat_img_ = cat_img_.resize((224, 224))\n",
    "        \n",
    "        cat_img = np.array(cat_img_)\n",
    "        \n",
    "        cat_img = cat_img / 255.\n",
    "        \n",
    "        cat_img = cat_img.reshape((1,224,224,3))\n",
    "        \n",
    "        cat_img_array = np.concatenate([cat_img_array, cat_img], axis = 0)\n",
    "        \n",
    "        cat_img_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dog_image:{}  cat_image:{}'.format(dog_img_array.shape, cat_img_array.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-companion",
   "metadata": {},
   "source": [
    "### イメージの出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配列のまま出力\n",
    "\n",
    "print('データ型:', cat_img_array[3].dtype)\n",
    "\n",
    "cat_img_array[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配列を画像として出力\n",
    "\n",
    "#plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "\n",
    "#plt.imshow(cat_img_array[1])\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'''\n",
    "\n",
    "#画像の中心を切り出し\n",
    "\n",
    "#https://note.nkmk.me/python-pillow-image-crop-trimming/\n",
    "\n",
    "#'''\n",
    "\n",
    "\n",
    "#def crop_center(pil_img, crop_width, crop_height):\n",
    "    \n",
    "#   img_width, img_height = pil_img.size\n",
    "    \n",
    "#    return pil_img.crop(((img_width - crop_width) // 2,\n",
    "#                         (img_height - crop_height) // 2,\n",
    "#                         (img_width + crop_width) // 2,\n",
    "#                         (img_height + crop_height) // 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = Image.open(img_list[1])\n",
    "\n",
    "#img_new = crop_center(img, 224, 224)\n",
    "\n",
    "#print(type(img_new))\n",
    "\n",
    "#plt.imshow(img_new)\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "#img.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-skating",
   "metadata": {},
   "source": [
    "## 【問題1】自作データセットでの分類の学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-rates",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(cat_img_array[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結合してX_trainに\n",
    "\n",
    "X_train = np.concatenate((cat_img_array, dog_img_array), axis=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベル作成 0=cat, 1=dog\n",
    "\n",
    "y_train = np.array((0,0,0,0,0,1,1,1,1,1))\n",
    "#y_train = y_train.reshape(-1, 1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "#y_train = enc.fit_transform(y_train)\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = tf.keras.applications.vgg16.VGG16(\n",
    "                                                                        weights='imagenet', \n",
    "                                                                        include_top=False, \n",
    "                                                                        input_shape=(224, 224, 3)\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tf.keras import models\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(conv_base)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                             batch_size=1,\n",
    "                             epochs=10,\n",
    "                             verbose=1,  # ０=非表示、2=エポックごとの表示\n",
    "                             validation_data=(X_val, y_val)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-privilege",
   "metadata": {},
   "source": [
    "## 【問題2】分類データセットに対するデータ拡張"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    " transform = A.Compose([\n",
    "        RandomRotate90(),\n",
    "        Flip(),\n",
    "        Transpose(),\n",
    "        OneOf([\n",
    "            IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=0.5),\n",
    "        OneOf([\n",
    "            MotionBlur(p=0.2),\n",
    "            MedianBlur(blur_limit=3, p=0.1),\n",
    "            Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.5),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=0.1),\n",
    "            IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.5),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=2),\n",
    "            IAASharpen(),\n",
    "            IAAEmboss(),\n",
    "            RandomBrightnessContrast(),\n",
    "        ], p=0.),\n",
    "        HueSaturationValue(p=0.3),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ拡張\n",
    "\n",
    "image = cv2.imread('./sprint18_image/training/cat.01.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#visualize(image)\n",
    "\n",
    "image.shape\n",
    "augmented_image = transform(image=image)['image']\n",
    "#visualize(augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 猫画像を水増しする\n",
    "\n",
    "#aug_num = 10\n",
    "\n",
    "#for j in range(5):\n",
    "    \n",
    "#    image = cv2.imread('./sprint18_image/training/cat.0{}.jpg'.format(j+1))\n",
    "\n",
    "#    for i in range(aug_num):\n",
    "        \n",
    "#        augmented_image = transform(image=image)['image']\n",
    "        # 可視化する場合\n",
    "        #show_image = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "        #visualize(show_image)\n",
    "\n",
    "#        cv2.imwrite(\"./sprint18_image/aug_train/cat.{}{}.jpg\".format(j, i), augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-leisure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 犬画像を水増しする\n",
    "\n",
    "#aug_num = 10\n",
    "\n",
    "#for j in range(5):\n",
    "    \n",
    "#    image = cv2.imread('./sprint18_image/training/dog.0{}.jpg'.format(j+1))\n",
    "\n",
    "#    for i in range(aug_num):\n",
    "        \n",
    "#        augmented_image = transform(image=image)['image']\n",
    "        #show_image = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "        #visualize(show_image)\n",
    "\n",
    "#        cv2.imwrite(\"./sprint18_image/aug_train/dog.{}{}.jpg\".format(j, i), augmented_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-oliver",
   "metadata": {},
   "source": [
    "## 【問題3】物体検出データセットの用意"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-newcastle",
   "metadata": {},
   "source": [
    "### Define functions to visualize bounding boxes and class labels on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_COLOR = (255, 0, 0) # Red\n",
    "TEXT_COLOR = (255, 255, 255) # White\n",
    "\n",
    "\n",
    "def visualize_bbox(img, bbox, class_name, color=BOX_COLOR, thickness=2):\n",
    "    \n",
    "    \"\"\"Visualizes a single bounding box on the image\"\"\"\n",
    "    #x_min, y_min, w, h = bbox\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)\n",
    "    #x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
    "    \n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n",
    "    \n",
    "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
    "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
    "    \n",
    "    cv2.putText(\n",
    "                            img,\n",
    "                            text=class_name,\n",
    "                            org=(x_min, y_min - int(0.3 * text_height)),\n",
    "                            fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            fontScale=0.35, \n",
    "                            color=TEXT_COLOR, \n",
    "                            lineType=cv2.LINE_AA,\n",
    "                            )\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def visualize(image, bboxes, category_ids, category_id_to_name):\n",
    "    \n",
    "    img = image.copy()\n",
    "    \n",
    "    for bbox, category_id in zip(bboxes, category_ids):\n",
    "        class_name = category_id_to_name[category_id]\n",
    "        img = visualize_bbox(img, bbox, class_name)\n",
    "        \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-yesterday",
   "metadata": {},
   "source": [
    "### Get an image and annotations for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image from the disk\n",
    "\n",
    "image = cv2.imread('./sprint18_image/training/cat.01.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-proportion",
   "metadata": {},
   "source": [
    "### xmlデータ構造をパース（分析）して座標情報を獲得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "# #読み込み例\n",
    "# tree = ET.parse(path + 'cat.41box.xml')\n",
    "# #一番上の階層\n",
    "# root = tree.getroot()\n",
    "\n",
    "COORDINATE = 4\n",
    "\n",
    "path = './sprint18_image/training_bbox_voc/'\n",
    "boxbox = []\n",
    "point = COORDINATE\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    \n",
    "    boundbox = []    \n",
    "    if not filename.endswith('.xml'): \n",
    "        continue\n",
    "        \n",
    "    fullname = os.path.join(path, filename)\n",
    "    tree = ET.parse(fullname)\n",
    "    \n",
    "    bndbox = tree.findall('object/bndbox')\n",
    "    \n",
    "    for i in range(point):\n",
    "        # 座標取得\n",
    "        boundbox.append(bndbox[0][i].text)\n",
    "    boxbox.append(boundbox)\n",
    "    \n",
    "boxbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two bounding boxes with coordinates and class labels\n",
    "\n",
    "bboxes = [[160, 13, 360, 360]]\n",
    "category_ids = [0]\n",
    "\n",
    "# We will use the mapping from category_id to the class name\n",
    "# to visualize the class label for the bounding box on the image\n",
    "category_id_to_name = {0: 'cat', 1: 'dog'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuaize the original image with bounding boxes\n",
    "\n",
    "#visualize(image, bboxes, category_ids, category_id_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-croatia",
   "metadata": {},
   "source": [
    "## Sprint18 [問題4] 物体検出用データ拡張"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [A.HorizontalFlip(p=0.5)],\n",
    "    bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.seed(7)\n",
    "#transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "#img = visualize(\n",
    "#    transformed['image'],\n",
    "#    transformed['bboxes'],\n",
    "#    transformed['category_ids'],\n",
    "#    category_id_to_name,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "                                     [A.HorizontalFlip(p=0.5),\n",
    "                                     RandomRotate90(),\n",
    "                                     Transpose(),\n",
    "                                      \n",
    "                                     OneOf([\n",
    "                                                 IAAAdditiveGaussianNoise(),\n",
    "                                                 GaussNoise(),\n",
    "                                                 ], p=0.5),\n",
    "                                      \n",
    "                                    OneOf([\n",
    "                                                MotionBlur(p=0.2),\n",
    "                                                MedianBlur(blur_limit=3, p=0.1),\n",
    "                                                Blur(blur_limit=3, p=0.1),\n",
    "                                                ], p=0.5),\n",
    "                                      \n",
    "                                    OneOf([\n",
    "                                                #OpticalDistortion(p=0.3),\n",
    "                                                #GridDistortion(p=0.1),\n",
    "                                                IAAPiecewiseAffine(p=0.3),\n",
    "                                                ], p=0.5),\n",
    "                                    \n",
    "                                    OneOf([\n",
    "                                                CLAHE(clip_limit=2),\n",
    "                                                IAASharpen(),\n",
    "                                                IAAEmboss(),\n",
    "                                                RandomBrightnessContrast(),\n",
    "                                                ], p=0.),\n",
    "                                    \n",
    "                                    HueSaturationValue(p=0.3), \n",
    "                                    ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "                                    ],\n",
    "                                    bbox_params=A.BboxParams(format='pascal_voc', label_fields=['category_ids']),\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データサイズが巨大になるため、以下の処理はコメントアウト\n",
    "\n",
    "# bboxつき猫画像を水増しする\n",
    "# cat01\n",
    "\n",
    "#random.seed()\n",
    "#aug_num = 10\n",
    "#category_id_to_name = {0: 'cat', 1: 'dog'}\n",
    "\n",
    "#bboxes = [[160, 13, 360, 360]]\n",
    "#category_ids = [0] #cat\n",
    "\n",
    "#image = cv2.imread('./sprint18_image/training/cat.01.jpg')\n",
    "\n",
    "#for i in range(aug_num):\n",
    "        \n",
    "#    transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "#    img = visualize(\n",
    "#                             transformed['image'],\n",
    "#                             transformed['bboxes'],\n",
    "#                             transformed['category_ids'],\n",
    "#                             category_id_to_name,\n",
    "#                             )\n",
    "\n",
    "#    cv2.imwrite(\"./sprint18_image/aug_train_bbox/cat.{0:02d}.jpg\".format(i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データサイズが巨大になるため、以下の処理はコメントアウト\n",
    "\n",
    "# cat02\n",
    "\n",
    "#bboxes = [[177, 192, 815, 971]]\n",
    "#category_ids = [0] #cat\n",
    "#\n",
    "#image = cv2.imread('./sprint18_image/training/cat.02.jpg')\n",
    "#\n",
    "#for i in range(aug_num):\n",
    "#        \n",
    "#    transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "#    img = visualize(\n",
    "#                             transformed['image'],\n",
    "#                             transformed['bboxes'],\n",
    "#                             transformed['category_ids'],\n",
    "#                             category_id_to_name,\n",
    "#                             )\n",
    "#    \n",
    "#    cv2.imwrite(\"./sprint18_image/aug_train_bbox/cat.1{}.jpg\".format(i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-williams",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat03\n",
    "\n",
    "#bboxes = [[322, 7, 693, 490]]\n",
    "#category_ids = [0] #cat\n",
    "\n",
    "#image = cv2.imread('./sprint18_image/training/cat.03.jpg')\n",
    "\n",
    "#for i in range(aug_num):\n",
    "        \n",
    "#    transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "#   img = visualize(\n",
    "#                             transformed['image'],\n",
    "#                             transformed['bboxes'],\n",
    "#                             transformed['category_ids'],\n",
    "#                             category_id_to_name,\n",
    "#                             )\n",
    "\n",
    "#    cv2.imwrite(\"./sprint18_image/aug_train_bbox/cat.2{}.jpg\".format(i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat04\n",
    "\n",
    "#bboxes =  [[380, 237, 2396, 1702]]\n",
    "#category_ids = [0] #cat\n",
    "\n",
    "#image = cv2.imread('./sprint18_image/training/cat.04.jpg')\n",
    "\n",
    "#for i in range(aug_num):\n",
    "        \n",
    "#    transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "#    img = visualize(\n",
    "#                             transformed['image'],\n",
    "#                             transformed['bboxes'],\n",
    "#                             transformed['category_ids'],\n",
    "#                             category_id_to_name,\n",
    "#                             )\n",
    "\n",
    "#    cv2.imwrite(\"./sprint18_image/aug_train_bbox/cat.3{}.jpg\".format(i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat05\n",
    "\n",
    "#bboxes =  [[227, 64, 690, 533]]\n",
    "#category_ids = [0] #cat\n",
    "\n",
    "#image = cv2.imread('./sprint18_image/training/cat.05.jpg')\n",
    "\n",
    "#for i in range(aug_num):\n",
    "        \n",
    "#    transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "#    img = visualize(\n",
    "#                             transformed['image'],\n",
    "#                             transformed['bboxes'],\n",
    "#                             transformed['category_ids'],\n",
    "#                             category_id_to_name,\n",
    "#                             )\n",
    "\n",
    "#    cv2.imwrite(\"./sprint18_image/aug_train_bbox/cat.4{}.jpg\".format(i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog01\n",
    "\n",
    "#bboxes = [[128, 66, 427, 312]]\n",
    "#category_ids = [1] #dog\n",
    "\n",
    "#image = cv2.imread('./sprint18_image/training/dog.01.jpg')\n",
    "\n",
    "#for i in range(aug_num):\n",
    "        \n",
    "#    transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "#    img = visualize(\n",
    "#                             transformed['image'],\n",
    "#                             transformed['bboxes'],\n",
    "#                             transformed['category_ids'],\n",
    "#                             category_id_to_name,\n",
    "#                             )\n",
    "\n",
    "#    cv2.imwrite(\"./sprint18_image/aug_train_bbox/dog.{0:02d}.jpg\".format(i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-honolulu",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog02\n",
    "\n",
    "#bboxes = [[115, 24, 1202, 974]]\n",
    "#category_ids = [1] #dog\n",
    "\n",
    "#image = cv2.imread('./sprint18_image/training/dog.02.jpg')\n",
    "\n",
    "#for i in range(aug_num):\n",
    "        \n",
    "#    transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "#    img = visualize(\n",
    "#                             transformed['image'],\n",
    "#                             transformed['bboxes'],\n",
    "#                             transformed['category_ids'],\n",
    "#                             category_id_to_name,\n",
    "#                             )\n",
    "\n",
    "#    cv2.imwrite(\"./sprint18_image/aug_train_bbox/dog.1{}.jpg\".format(i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog03\n",
    "\n",
    "#bboxes = [[182, 72, 715, 509]]\n",
    "#category_ids = [1] #dog\n",
    "\n",
    "#image = cv2.imread('./sprint18_image/training/dog.03.jpg')\n",
    "\n",
    "#for i in range(aug_num):\n",
    "        \n",
    "#    transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "#    img = visualize(\n",
    "#                             transformed['image'],\n",
    "#                             transformed['bboxes'],\n",
    "#                             transformed['category_ids'],\n",
    "#                             category_id_to_name,\n",
    "#                             )\n",
    "\n",
    "#    cv2.imwrite(\"./sprint18_image/aug_train_bbox/dog.2{}.jpg\".format(i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog04\n",
    "\n",
    "#bboxes = [[458, 61, 862, 759]]\n",
    "#category_ids = [1] #dog\n",
    "\n",
    "#image = cv2.imread('./sprint18_image/training/dog.04.jpg')\n",
    "\n",
    "#for i in range(aug_num):\n",
    "        \n",
    "#    transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "#    img = visualize(\n",
    "#                             transformed['image'],\n",
    "#                             transformed['bboxes'],\n",
    "#                             transformed['category_ids'],\n",
    "#                             category_id_to_name,\n",
    "#                             )\n",
    "\n",
    "#    cv2.imwrite(\"./sprint18_image/aug_train_bbox/dog.3{}.jpg\".format(i), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog05\n",
    "\n",
    "#bboxes = [[182, 20, 917, 576]]\n",
    "#category_ids = [1] #dog\n",
    "\n",
    "#image = cv2.imread('./sprint18_image/training/dog.05.jpg')\n",
    "\n",
    "#for i in range(aug_num):\n",
    "        \n",
    "#    transformed = transform(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "#    img = visualize(\n",
    "#                             transformed['image'],\n",
    "#                             transformed['bboxes'],\n",
    "#                             transformed['category_ids'],\n",
    "#                             category_id_to_name,\n",
    "#                             )\n",
    "\n",
    "#    cv2.imwrite(\"./sprint18_image/aug_train_bbox/dog.4{}.jpg\".format(i), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-rebecca",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stainless-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './sprint18_image/aug_train_bbox/'\n",
    "flist = os.listdir(path)\n",
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = glob.glob(path + '/*' + \".jpg\")\n",
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_img_array = np.empty((0,224,224,3))\n",
    "cat_img_array = np.empty((0,224,224,3))\n",
    "\n",
    "for img in img_list:\n",
    "    \n",
    "    if re.search('dog', img):\n",
    "        \n",
    "        dog_img_ = Image.open(img)\n",
    "        dog_img_ = dog_img_.resize((224, 224))\n",
    "        dog_img = np.array(dog_img_)\n",
    "        dog_img = dog_img / 255.\n",
    "        dog_img = dog_img.reshape((1,224,224,3))\n",
    "        dog_img_array = np.concatenate([dog_img_array, dog_img], axis = 0)\n",
    "        dog_img_.close()\n",
    "    \n",
    "    if re.search('cat', img):\n",
    "        \n",
    "        cat_img_ = Image.open(img)\n",
    "        cat_img_ = cat_img_.resize((224, 224))\n",
    "        cat_img = np.array(cat_img_)\n",
    "        cat_img = cat_img / 255.\n",
    "        cat_img = cat_img.reshape((1,224,224,3))\n",
    "        cat_img_array = np.concatenate([cat_img_array, cat_img], axis = 0)\n",
    "        cat_img_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dog_image:{}  cat_image:{}'.format(dog_img_array.shape, cat_img_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結合してX_trainに\n",
    "\n",
    "X_train = np.concatenate((cat_img_array, dog_img_array), axis=0)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-abraham",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベル作成 0=cat, 1=dog\n",
    "\n",
    "label_cat = np.zeros((len(cat_img_array)))\n",
    "label_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dog = np.ones((len(dog_img_array)))\n",
    "label_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate((label_cat, label_dog))\n",
    "#y_train = y_train.reshape(-1, 1)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "#y_train = enc.fit_transform(y_train)\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = tf.keras.applications.vgg16.VGG16(\n",
    "                                                                        weights='imagenet', \n",
    "                                                                        include_top=False, \n",
    "                                                                        input_shape=(224, 224, 3)\n",
    "                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tf.keras import models\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(conv_base)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                             batch_size=1,\n",
    "                             epochs=10,\n",
    "                             verbose=1,  # ０=非表示、2=エポックごとの表示\n",
    "                             validation_data=(X_val, y_val)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-karen",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './sprint18_image/testdataset/'\n",
    "flist = os.listdir(path)\n",
    "flist\n",
    "\n",
    "# チャネル数４のデータは排除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = glob.glob(path + '/*' + \".jpg\")\n",
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_img_array = np.empty((0,224,224,3))\n",
    "cat_img_array = np.empty((0,224,224,3))\n",
    "\n",
    "for img in img_list:\n",
    "    \n",
    "    if re.search('dog', img):\n",
    "        \n",
    "        dog_img_ = Image.open(img)\n",
    "        dog_img_ = dog_img_.resize((224, 224))\n",
    "        dog_img = np.array(dog_img_)\n",
    "        #print(dog_img.shape)\n",
    "        dog_img = dog_img / 255.\n",
    "        dog_img = dog_img.reshape((1,224,224,3))\n",
    "        dog_img_array = np.concatenate([dog_img_array, dog_img], axis = 0)\n",
    "        dog_img_.close()\n",
    "    \n",
    "    if re.search('cat', img):\n",
    "        \n",
    "        cat_img_ = Image.open(img)\n",
    "        cat_img_ = cat_img_.resize((224, 224))\n",
    "        cat_img = np.array(cat_img_)\n",
    "        cat_img = cat_img / 255.\n",
    "        cat_img = cat_img.reshape((1,224,224,3))\n",
    "        cat_img_array = np.concatenate([cat_img_array, cat_img], axis = 0)\n",
    "        cat_img_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dog_image:{}  cat_image:{}'.format(dog_img_array.shape, cat_img_array.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((cat_img_array, dog_img_array), axis=0)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 精度上がらず\n",
    "\n",
    "model.predict(X_test, batch_size=None, verbose=1, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-inclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
