{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "#from keras.datasets import mnist\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平滑化\n",
    "    \n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "\n",
    "#X_train = X_train.astype(np.float)\n",
    "#X_test = X_test.astype(np.float)\n",
    "#X_train /= 255\n",
    "#X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8:2にtrain_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d():\n",
    "    \n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr=0.01):\n",
    "        \n",
    "        #self.optimizer = optimizer\n",
    "        \n",
    "        # 仮\n",
    "        self.w = np.array([3, 5, 7])\n",
    "        self.b = np.array([1])\n",
    "        \n",
    "        self.X = None\n",
    "        \n",
    "        self.dW = None\n",
    "        self.dB = None\n",
    "        \n",
    "        self.pad = None\n",
    "        self.stride = None\n",
    "        self.FW = None\n",
    "\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.N_out = None\n",
    "    \n",
    "    \n",
    "    def conv_forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "    \n",
    "        # 仮\n",
    "        self.pad = 1\n",
    "        self.stride = 1\n",
    "        \n",
    "        # フィルタの幅は重みのサイズ（今回は幅３）\n",
    "        self.FW = len(self.w)\n",
    "        \n",
    "        # 入力Xをコントラクタに保存しておく\n",
    "        self.X = X\n",
    "              \n",
    "        # conv後の出力のサイズ（self.N_out）を取っておく\n",
    "        self.N_out = (len(X) + 2 * self.pad - self.FW) //  self.stride + 1\n",
    "        \n",
    "        # 入力にパディング\n",
    "        X = np.pad(X, self.pad)\n",
    "\n",
    "        # 出力の空箱を用意する\n",
    "        out = np.zeros(self.N_out)\n",
    "        \n",
    "        # 入力をフィルタサイズに切り出し、フィルタの要素毎に積を取り、それを出力のi番目の要素としたい\n",
    "        for i in range(self.N_out):\n",
    "            # 入力のi番目からフィルタサイズ分、ストライド幅毎に、Xとwの積をとる\n",
    "            out[i] += np.dot(X[i : i+self.FW], self.w.T)\n",
    "            # ！！！ストライド未実装！！！\n",
    "            \n",
    "            print(out)\n",
    "            \n",
    "        # バイアスを足す    \n",
    "        out += self.b\n",
    "        \n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def conv_backward(self, dA):\n",
    "        \n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        # XについてのLの微分\n",
    "        delta_x = np.zeros(self.N_out)\n",
    "        for i in range(len(dA)):\n",
    "            delta_x[i : i + self.FW] += dA[i] * self.w\n",
    "        print(\"delta_x\" + str(delta_x))\n",
    "            \n",
    "        # BについてのLの微分\n",
    "        delta_b = 0\n",
    "        for i in range(len(dA)):\n",
    "            delta_b += np.sum(dA[i], axis=0)\n",
    "        print(\"delta_b\" + str(delta_b))    \n",
    "            \n",
    "        # WについてのLの微分\n",
    "        delta_w = np.zeros(len(self.w))\n",
    "        for i in range(len(dA)):\n",
    "            delta_w += dA[i] * self.X[i : i + self.FW]\n",
    "        print(\"delta_w\" + str(delta_w))\n",
    "        \n",
    "        # optimizerに流す前にデータ型を揃える\n",
    "        self.w = self.w.astype(np.float64)\n",
    "        self.b = self.b.astype(np.float64)\n",
    "        \n",
    "        # 更新\n",
    "        self.w -= self.lr * delta_w\n",
    "        self.b -= self.lr * delta_b\n",
    "        #self.optimizer.update(self)\n",
    "        \n",
    "        print(\"self.w\" + str(self.w))\n",
    "        print(\"self.b\" + str(self.b))\n",
    "        \n",
    "        return delta_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】1次元畳み込み後の出力サイズの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 1\n",
    "stride  = 3\n",
    "FW = 3\n",
    "\n",
    "def calc_kernel_size(X):\n",
    "    \n",
    "    N_out = (X.shape[1] + 2 * pad - FW) //  stride + 1\n",
    "    return N_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_kernel_size(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】小さな配列での1次元畳み込み層の実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_conv1d = SimpleConv1d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.  0.  0.  0.]\n",
      "[19. 34.  0.  0.]\n",
      "[19. 34. 49.  0.]\n",
      "[19. 34. 49. 29.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([20., 35., 50., 30.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward\n",
    "\n",
    "x = np.array([1, 2, 3, 4])\n",
    "\n",
    "s_conv1d.conv_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta_x[ 30. 110. 170. 140.]\n",
      "delta_b30\n",
      "delta_w[ 50.  80. 110.]\n",
      "self.w[2.5 4.2 5.9]\n",
      "self.b[0.7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 30., 110., 170., 140.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# backward\n",
    "\n",
    "delta_a = np.array([10, 20])\n",
    "\n",
    "s_conv1d.conv_backward(delta_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トイデータ\n",
    "x = np.array([1, 2, 3, 4])\n",
    "w = np.array([3, 5, 7])\n",
    "a = np.empty((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ind0 = np.array([0, 1, 2]).astype(np.int)\n",
    "ind1 = np.array([1, 2, 3]).astype(np.int)\n",
    "\n",
    "print(ind0)\n",
    "print(ind1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FW=3 # フィルタ幅\n",
    "\n",
    "x[0:FW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34., 49.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0] = x[ind0]*w # x[indexes0]は([1, 2, 3])である\n",
    "a[1] = x[ind1]*w # x[indexes1]は([2, 3, 4])である\n",
    "\n",
    "a = a.sum(axis=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [2 3 4]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4])\n",
    "indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\n",
    "print(x[indexes]) # ([[1, 2, 3], [2, 3, 4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FW = 3 #フィルタ幅\n",
    "C = 3 #出力チャネル数\n",
    "N_out = 2 #出力サイズ\n",
    "out = np.zeros((C, N_out)) #出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ① 入力xの（N_in=0, F=0~3）要素とwの（C=0, N_in=0, FW=:）要素の積を取り、出力outの（C=0, N_out=0）要素に加える\n",
    "out[0, 0] += (x[0, 0 : 0+FW] * w[0, 0, :]).sum()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 9.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ② 入力xの（N_in=0, F=1~4）要素とwの（C=0, N_in=0, FW=:）要素の積を取り、出力outの（C=0, N_out=1）要素に加える\n",
    "# F = N_out : N_out + FW\n",
    "out[0, 1] += (x[0, 1 : 1+FW] * w[0, 0, :]).sum()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.,  9.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ③ 入力xの（N_in=1, F=0~3）要素とwの（C=0, N_in=1, FW=:）要素の積を取り、出力outの（C=0, N_out=0）要素に加える\n",
    "out[0, 0] += (x[1, 0 : 0+FW] * w[0, 1, :]).sum()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15., 21.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ④ 入力xの（N_in=1, F=1~4）要素とwの（C=0, N_in=1, FW=:）要素の積を取り、出力outの（C=0, N_out=1）要素に加える\n",
    "out[0, 1] += (x[1, 1 : 1+FW] * w[0, 1, :]).sum()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16., 22.],\n",
       "       [ 0.,  0.],\n",
       "       [ 0.,  0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ⑤ 出力outの（C=0, N_out=:）要素にバイアスを加える\n",
    "out[0, :] += b[0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16. 22.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# ⑥ ↑の処理をfor ループ化\n",
    "\n",
    "FW = 3 #フィルタ幅\n",
    "C = 3 #出力チャネル数\n",
    "N_out = 2 #出力サイズ\n",
    "N_in = x.shape[0]\n",
    "out = np.zeros((C, N_out)) #出力\n",
    "\n",
    "for i in range(N_in):\n",
    "    for o in range(N_out):\n",
    "        out[0, o] += (x[i, o : o+FW] * w[0, i, :]).sum()\n",
    "out[0, :] += b[0]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16. 22.]\n",
      " [17. 23.]\n",
      " [18. 24.]]\n"
     ]
    }
   ],
   "source": [
    "# ⑦ ↑を入力チャネル数分（C回）行う\n",
    "\n",
    "FW = 3 #フィルタ幅\n",
    "C = 3 #出力チャネル数\n",
    "N_out = 2 #出力サイズ\n",
    "out = np.zeros((C, N_out)) #出力\n",
    "\n",
    "for c in range(C):\n",
    "    for i in range(N_in):\n",
    "        for o in range(N_out):\n",
    "            out[c, o] += (x[i, o : o+FW] * w[c, i, :]).sum()\n",
    "    out[c, :] += b[c]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、入力チャネル数）である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】（アドバンス課題）パディングの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 2, 3, 4, 0],\n",
       "       [0, 2, 3, 4, 5, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(x, pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0],\n",
       "       [1, 2, 3, 4],\n",
       "       [2, 3, 4, 5],\n",
       "       [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 入力チャネル数方向にゼロパディング\n",
    "np.pad(x, [(pad, pad), (0, 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4, 0],\n",
       "       [0, 2, 3, 4, 5, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特徴量方向にゼロパディング（今回はこれを使いたい）\n",
    "np.pad(x, [(0, 0), (pad, pad)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4, 0],\n",
       "       [0, 2, 3, 4, 5, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_padded = np.pad(x, [(0, 0), (pad, pad)])\n",
    "x_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " array([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FW = 3 #フィルタ幅\n",
    "C = 3 #出力チャネル数\n",
    "stride = 1\n",
    "pad = 1\n",
    "\n",
    "# パディング後の出力サイズの計算（strideは１で固定）＊パディング前のxのサイズを使うことに注意\n",
    "N_out = (x.shape[1] + 2 * pad - FW) //  stride + 1\n",
    "out = np.zeros((C, N_out)) #出力\n",
    "\n",
    "N_out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9. 16. 22. 17.]\n",
      " [10. 17. 23. 18.]\n",
      " [11. 18. 24. 19.]]\n"
     ]
    }
   ],
   "source": [
    "x_padded = np.pad(x, [(0, 0), (pad, pad)])\n",
    "\n",
    "for c in range(C):\n",
    "    for i in range(N_in):\n",
    "        for o in range(N_out):\n",
    "            out[c, o] += (x_padded[i, o : o+FW] * w[c, i, :]).sum() # padされたxに置き換えている\n",
    "    out[c, :] += b[c]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】（アドバンス課題）任意のストライド数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4, 0],\n",
       "       [0, 2, 3, 4, 5, 0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "------------\n",
      "[[3. 7.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "------------\n",
      "[[8. 7.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "------------\n",
      "[[ 8. 16.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n",
      "------------\n",
      "[[ 9. 17.]\n",
      " [ 3.  0.]\n",
      " [ 0.  0.]]\n",
      "------------\n",
      "[[ 9. 17.]\n",
      " [ 3.  7.]\n",
      " [ 0.  0.]]\n",
      "------------\n",
      "[[ 9. 17.]\n",
      " [ 8.  7.]\n",
      " [ 0.  0.]]\n",
      "------------\n",
      "[[ 9. 17.]\n",
      " [ 8. 16.]\n",
      " [ 0.  0.]]\n",
      "------------\n",
      "[[ 9. 17.]\n",
      " [10. 18.]\n",
      " [ 3.  0.]]\n",
      "------------\n",
      "[[ 9. 17.]\n",
      " [10. 18.]\n",
      " [ 3.  7.]]\n",
      "------------\n",
      "[[ 9. 17.]\n",
      " [10. 18.]\n",
      " [ 8.  7.]]\n",
      "------------\n",
      "[[ 9. 17.]\n",
      " [10. 18.]\n",
      " [ 8. 16.]]\n",
      "------------\n",
      "[[ 9. 17.]\n",
      " [10. 18.]\n",
      " [11. 19.]]\n"
     ]
    }
   ],
   "source": [
    "x_padded = np.pad(x, [(0, 0), (pad, pad)])\n",
    "\n",
    "FW = 3 #フィルタ幅\n",
    "C = 3 #出力チャネル数\n",
    "stride = 3\n",
    "pad = 1\n",
    "\n",
    "N_out = (x.shape[1] + 2 * pad - FW) //  stride + 1\n",
    "out = np.zeros((C, N_out)) #出力\n",
    "\n",
    "for c in range(C):\n",
    "    for i in range(N_in):\n",
    "        for o in range(N_out):\n",
    "            out[c, o] += (x_padded[i, (o*stride) : (o*stride)+FW] * w[c, i, :]).sum() # stride=3 の間隔で処理を行うように改変\n",
    "            print(out)\n",
    "            print(\"-\"*12)\n",
    "    out[c, :] += b[c]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】（アドバンス課題）ミニバッチへの対応"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mini_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2, 4),\n",
       " array([[[6, 6, 6, 1],\n",
       "         [2, 7, 7, 4]],\n",
       " \n",
       "        [[5, 2, 8, 4],\n",
       "         [4, 2, 1, 3]]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# バッジサイズ N=2 の入力を生成\n",
    "\n",
    "x_3d = np.random.randint(1, 9, (2, 2, 4))\n",
    "x_3d.shape, x_3d # shape  =（N, N_in, F） "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 2, 6),\n",
       " array([[[0, 6, 6, 6, 1, 0],\n",
       "         [0, 2, 7, 7, 4, 0]],\n",
       " \n",
       "        [[0, 5, 2, 8, 4, 0],\n",
       "         [0, 4, 2, 1, 3, 0]]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature方向にパディング\n",
    "\n",
    "x_3d_padded = np.pad(x_3d, [(0, 0), (0, 0), (pad, pad)])\n",
    "x_3d_padded.shape, x_3d_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[22. 19.]\n",
      "  [23. 20.]\n",
      "  [24. 21.]]\n",
      "\n",
      " [[14. 17.]\n",
      "  [15. 18.]\n",
      "  [16. 19.]]]\n"
     ]
    }
   ],
   "source": [
    "N = 2 #ミニバッチ数\n",
    "FW = 3 #フィルタ幅\n",
    "C = 3 #出力チャネル数\n",
    "\n",
    "stride = 3\n",
    "pad = 1\n",
    "\n",
    "N_out = (x_3d.shape[2] + 2 * pad - FW) //  stride + 1\n",
    "out = np.zeros((N, C, N_out)) #出力\n",
    "\n",
    "for n in range(N):\n",
    "    for c in range(C):\n",
    "        for i in range(N_in):\n",
    "            for o in range(N_out):\n",
    "                out[n, c, o] += (x_3d_padded[n, i, (o*stride) : (o*stride)+FW] * w[c, i, :]).sum()\n",
    "        out[n, c, :] += b[c]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA = np.array([[9, 11], [32, 35], [52, 56]])\n",
    "dA.shape #（C, N_out）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 11])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dA[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_x = np.zeros((x.shape))\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9., 9., 9., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ① delta_x の N_in=0 の F=0~2 に、C=0, N_out=0のdAと C=0, N=0 のwの各要素を掛け合わたものを足し込む。\n",
    "delta_x[0, 0 : 0 + FW] += dA[0, 0]*w[0, 0, :]\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9., 20., 20., 11.],\n",
       "       [ 0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ② delta_x の N_in=0 の F=1~3 に、C=0, N_out=1のdAと C=0, N=0 のwの各要素を掛け合わたものを足し込む。\n",
    "delta_x[0, 1 : 1 + FW] += dA[0, 1]*w[0, 0, :]\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9., 20., 20., 11.],\n",
       "       [ 9.,  9.,  9.,  0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ③ delta_x の N_in=1 の F=0~2 に、C=0, N_out=0のdAと C=0, N=1 のwの各要素を掛け合わたものを足し込む。\n",
    "delta_x[1, 0 : 0 + FW] += dA[0, 0]*w[0, 1, :]\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9., 20., 20., 11.],\n",
       "       [ 9., 20., 20., 11.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ④ delta_x の N_in=1 の F=1~3 に、C=0, N_out=1のdAと C=0, N=1 のwの各要素を掛け合わたものを足し込む。\n",
    "delta_x[1, 1 : 1 + FW] += dA[0, 1]*w[0, 1, :]\n",
    "delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9. 20. 20. 11.]\n",
      " [ 9. 20. 20. 11.]]\n"
     ]
    }
   ],
   "source": [
    "# ⑤↑をfor ループ化\n",
    "\n",
    "N_out= dA.shape[1] # 出力サイズ:2\n",
    "FW = w.shape[2] # フィルタ幅:3\n",
    "F = x.shape[1] #特徴量:4\n",
    "N_in = x.shape[0] #入力チャネル数:2\n",
    "delta_x = np.zeros((N_in, F))\n",
    "\n",
    "for i in range(N_in):\n",
    "    for o in range(N_out):\n",
    "        delta_x[i, o : o+FW] += dA[0, o]*w[0, i, :]\n",
    "print(delta_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93. 195. 195. 102.]\n",
      " [ 93. 195. 195. 102.]]\n"
     ]
    }
   ],
   "source": [
    "# ↑をC回ループ処理を行う\n",
    "C = dA.shape[0] # 入力チャネル数:3\n",
    "N_out= dA.shape[1] # 出力サイズ:2\n",
    "FW = w.shape[2] # フィルタ幅:3\n",
    "F = x.shape[1] #特徴量:4\n",
    "N_in = x.shape[0] #入力チャネル数:2\n",
    "delta_x = np.zeros((N_in, F))\n",
    "\n",
    "for c in range(C):\n",
    "    for i in range(N_in):\n",
    "        for o in range(N_out):\n",
    "            delta_x[i, o : o + FW] += dA[c, o]*w[c, i, :]\n",
    "print(delta_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [2, 3, 4, 5]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 2, 3),\n",
       " array([[[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.]]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FW = 3\n",
    "\n",
    "delta_w = np.zeros((w.shape))\n",
    "delta_w.shape, delta_w # （C, N, W）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 9., 18., 27.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ① dAの（C=0, N_out=0）要素とxの（N_in=0、F=0 : 3）要素を掛け、delta_wの（C=0, N_in=0, FW=:）要素に足す\n",
    "delta_w[0, 0, :] += dA[0, 0] * x[0, 0 : 0+FW]\n",
    "delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[31., 51., 71.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ② dAの（C=0, N_out=1）要素とxの（N_in=0、F=1 : 4）要素を掛け、delta_wの（C=0, N_in=0, FW=:）要素に足す\n",
    "delta_w[0, 0, :] += dA[0, 1] * x[0, 1 : 1 + FW]\n",
    "delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[31., 51., 71.],\n",
       "        [18., 27., 36.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ③ dAの（C=0, N_out=0）要素とxの（N_in=1、F=0 : 3）要素を掛け、delta_wの（C=0, N_in=1, FW=:）要素に足す\n",
    "delta_w[0, 1, :] += dA[0, 0] * x[1, 0 : 0+FW]\n",
    "delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[31., 51., 71.],\n",
       "        [51., 71., 91.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ④ dAの（C=0, N_out=1）要素とxの（N_in=1、F=1 : 4）要素を掛け、delta_wの（C=0, N_in=1, FW=:）要素に足す\n",
    "delta_w[0, 1, :] += dA[0, 1] * x[1, 1 : 1+FW]\n",
    "delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[31. 51. 71.]\n",
      "  [51. 71. 91.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0.]\n",
      "  [ 0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "# ⑤↑をforループ化\n",
    "N_in = 2 #入力\n",
    "N_out= 2 # 出力\n",
    "FW = 3 # フィルタ幅\n",
    "delta_w = np.zeros((w.shape))\n",
    "\n",
    "for i in range(N_in):\n",
    "    for o in range(N_out):\n",
    "        delta_w[0, i, :] += dA[0, o] * x[i, o : o+FW]\n",
    "print(delta_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 31.  51.  71.]\n",
      "  [ 51.  71.  91.]]\n",
      "\n",
      " [[102. 169. 236.]\n",
      "  [169. 236. 303.]]\n",
      "\n",
      " [[164. 272. 380.]\n",
      "  [272. 380. 488.]]]\n"
     ]
    }
   ],
   "source": [
    "# ⑥同様の処理をチャネル数分（C回）行う\n",
    "C = 3 #チャネル\n",
    "N_in = 2 #入力\n",
    "N_out= 2 # 出力\n",
    "FW = 3 # フィルタ幅\n",
    "delta_w = np.zeros((w.shape))\n",
    "\n",
    "for c in range(C):\n",
    "    for i in range(N_in):\n",
    "        for o in range(N_out):\n",
    "            delta_w[c, i, :] += dA[c, o] * x[i, o : o+FW]\n",
    "print(delta_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### delta_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_b = np.zeros((b.shape))\n",
    "delta_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.,  0.,  0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ① dAの（C=0）要素の総和を、delta_bの（C=0）要素とする\n",
    "delta_b[0] += dA[0, :].sum()\n",
    "delta_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20.  67. 108.]\n"
     ]
    }
   ],
   "source": [
    "# 同様の処理ををチャネル数分（C回）行う\n",
    "C = 3\n",
    "delta_b = np.zeros((b.shape))\n",
    "\n",
    "for c in range(C):\n",
    "    delta_b[c] += dA[c, :].sum()\n",
    "print(delta_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d():\n",
    "    \n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, stride, pad, lr=0.01):\n",
    "        \n",
    "        #self.optimizer = optimizer\n",
    "        \n",
    "        #forward\n",
    "        self.X = None\n",
    "        \n",
    "        self.w = np.ones((3, 2, 3)) # 今回はコンストラクタ中に組み込んでいる（実際はInitializerを使う）\n",
    "        self.b = np.array([1, 2, 3]) \n",
    "        \n",
    "        self.N_in = None #入力チャネル\n",
    "        self.C = None # 出力チャネル\n",
    "        self.FW = None # フィルタサイズ（幅のみ）\n",
    "        self.F = None\n",
    "        self.N_out = None\n",
    "        \n",
    "        self.pad = pad\n",
    "        self.stride = stride\n",
    "\n",
    "        self.dW = None\n",
    "        self.dB = None\n",
    "        \n",
    "        self.lr = lr\n",
    "    \n",
    "    \n",
    "    def calc_kernel_size(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        出力のサイズを計算\n",
    "        \"\"\"\n",
    "        \n",
    "        N_out = (self.F - self.FW) //  self.stride + 1 # self.Fはpad後のXの幅\n",
    "        return N_out\n",
    "\n",
    "    \n",
    "    def conv_forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        # ストライド・パディング\n",
    "        stride = self.stride\n",
    "        pad = self.pad\n",
    "               \n",
    "        # 入力にパディング（幅方向のみ）\n",
    "        X = np.pad(X, [(0, 0), (pad, pad)]) \n",
    "        \n",
    "        # 重みの型を取る\n",
    "        C, N_in, FW = self.w.shape\n",
    "        \n",
    "        self.N_in = N_in\n",
    "        self.C = C\n",
    "        self.FW = FW\n",
    "        \n",
    "        # 入力の型を取る\n",
    "        N_in, F = X.shape\n",
    "        \n",
    "        #self.N = N\n",
    "        self.N_in = N_in\n",
    "        self.F = F #pad後の特徴量\n",
    "        \n",
    "        # pad後の入力Xをコントラクタに保存\n",
    "        self.X = X\n",
    "        \n",
    "        w = self.w\n",
    "        b = self.b\n",
    "\n",
    "        # 出力の型を用意\n",
    "        N_out = self.calc_kernel_size(X)\n",
    "        self.N_out = N_out\n",
    "        out = np.zeros((C, N_out))\n",
    "        \n",
    "        for c in range(C):\n",
    "            for i in range(N_in):\n",
    "                for o in range(N_out):\n",
    "                        \n",
    "                    out[c, o] += (X[i, (o*stride) : (o*stride)+FW] * w[c, i, :]).sum()\n",
    "            out[c, :] += b[c]\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def conv_backward(self, dA):\n",
    "        \n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        C = self.C\n",
    "        N_out= self.N_out\n",
    "        FW = self.FW\n",
    "        F = self.F\n",
    "        N_in = self.N_in\n",
    "        \n",
    "        # ストライド・パディング\n",
    "        stride = self.stride\n",
    "        pad = self.pad\n",
    "        \n",
    "        \n",
    "        # delta_x\n",
    "        delta_x = np.zeros((self.X.shape))\n",
    "        \n",
    "        for c in range(C):\n",
    "            for i in range(N_in):\n",
    "                for o in range(N_out):\n",
    "                    delta_x[i, o : o + FW] += dA[c, o]*w[c, i, :]\n",
    "         \n",
    "        # paddingした分をリサイズし、元の入力サイズと同じにする\n",
    "        delta_x = delta_x[:, pad : -pad]\n",
    "\n",
    "        \n",
    "        # delta_b\n",
    "        delta_b = np.zeros((self.b.shape))\n",
    "\n",
    "        for c in range(C):\n",
    "            delta_b[c] += dA[c, :].sum()\n",
    "        \n",
    "            \n",
    "        # delta_w\n",
    "        delta_w = np.zeros((self.w.shape))\n",
    "        \n",
    "        for c in range(C):\n",
    "            for i in range(N_in):\n",
    "                for o in range(N_out):\n",
    "                    delta_w[c, i, :] += dA[c, o] * self.X[i, o : o+FW]\n",
    "        \n",
    "        \n",
    "        # optimizerに流す前にデータ型を揃える\n",
    "        self.w = self.w.astype(np.float64)\n",
    "        self.b = self.b.astype(np.float64)\n",
    "        \n",
    "        # 更新\n",
    "        self.w -= self.lr * delta_w\n",
    "        self.b -= self.lr * delta_b\n",
    "        #self.optimizer.update(self)\n",
    "        \n",
    "        print(\"self.w\" + str(self.w))\n",
    "        print(\"self.b\" + str(self.b))\n",
    "        \n",
    "        return delta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d = Conv1d(stride=1, pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4),\n",
       " array([[ 9., 16., 22., 17.],\n",
       "        [10., 17., 23., 18.],\n",
       "        [11., 18., 24., 19.]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward\n",
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
    "conv1d.conv_forward(x).shape, conv1d.conv_forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 4),\n",
       " array([[7, 3, 7, 7],\n",
       "        [6, 2, 3, 2],\n",
       "        [4, 3, 5, 6]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# backward（1pad, 1stride）\n",
    "#dA = np.array([[9, 11], [32, 35], [52, 56]])\n",
    "dA = np.random.randint(1, 9, (3, 4))\n",
    "dA.shape, dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.w[[[0.62 0.38 0.49]\n",
      "  [0.45 0.14 0.32]]\n",
      "\n",
      " [[0.86 0.73 0.7 ]\n",
      "  [0.79 0.6  0.59]]\n",
      "\n",
      " [[0.69 0.51 0.63]\n",
      "  [0.55 0.33 0.51]]]\n",
      "self.b[0.76 1.87 2.82]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[25., 40., 38., 30.],\n",
       "       [25., 40., 38., 30.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 入力と同じ形で返す（2, 4）\n",
    "\n",
    "dZ = conv1d.conv_backward(dA)\n",
    "dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "from tensorflow import keras\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平滑化\n",
    "    \n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理\n",
    "\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8:2にtrain_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 雛形\n",
    "\n",
    "class FC:\n",
    "    \n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "       \n",
    "        self.X = None\n",
    "        self.dZ = None\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = X\n",
    "        \n",
    "        # アフィン変換\n",
    "        A = X.dot(self.W) + self.B\n",
    "\n",
    "        return A\n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "            \n",
    "        \"\"\"\n",
    "        # 前のノードに流す勾配\n",
    "        self.dZ = np.dot(dA, self.W.T)\n",
    "        \n",
    "        # バイアスに流す勾配\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        \n",
    "        # 重み行列に流す勾配\n",
    "        self.dW = np.dot(self.X.T, dA)\n",
    "        \n",
    "        # 更新\n",
    "        self.optimizer.update(self)\n",
    "        \n",
    "        return self.dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d():\n",
    "    \n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, initializer, optimizer, N=20, O=1, C=1,  FW=3, stride=1, pad=0, lr=0.01):\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        #forward\n",
    "        self.X = None\n",
    "            \n",
    "        self.N = N #サンプル数\n",
    "        \n",
    "        self.O = O\n",
    "        self.C = C\n",
    "        \n",
    "        self.FW = FW # フィルタサイズ（幅のみ）\n",
    "        self.F = None #特徴量数\n",
    "        self.f_out = None #出力の特徴量数\n",
    "        \n",
    "        self.initializer = initializer\n",
    "        self.W = self.initializer.W(N, O, C, FW) # (バッチサイズ、出力チャネル数、入力チャネル数、フィルタサイズ)\n",
    "        self.B = self.initializer.B(N, O) # (バッチサイズ、出力チャネル数)\n",
    "        \n",
    "        self.pad = pad\n",
    "        self.stride = stride\n",
    "         \n",
    "        self.dW = None\n",
    "        self.dB = None\n",
    "        \n",
    "        self.lr = lr\n",
    "    \n",
    "    \n",
    "    def calc_kernel_size(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        出力のサイズを計算\n",
    "        \"\"\"\n",
    "        \n",
    "        out = (self.F - self.FW) //  self.stride + 1 # self.Fはpad後のXの幅\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def conv_forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        # ストライド・パディング\n",
    "        stride = self.stride\n",
    "        pad = self.pad\n",
    "        \n",
    "        N = self.N\n",
    "        O = self.O\n",
    "        C = self.C\n",
    "        \n",
    "        # 入力にパディング（幅方向のみ）\n",
    "        X = np.pad(X, [(0, 0), (0, 0), (pad, pad)]) \n",
    "\n",
    "        # 入力の型を取る\n",
    "        _, _, F = X.shape\n",
    "        self.F = F\n",
    "        self.X = X # backwardで使う\n",
    "        \n",
    "        w = self.W\n",
    "        b = self.B\n",
    "        \n",
    "        # 出力の型を用意\n",
    "        f_out = self.calc_kernel_size(X)\n",
    "        self.f_out = f_out\n",
    "        out = np.zeros((N, O, f_out))\n",
    "        \n",
    "        for n in range(N):\n",
    "            for o in range(O):\n",
    "                for c in range(C):\n",
    "                    for f in range(f_out):\n",
    "                        out[n, o, f] += (X[n, c, (f*stride) : (f*stride)+FW] * w[n, o, c, :]).sum()\n",
    "                        out += b[n, :]\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def conv_backward(self, dA):\n",
    "        \n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        X = self.X\n",
    "        f_out = self.f_out\n",
    "        FW = self.FW\n",
    "        C  = self.C\n",
    "        O = self.O\n",
    "        F = self.F\n",
    "        w = self.W\n",
    "            \n",
    "        stride = self.stride\n",
    "        pad = self.pad\n",
    "        \n",
    "   \n",
    "        # delta_x\n",
    "        delta_x = np.zeros((self.X.shape))\n",
    "        \n",
    "        for n in range(N):\n",
    "            for o in range(O):\n",
    "                for c in range(C):\n",
    "                    for f in range(f_out):\n",
    "                        delta_x[n, c, f*stride : f*stride+FW] += dA[n, o, f]*w[n, o, c, :]\n",
    "                \n",
    "        delta_x = delta_x[:, :, pad : -pad]\n",
    "        \n",
    "                \n",
    "        # delta_b\n",
    "        delta_b = np.zeros((self.B.shape))\n",
    "\n",
    "        for n in range(N):\n",
    "            for o in range(O):\n",
    "                for f in range(f_out):\n",
    "                        delta_b[n, o] += dA[n, o, :].sum()   \n",
    "                        \n",
    "        self.dB = delta_b        \n",
    "        \n",
    "           \n",
    "        # delta_w\n",
    "        delta_w = np.zeros((self.W.shape))\n",
    "         \n",
    "        for n in range(N):\n",
    "            for o in range(O):\n",
    "                for c in range(C):\n",
    "                    for f in range(f_out):\n",
    "                        delta_w[n, o, c,  :] += dA[n, o, f] * X[n, c, (f*stride) : (f*stride)+FW]\n",
    "                                    \n",
    "        self.dW = delta_w\n",
    "                \n",
    "        # optimizerに流す前にデータ型を揃える\n",
    "        #self.W = self.W.astype(np.float64)\n",
    "        #self.B = self.B.astype(np.float64)\n",
    "        \n",
    "        # 更新\n",
    "        #self.W -= self.lr * delta_w\n",
    "        #self.B -= self.lr * delta_b\n",
    "        self.optimizer.update(self)\n",
    "        \n",
    "        return delta_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "         \n",
    "    def forward(self, A):\n",
    "\n",
    "        self.Z = (np.exp(A) - np.exp(-A)) / (np.exp(A) + np.exp(-A))\n",
    "        return self.Z\n",
    "    \n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \n",
    "        dA = dZ*(1 - self.Z)**2\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    \n",
    "    def forward(self, A):\n",
    "        \n",
    "        A = A - np.max(A, axis=1, keepdims=True)\n",
    "        Z = np.exp(A) / np.sum(np.exp(A), axis=1, keepdims=True)\n",
    "        return Z\n",
    "        \n",
    "        \n",
    "    def backward(self, dZ, Y):\n",
    "        \n",
    "        batch_size = dZ.shape[0]\n",
    "        dA = (dZ - Y) / batch_size\n",
    "        \n",
    "        loss = (-1)*np.sum(Y * np.log(dZ + 1e-7))  / batch_size\n",
    "        \n",
    "        \n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.mask = None\n",
    "    \n",
    "    \n",
    "    def forward(self, A):\n",
    "\n",
    "        self.mask = (A <= 0)\n",
    "        Z = np.maximum(0, A)\n",
    "        return Z\n",
    "        \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \n",
    "        dA[self.mask] = 0\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    \n",
    "    def forward(self, A):\n",
    "\n",
    "        self.A = A\n",
    "        Z = np.maximum(0, A)\n",
    "        return Z\n",
    "        \n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        \n",
    "        dA = np.where(self.A>0, dZ, 0)\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvInitializer():\n",
    "    \n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sigma=0.01):\n",
    "        \n",
    "        self.sigma = sigma\n",
    "        \n",
    "        \n",
    "    def W(self, N, O, C, F):\n",
    "        \n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "          \n",
    "        Returns\n",
    "        ----------\n",
    "        W :float\n",
    "            重みの初期値\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        W = self.sigma * np.random.randn(N, O, C, F)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, N, O):\n",
    "        \n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "          \n",
    "        Returns\n",
    "        ----------\n",
    "        B :float\n",
    "            バイアスの初期値\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        B = self.sigma * np.random.randn(N, O)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer():\n",
    "    \n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sigma=0.01):\n",
    "        \n",
    "        self.sigma = sigma\n",
    "        \n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "          \n",
    "        Returns\n",
    "        ----------\n",
    "        W :float\n",
    "            重みの初期値\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "          \n",
    "        Returns\n",
    "        ----------\n",
    "        B :float\n",
    "            バイアスの初期値\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \n",
    "    \"\"\"\n",
    "    Heの初期値\n",
    "      \n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        \n",
    "        self.sigma = sigma\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "          \n",
    "        Returns\n",
    "        ----------\n",
    "        W :float\n",
    "            重みの初期値\n",
    "            \n",
    "        \"\"\"\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        sigma = np.sqrt(2 / n_nodes1)\n",
    "        W = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "          \n",
    "        Returns\n",
    "        ----------\n",
    "        B :float\n",
    "            バイアスの初期値\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        sigma = np.sqrt(2 / self.n_nodes1)\n",
    "        B = sigma * np.random.randn(n_nodes2)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD():\n",
    "    \n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        \n",
    "        self.lr = lr\n",
    "        \n",
    "        \n",
    "    def update(self, layer):\n",
    "        \n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.B -= self.lr * layer.dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad():\n",
    "    \n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lr):\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.hW = 1.\n",
    "        self.hB = 1.\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.hW += np.mean(layer.dW, axis=0)**2\n",
    "        self.hB += ((np.mean(layer.dB, axis=0))**2).sum(axis=0)\n",
    "        \n",
    "        layer.W -= (self.lr / np.sqrt(self.hW)) * layer.dW\n",
    "        layer.B -= (self.lr / np.sqrt(self.hB)) * layer.dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def __next__(self):\n",
    "        \n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "            \n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchConvolutionalNeuralNetrowkClassifier():\n",
    "    \n",
    "    \"\"\"\n",
    "    任意の構成で学習と推定が行えるCNNクラス\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fc_initializer, conv_initializer, optimizer, activator1, activator2, lr = 0.01,  batch_size = 20, n_features = 88, n_output = 10, sigma=0.01, n_epochs=20, verbose = True):\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.n_features = n_features\n",
    "        self.n_output = n_output\n",
    "        \n",
    "        self.Conv1 = None\n",
    "        self.Conv2 = None\n",
    "        self.FC = None\n",
    "        \n",
    "        self.fc_initializer = fc_initializer\n",
    "        self.conv_initializer = conv_initializer\n",
    "        self.optimizer = optimizer\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.activator1 = activator1\n",
    "        self.activator2 = activator2   \n",
    "        \n",
    "        self.sigma = sigma\n",
    "        \n",
    "        self.loss = None\n",
    "        self.val_loss = None\n",
    "        \n",
    "        self.loss_hist = []\n",
    "        self.val_loss_hist = []\n",
    "        \n",
    "        \n",
    "    # 訓練時に１エポック分の処理を行う関数\n",
    "    def forward_and_backward(self, X, y):\n",
    "        \n",
    "        # one-hot変換\n",
    "        Y = np.identity(10)[y]\n",
    "        \n",
    "        # 入力Xの入力チャンネル次元を作る\n",
    "        X = X[:, np.newaxis, :]  #(N, C, F)\n",
    "        #print(\"X\"+str(X.shape))\n",
    "        \n",
    "        # サンプルコード2 : フォワード\n",
    "        A1 = self.Conv1.conv_forward(X)\n",
    "        #print(\"A1\"+str(A1.shape))\n",
    "        \n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        #print(\"Z1\"+str(Z1.shape))\n",
    "        \n",
    "        A2 = self.Conv2.conv_forward(Z1)\n",
    "        #print(\"A2\"+str(A2.shape))\n",
    "        \n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        #print(\"Z2\"+str(Z2.shape))\n",
    "        \n",
    "        # FC層に渡せる形に変換\n",
    "        Z2 = Z2[:, -1]\n",
    "        #print(\"Z2\"+str(Z2.shape))\n",
    "        \n",
    "        #F1 = self.Flat.flat_forward(Z2)\n",
    "        #print(\"F1\"+str(F1.shape))\n",
    "        \n",
    "        A3 = self.FC.forward(Z2)\n",
    "        #print(\"A3\"+str(A3.shape))\n",
    "        \n",
    "        Z3 = self.activation3.forward(A3)      \n",
    "        #print(\"Z3\"+str(Z3.shape))\n",
    "    \n",
    "        # サンプルコード3 : バックワード\n",
    "        dA3, self.loss = self.activation3.backward(Z3, Y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "        #print(\"dA3\"+str(dA3.shape))\n",
    "            \n",
    "        dZ2 = self.FC.backward(dA3)\n",
    "        #print(\"dZ2\"+str(dZ2.shape))\n",
    "        \n",
    "        # チャンネル軸を増やす\n",
    "        dZ2 = dZ2[:, np.newaxis, :]\n",
    "        #print(\"dZ2\"+str(dZ2.shape))\n",
    "        \n",
    "        dA2 = self.activation2.backward(dZ2)\n",
    "        #print(\"dA2\"+str(dA2.shape))\n",
    "        \n",
    "        dZ1 = self.Conv2.conv_backward(dA2)\n",
    "        #print(\"dZ1\"+str(dZ1.shape))\n",
    "        \n",
    "        dA1 = self.activation1.backward(dZ1)\n",
    "        #print(\"dA1\"+str(dA1.shape))\n",
    "        \n",
    "        dZ0 = self.Conv1.conv_backward(dA1) # dZ0は使用しない\n",
    "        #print(dZ0.shape)\n",
    "        \n",
    "    \n",
    "    \n",
    "    # このエポックで更新した重みを使って検証する関数\n",
    "    def forward_with_loss(self, X, y):\n",
    "        \n",
    "        Y = np.identity(10)[y]\n",
    "        \n",
    "        X = X[:, np.newaxis, :]  #(N, C, F)\n",
    "        #print(\"X\"+str(X.shape))\n",
    "        \n",
    "        A1 = self.Conv1.conv_forward(X)\n",
    "        #print(\"A1\"+str(A1.shape))\n",
    "        \n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        #print(\"Z1\"+str(Z1.shape))\n",
    "        \n",
    "        A2 = self.Conv2.conv_forward(Z1)\n",
    "        #print(\"A2\"+str(A2.shape))\n",
    "        \n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        #print(\"Z2\"+str(Z2.shape))\n",
    "        \n",
    "        Z2 = Z2[:, -1]\n",
    "        #print(\"Z2\"+str(Z2.shape))\n",
    "        \n",
    "        A3 = self.FC.forward(Z2)\n",
    "        #print(\"A3\"+str(A3.shape))\n",
    "        \n",
    "        Z3 = self.activation3.forward(A3)      \n",
    "        #print(\"Z3\"+str(Z3.shape))\n",
    "    \n",
    "        dA3, self.val_loss = self.activation3.backward(Z3, Y) \n",
    "        #print(\"dA3\"+str(dA3.shape))\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        self.sigma : ガウス分布の標準偏差\n",
    "        self.lr : 学習率\n",
    "        self.n_nodes1 : 1層目のノード数\n",
    "        self.n_nodes2 : 2層目のノード数\n",
    "        self.n_output : 出力層のノード数\n",
    "        \"\"\"\n",
    "        \n",
    "        # 最初に全ノードを生成\n",
    "        self.Conv1 = Conv1d(self.conv_initializer(self.sigma), self.optimizer(self.lr), N=20, FW=3, stride=3, pad=1)\n",
    "        \n",
    "        self.activation1 = self.activator1\n",
    "        \n",
    "        self.Conv2 = Conv1d(self.conv_initializer(self.sigma), self.optimizer(self.lr), N=20, FW=3, stride=3, pad=1)\n",
    "        \n",
    "        self.activation2 = self.activator2\n",
    "        \n",
    "        self.FC = FC(self.n_features, self.n_output, self.fc_initializer(self.sigma), self.optimizer(self.lr))\n",
    "        self.activation3 = Softmax()\n",
    "        \n",
    "        # 訓練データのミニバッチを生成\n",
    "        get_mini_batch_train = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
    "        \n",
    "        # 検証データのミニバッチを生成\n",
    "        get_mini_batch_val = GetMiniBatch(X_val, y_val, batch_size=self.batch_size)\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            \n",
    "            for mini_X_train, mini_y_train in get_mini_batch_train:\n",
    "                \n",
    "                # 順伝播・クロスエントロピー誤差・逆伝播\n",
    "                self.forward_and_backward(mini_X_train, mini_y_train)\n",
    "                \n",
    "            self.loss_hist.append(self.loss)\n",
    "            \n",
    "            # 検証\n",
    "            mini_X_val, mini_y_val = get_mini_batch_val[0]\n",
    "            self.forward_with_loss(mini_X_val, mini_y_val)\n",
    "            self.val_loss_hist.append(self.val_loss)\n",
    "        \n",
    "            \n",
    "            if self.verbose:\n",
    "\n",
    "                print('#'*25)\n",
    "                print('### Epoch %i'%(epoch+1))\n",
    "                print('#'*25)\n",
    "                \n",
    "                print(\"訓練データの損失 : {}\".format(self.loss))\n",
    "                print(\"検証データの損失 : {}\".format(self.val_loss))\n",
    "                \n",
    "                print()\n",
    "                \n",
    "                \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        \n",
    "        preds = []\n",
    "        \n",
    "        for i in range(int(X.shape[0] // self.batch_size)):\n",
    "        \n",
    "       \n",
    "            X_batch = X[i*self.batch_size : i*self.batch_size + self.batch_size]     \n",
    "        \n",
    "            X_batch = X_batch[:, np.newaxis, :]\n",
    "\n",
    "            A1 = self.Conv1.conv_forward(X_batch)\n",
    "            #print(\"A1\"+str(A1.shape))\n",
    "\n",
    "            Z1 = self.activation1.forward(A1)\n",
    "            #print(\"Z1\"+str(Z1.shape))\n",
    "\n",
    "            A2 = self.Conv2.conv_forward(Z1)\n",
    "            #print(\"A2\"+str(A2.shape))\n",
    "\n",
    "            Z2 = self.activation2.forward(A2)\n",
    "            #print(\"Z2\"+str(Z2.shape))\n",
    "\n",
    "            Z2 = Z2[:, -1]\n",
    "            #print(\"Z2\"+str(Z2.shape))\n",
    "\n",
    "            A3 = self.FC.forward(Z2)\n",
    "            #print(\"A3\"+str(A3.shape))\n",
    "\n",
    "            Z3 = self.activation3.forward(A3)\n",
    "            #print(\"Z3\"+str(Z3.shape))\n",
    "\n",
    "            pred = Z3.argmax(axis=1)\n",
    "\n",
    "            preds.append(pred)\n",
    "            \n",
    "        out = np.array(preds)\n",
    "        out = out.ravel()\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = ScratchConvolutionalNeuralNetrowkClassifier(fc_initializer=HeInitializer,\n",
    "                                                  conv_initializer=ConvInitializer,\n",
    "                                                  optimizer = AdaGrad,\n",
    "                                                  lr=1e-4,\n",
    "                                                  sigma=0.1, \n",
    "                                                  activator1=ReLU(),\n",
    "                                                  activator2=ReLU(),\n",
    "                                                  n_epochs=20,\n",
    "                                                  verbose = True\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Epoch 1\n",
      "#########################\n",
      "訓練データの損失 : 7.991261578490051\n",
      "検証データの損失 : 6.476156223491832\n",
      "\n",
      "#########################\n",
      "### Epoch 2\n",
      "#########################\n",
      "訓練データの損失 : 7.587401455372442\n",
      "検証データの損失 : 5.838422538469379\n",
      "\n",
      "#########################\n",
      "### Epoch 3\n",
      "#########################\n",
      "訓練データの損失 : 6.892581230477594\n",
      "検証データの損失 : 5.377587860477381\n",
      "\n",
      "#########################\n",
      "### Epoch 4\n",
      "#########################\n",
      "訓練データの損失 : 6.461883842080425\n",
      "検証データの損失 : 4.8956526945189465\n",
      "\n",
      "#########################\n",
      "### Epoch 5\n",
      "#########################\n",
      "訓練データの損失 : 5.530525066631119\n",
      "検証データの損失 : 4.3678804999491465\n",
      "\n",
      "#########################\n",
      "### Epoch 6\n",
      "#########################\n",
      "訓練データの損失 : 4.975883789704128\n",
      "検証データの損失 : 4.172090510210234\n",
      "\n",
      "#########################\n",
      "### Epoch 7\n",
      "#########################\n",
      "訓練データの損失 : 4.789682403733623\n",
      "検証データの損失 : 4.089806427981912\n",
      "\n",
      "#########################\n",
      "### Epoch 8\n",
      "#########################\n",
      "訓練データの損失 : 4.62531051261322\n",
      "検証データの損失 : 3.995539625580281\n",
      "\n",
      "#########################\n",
      "### Epoch 9\n",
      "#########################\n",
      "訓練データの損失 : 4.472821161785079\n",
      "検証データの損失 : 3.9070862740343726\n",
      "\n",
      "#########################\n",
      "### Epoch 10\n",
      "#########################\n",
      "訓練データの損失 : 4.332477868420276\n",
      "検証データの損失 : 3.8266105459289497\n",
      "\n",
      "#########################\n",
      "### Epoch 11\n",
      "#########################\n",
      "訓練データの損失 : 4.212422442216229\n",
      "検証データの損失 : 3.76130149975166\n",
      "\n",
      "#########################\n",
      "### Epoch 12\n",
      "#########################\n",
      "訓練データの損失 : 4.154156083432357\n",
      "検証データの損失 : 3.736707822426337\n",
      "\n",
      "#########################\n",
      "### Epoch 13\n",
      "#########################\n",
      "訓練データの損失 : 4.155606775305276\n",
      "検証データの損失 : 3.7360655391253026\n",
      "\n",
      "#########################\n",
      "### Epoch 14\n",
      "#########################\n",
      "訓練データの損失 : 4.149508569004107\n",
      "検証データの損失 : 3.725419216094963\n",
      "\n",
      "#########################\n",
      "### Epoch 15\n",
      "#########################\n",
      "訓練データの損失 : 4.1428941708159615\n",
      "検証データの損失 : 3.7166934462547836\n",
      "\n",
      "#########################\n",
      "### Epoch 16\n",
      "#########################\n",
      "訓練データの損失 : 4.1367028842017355\n",
      "検証データの損失 : 3.7084058312094483\n",
      "\n",
      "#########################\n",
      "### Epoch 17\n",
      "#########################\n",
      "訓練データの損失 : 4.13084237939529\n",
      "検証データの損失 : 3.698447342282461\n",
      "\n",
      "#########################\n",
      "### Epoch 18\n",
      "#########################\n",
      "訓練データの損失 : 4.125248697873677\n",
      "検証データの損失 : 3.684040683706354\n",
      "\n",
      "#########################\n",
      "### Epoch 19\n",
      "#########################\n",
      "訓練データの損失 : 4.119885643696664\n",
      "検証データの損失 : 3.6619599753652876\n",
      "\n",
      "#########################\n",
      "### Epoch 20\n",
      "#########################\n",
      "訓練データの損失 : 4.114731360752151\n",
      "検証データの損失 : 3.630711446786774\n",
      "\n",
      "CPU times: user 1h 39min 39s, sys: 12.8 s, total: 1h 39min 52s\n",
      "Wall time: 1h 39min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cnn.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, array([7, 7, 3, ..., 3, 7, 7]))"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "len(y_pred), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, array([7, 2, 1, ..., 4, 5, 6], dtype=uint8))"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0998"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
