{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】コードレビュー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 前回使用した実装とはどのように違うのか\n",
    "  +  前回はゼロから学習を行なっていたが、今回はImagenetで学習済みのモデルを使用している\n",
    "  \n",
    "* 転移学習をどのように行っているか  \n",
    "  + base_model の ResNet50 の最後のFC層を切り離し、今回の予測問題に合った出力を出すものに付け替えている\n",
    "  + base_model の ResNet50 を、U-Net の Encoder-Decoder 構造（スキップ結合付き）にカスタマイズしている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】コードの書き換え"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /Users/teruitakahiro/opt/anaconda3/envs/data_science:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_tflow_select             2.3.0                       mkl  \r\n",
      "absl-py                   0.12.0           py37hecd8cb5_0  \r\n",
      "albumentations            0.5.2                    pypi_0    pypi\r\n",
      "appnope                   0.1.0                    pypi_0    pypi\r\n",
      "argon2-cffi               20.1.0           py37h9ed2024_1  \r\n",
      "astor                     0.8.1                    pypi_0    pypi\r\n",
      "async_generator           1.10             py37h28b3542_0  \r\n",
      "attrs                     20.2.0                   pypi_0    pypi\r\n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \r\n",
      "blas                      1.0                         mkl  \r\n",
      "bleach                    3.2.1                    pypi_0    pypi\r\n",
      "c-ares                    1.17.1               h9ed2024_0  \r\n",
      "ca-certificates           2021.1.19            hecd8cb5_1  \r\n",
      "cached-property           1.5.2                    pypi_0    pypi\r\n",
      "certifi                   2020.12.5        py37hecd8cb5_0  \r\n",
      "cffi                      1.14.3                   pypi_0    pypi\r\n",
      "cloudpickle               1.6.0                      py_0  \r\n",
      "cycler                    0.10.0                     py_2    conda-forge\r\n",
      "cytoolz                   0.11.0           py37haf1e3a3_0  \r\n",
      "dask-core                 2021.3.0           pyhd3eb1b0_0  \r\n",
      "decorator                 4.4.2              pyhd3eb1b0_0  \r\n",
      "defusedxml                0.6.0                    pypi_0    pypi\r\n",
      "emoji                     0.6.0                    pypi_0    pypi\r\n",
      "entrypoints               0.3                      pypi_0    pypi\r\n",
      "freetype                  2.10.4               h4cff582_1    conda-forge\r\n",
      "gast                      0.4.0                      py_0  \r\n",
      "google-pasta              0.2.0                    pypi_0    pypi\r\n",
      "grpcio                    1.36.1                   pypi_0    pypi\r\n",
      "h5py                      3.2.1                    pypi_0    pypi\r\n",
      "hdf5                      1.10.6               hdbbcd12_0  \r\n",
      "imageio                   2.9.0                      py_0  \r\n",
      "imgaug                    0.4.0                    pypi_0    pypi\r\n",
      "importlib-metadata        2.0.0                      py_1  \r\n",
      "importlib_metadata        2.0.0                         1  \r\n",
      "intel-openmp              2019.4                      233  \r\n",
      "ipykernel                 5.3.4            py37h5ca1d4c_0  \r\n",
      "ipython                   7.19.0                   pypi_0    pypi\r\n",
      "ipython_genutils          0.2.0              pyhd3eb1b0_1  \r\n",
      "ipywidgets                7.5.1                    pypi_0    pypi\r\n",
      "jctconv                   0.1.2                    pypi_0    pypi\r\n",
      "jedi                      0.17.2           py37hecd8cb5_1  \r\n",
      "jinja2                    2.11.2                   pypi_0    pypi\r\n",
      "joblib                    0.17.0                   pypi_0    pypi\r\n",
      "jpeg                      9d                   hbcb3906_0    conda-forge\r\n",
      "jsonschema                3.2.0                      py_2  \r\n",
      "jupyter                   1.0.0                    pypi_0    pypi\r\n",
      "jupyter-console           6.2.0                    pypi_0    pypi\r\n",
      "jupyter-core              4.6.3                    pypi_0    pypi\r\n",
      "jupyter_client            6.1.7                      py_0  \r\n",
      "jupyter_core              4.7.1            py37hecd8cb5_0  \r\n",
      "jupyterlab_pygments       0.1.2                      py_0  \r\n",
      "keras                     2.2.4                         0  \r\n",
      "keras-applications        1.0.8                      py_1  \r\n",
      "keras-base                2.2.4                    py37_0  \r\n",
      "keras-preprocessing       1.1.2              pyhd3eb1b0_0  \r\n",
      "kiwisolver                1.3.1            py37h23ab428_0  \r\n",
      "lcms2                     2.12                 h577c468_0    conda-forge\r\n",
      "libcxx                    10.0.0                        1  \r\n",
      "libedit                   3.1.20191231         h1de35cc_1  \r\n",
      "libffi                    3.2.1             h0a44026_1007  \r\n",
      "libgfortran               3.0.1                h93005f0_2  \r\n",
      "libpng                    1.6.37               h7cec526_2    conda-forge\r\n",
      "libprotobuf               3.14.0               h2842e9f_0  \r\n",
      "libsodium                 1.0.18               h1de35cc_0  \r\n",
      "libtiff                   4.2.0                h9da4c3f_0  \r\n",
      "libwebp-base              1.2.0                hbcf498f_0    conda-forge\r\n",
      "llvm-openmp               11.0.1               h7c73e74_0    conda-forge\r\n",
      "lz4-c                     1.9.2                h4a8c4bd_1    conda-forge\r\n",
      "markdown                  3.3.4            py37hecd8cb5_0  \r\n",
      "markupsafe                1.1.1            py37h1de35cc_0  \r\n",
      "matplotlib                3.3.4            py37hf985489_0    conda-forge\r\n",
      "matplotlib-base           3.3.4            py37h8b3ea08_0  \r\n",
      "mistune                   0.8.4            py37h1de35cc_0  \r\n",
      "mkl                       2019.4                      233  \r\n",
      "mkl-service               2.3.0            py37h9ed2024_0  \r\n",
      "mkl_fft                   1.3.0            py37ha059aab_0  \r\n",
      "mkl_random                1.1.1            py37h959d312_0  \r\n",
      "mock                      4.0.3                    pypi_0    pypi\r\n",
      "nbclient                  0.5.1                    pypi_0    pypi\r\n",
      "nbconvert                 6.0.7                    py37_0  \r\n",
      "nbformat                  5.0.8                    pypi_0    pypi\r\n",
      "ncurses                   6.2                  h0a44026_1  \r\n",
      "nest-asyncio              1.4.2                    pypi_0    pypi\r\n",
      "networkx                  2.5                        py_0  \r\n",
      "notebook                  6.1.4                    pypi_0    pypi\r\n",
      "numpy                     1.19.3                   pypi_0    pypi\r\n",
      "numpy-base                1.19.2           py37hcfb5961_0  \r\n",
      "olefile                   0.46               pyh9f0ad1d_1    conda-forge\r\n",
      "opencv-python             4.5.1.48                 pypi_0    pypi\r\n",
      "opencv-python-headless    4.5.1.48                 pypi_0    pypi\r\n",
      "openssl                   1.0.2u               h1de35cc_0  \r\n",
      "packaging                 20.4                     pypi_0    pypi\r\n",
      "pandas                    1.1.4                    pypi_0    pypi\r\n",
      "pandoc                    2.11                 h0dc7051_0  \r\n",
      "pandocfilters             1.4.3            py37hecd8cb5_1  \r\n",
      "parso                     0.7.1                    pypi_0    pypi\r\n",
      "pexpect                   4.8.0              pyhd3eb1b0_3  \r\n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \r\n",
      "pillow                    8.1.2            py37hd4e48bc_0    conda-forge\r\n",
      "pip                       20.2.4                   py37_0  \r\n",
      "prometheus-client         0.8.0                    pypi_0    pypi\r\n",
      "prometheus_client         0.9.0              pyhd3eb1b0_0  \r\n",
      "prompt-toolkit            3.0.8                      py_0  \r\n",
      "protobuf                  3.15.6                   pypi_0    pypi\r\n",
      "ptyprocess                0.6.0                    pypi_0    pypi\r\n",
      "pycparser                 2.20                       py_2  \r\n",
      "pygments                  2.7.2                    pypi_0    pypi\r\n",
      "pyparsing                 2.4.7              pyhd3eb1b0_0  \r\n",
      "pyrsistent                0.17.3           py37haf1e3a3_0  \r\n",
      "python                    3.7.0                hc167b69_0  \r\n",
      "python-dateutil           2.8.1              pyhd3eb1b0_0  \r\n",
      "python_abi                3.7                     1_cp37m    conda-forge\r\n",
      "pytz                      2020.1                   pypi_0    pypi\r\n",
      "pywavelets                1.1.1            py37haf1e3a3_2  \r\n",
      "pyyaml                    5.4.1                    pypi_0    pypi\r\n",
      "pyzmq                     19.0.2                   pypi_0    pypi\r\n",
      "qtconsole                 4.7.7                    pypi_0    pypi\r\n",
      "qtpy                      1.9.0                    pypi_0    pypi\r\n",
      "readline                  7.0                  h1de35cc_5  \r\n",
      "scikit-image              0.18.1                   pypi_0    pypi\r\n",
      "scikit-learn              0.23.2                   pypi_0    pypi\r\n",
      "scipy                     1.5.3                    pypi_0    pypi\r\n",
      "seaborn                   0.11.1             pyhd3eb1b0_0  \r\n",
      "send2trash                1.5.0              pyhd3eb1b0_1  \r\n",
      "setuptools                50.3.0           py37h0dc7051_1  \r\n",
      "shapely                   1.7.1                    pypi_0    pypi\r\n",
      "six                       1.15.0           py37hecd8cb5_0  \r\n",
      "sklearn                   0.0                      pypi_0    pypi\r\n",
      "sqlite                    3.33.0               hffcf06c_0  \r\n",
      "tensorboard               1.12.2                   pypi_0    pypi\r\n",
      "tensorflow                1.13.0rc1                pypi_0    pypi\r\n",
      "tensorflow-base           1.14.0          mkl_py37h5a24fda_0  \r\n",
      "tensorflow-estimator      1.13.0                   pypi_0    pypi\r\n",
      "termcolor                 1.1.0                    pypi_0    pypi\r\n",
      "terminado                 0.9.1                    pypi_0    pypi\r\n",
      "testpath                  0.4.4              pyhd3eb1b0_0  \r\n",
      "threadpoolctl             2.1.0                    pypi_0    pypi\r\n",
      "tifffile                  2021.3.17                pypi_0    pypi\r\n",
      "tk                        8.6.10               hb0a8c7a_0  \r\n",
      "toolz                     0.11.1             pyhd3eb1b0_0  \r\n",
      "torch                     1.8.1                    pypi_0    pypi\r\n",
      "tornado                   6.1              py37h9ed2024_0  \r\n",
      "tqdm                      4.59.0             pyhd3eb1b0_1  \r\n",
      "traitlets                 5.0.5              pyhd3eb1b0_0  \r\n",
      "typing-extensions         3.7.4.3                  pypi_0    pypi\r\n",
      "vision-transformer-pytorch 1.0.3                    pypi_0    pypi\r\n",
      "wcwidth                   0.2.5                      py_0  \r\n",
      "webencodings              0.5.1                    pypi_0    pypi\r\n",
      "werkzeug                  1.0.1              pyhd3eb1b0_0  \r\n",
      "wheel                     0.35.1                     py_0  \r\n",
      "widgetsnbextension        3.5.1                    pypi_0    pypi\r\n",
      "wrapt                     1.12.1           py37h1de35cc_1  \r\n",
      "xz                        5.2.5                h1de35cc_0  \r\n",
      "yaml                      0.2.5                haf1e3a3_0  \r\n",
      "zeromq                    4.3.3                hb1e8313_3  \r\n",
      "zipp                      3.4.0              pyhd3eb1b0_0  \r\n",
      "zlib                      1.2.11               h1de35cc_3  \r\n",
      "zstd                      1.4.5                h41d2c2f_0  \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "#plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/teruitakahiro/dive/diveintocode-ml/Sprint20'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./tgs-salt-identification-challenge/train.csv')\n",
    "test = pd.read_csv('./tgs-salt-identification-challenge/sample_submission.csv')\n",
    "depth = pd.read_csv('./tgs-salt-identification-challenge/depths.csv')\n",
    "\n",
    "train_src = './tgs-salt-identification-challenge/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "                                    [cv2.imread('./tgs-salt-identification-challenge/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "                                    dtype=np.uint8) / 255.\n",
    "\n",
    "y_train = np.asarray(\n",
    "                                    [cv2.imread('./tgs-salt-identification-challenge/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "                                    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1080d0c88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        \n",
    "        def treat_image(log_lab):\n",
    "            \n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        \n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "        \n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        \n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                           lambda: tf.reduce_sum(logits) * 0.,\n",
    "                           compute_loss,\n",
    "                           strict=True,\n",
    "                           name=\"loss\"\n",
    "                           )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    \n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    \n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    \n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    \n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "\n",
    "def decoder_block_simple(\n",
    "                                                layer_name, block_name,\n",
    "                                                num_filters=32,\n",
    "                                                conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "                                    num_filters, conv_dim,\n",
    "                                    padding='same',\n",
    "                                    name='{}_conv'.format(block_name))(layer_name)\n",
    "    \n",
    "    x_dec = BatchNormalization(\n",
    "                                                        name='{}_bn'.format(block_name))(x_dec)\n",
    "    \n",
    "    x_dec = PReLU(\n",
    "                                name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "                                                        layer_name, block_name,\n",
    "                                                        num_filters=32,\n",
    "                                                        conv_dim=(3, 3),\n",
    "                                                        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "                                    num_filters, conv_dim,\n",
    "                                    padding='same',\n",
    "                                    name='{}_conv1'.format(block_name))(layer_name)\n",
    "    \n",
    "    x_dec = BatchNormalization(\n",
    "                                                        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    \n",
    "    x_dec = PReLU(\n",
    "                                name='{}_activation1'.format(block_name))(x_dec)\n",
    "    \n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "                                    num_filters // 2, conv_dim,\n",
    "                                    padding='same',\n",
    "                                    name='{}_conv2'.format(block_name))(x_dec)\n",
    "    \n",
    "    x_dec2 = BatchNormalization(\n",
    "                                                        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    \n",
    "    x_dec2 = PReLU(\n",
    "                                  name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    \n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "                                    num_filters, conv_dim,\n",
    "                                    padding='same',\n",
    "                                    name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    \n",
    "    x_dec2 = BatchNormalization(\n",
    "                                                        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    \n",
    "    x_dec2 = PReLU(\n",
    "                                  name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    \n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG書きかえ版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "\n",
    "#def unet_resnet(input_size, decoder_block,\n",
    "def unet_vgg19(input_size, decoder_block,\n",
    "                             weights='imagenet',\n",
    "                             loss_func='binary_crossentropy',\n",
    "                             metrics_list=[my_iou_metric],\n",
    "                             use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "#    base_model = ResNet50(\n",
    "#                                                input_shape=input_size, \n",
    "#                                                include_top=False,\n",
    "#                                                weights=weights)\n",
    "    \n",
    "    base_model = VGG19(\n",
    "                                            input_shape=input_size, \n",
    "                                            include_top=False,\n",
    "                                            weights=weights)\n",
    "    \n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "#    encoder1 = base_model.get_layer('activation_1').output\n",
    "#    encoder2 = base_model.get_layer('activation_10').output\n",
    "#    encoder3 = base_model.get_layer('activation_22').output\n",
    "#    encoder4 = base_model.get_layer('activation_40').output\n",
    "#    encoder5 = base_model.get_layer('activation_49').output\n",
    "    \n",
    "    # VGG19 用\n",
    "    encoder1 = base_model.get_layer('block1_pool').output\n",
    "    encoder2 = base_model.get_layer('block2_pool').output\n",
    "    encoder3 = base_model.get_layer('block3_pool').output\n",
    "    encoder4 = base_model.get_layer('block4_pool').output\n",
    "    encoder5 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "                                                encoder5, 'center', num_filters=512)\n",
    "    \n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG19\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From <ipython-input-11-f24ac26d6fd8>:172: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,920,897\n",
      "Trainable params: 27,918,785\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# unet_vgg19\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg19(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 33,987,185\n",
      "Trainable params: 33,981,905\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/2\n",
      "3200/3200 [==============================] - 14976s 5s/step - loss: 0.8268 - my_iou_metric: 0.2090 - val_loss: 0.9828 - val_my_iou_metric: 0.3935\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.39350, saving model to unet_resnet.h5\n",
      "Epoch 2/2\n",
      "3200/3200 [==============================] - 14250s 4s/step - loss: 0.6711 - my_iou_metric: 0.3549 - val_loss: 0.6804 - val_my_iou_metric: 0.4634\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.39350 to 0.46338, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "\n",
    "model_depth = unet_vgg19(\n",
    "                                                    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "                                                    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "                                                    use_lovash=False)\n",
    "\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "                                                                    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "                                                                    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "                                                        monitor='val_my_iou_metric',\n",
    "                                                        mode='max',\n",
    "                                                        factor=0.5, \n",
    "                                                        patience=5, \n",
    "                                                        min_lr=0.0001, \n",
    "                                                        verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                                            validation_data=[X_val, y_val], \n",
    "                                            epochs=epochs,\n",
    "                                            batch_size=batch_size,\n",
    "                                            callbacks=[model_checkpoint,reduce_lr], \n",
    "                                            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:04<00:00,  1.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5024 at threshold: 0.660\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.477114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.031476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.377500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.491250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.496625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.502375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.477114\n",
       "std     0.204939   0.031476\n",
       "min     0.200000   0.377500\n",
       "25%     0.370000   0.470000\n",
       "50%     0.540000   0.491250\n",
       "75%     0.710000   0.496625\n",
       "max     0.880000   0.502375"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='threshold'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66465"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                             weights='imagenet',\n",
    "                             loss_func='binary_crossentropy',\n",
    "                             metrics_list=[my_iou_metric],\n",
    "                             use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = ResNet50(\n",
    "                                                input_shape=input_size, \n",
    "                                                include_top=False,\n",
    "                                                weights=weights)\n",
    "    \n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n",
    "    \n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "                                                encoder5, 'center', num_filters=512)\n",
    "    \n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ResNet50\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,912,065\n",
      "Trainable params: 42,856,833\n",
      "Non-trainable params: 55,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# unet_resnet\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,978,353\n",
      "Trainable params: 48,919,953\n",
      "Non-trainable params: 58,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/2\n",
      "3200/3200 [==============================] - 10396s 3s/step - loss: 0.7104 - my_iou_metric: 0.2439 - val_loss: 2.3455 - val_my_iou_metric: 0.1829\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.18288, saving model to unet_resnet.h5\n",
      "Epoch 2/2\n",
      "3200/3200 [==============================] - 12186s 4s/step - loss: 0.5455 - my_iou_metric: 0.3568 - val_loss: 3.2050 - val_my_iou_metric: 0.2185\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.18288 to 0.21850, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "\n",
    "model_depth = unet_resnet(\n",
    "                                                    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "                                                    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "                                                    use_lovash=False)\n",
    "\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "                                                                    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "                                                                    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "                                                        monitor='val_my_iou_metric',\n",
    "                                                        mode='max',\n",
    "                                                        factor=0.5, \n",
    "                                                        patience=5, \n",
    "                                                        min_lr=0.0001, \n",
    "                                                        verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                                            validation_data=[X_val, y_val], \n",
    "                                            epochs=epochs,\n",
    "                                            batch_size=batch_size,\n",
    "                                            callbacks=[model_checkpoint,reduce_lr], \n",
    "                                            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [01:16<00:00,  2.19s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.3400 at threshold: 0.880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.324946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.005672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.317375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.321688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.322875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.328437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.324946\n",
       "std     0.204939   0.005672\n",
       "min     0.200000   0.317375\n",
       "25%     0.370000   0.321688\n",
       "50%     0.540000   0.322875\n",
       "75%     0.710000   0.328437\n",
       "max     0.880000   0.340000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='threshold'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* unet_vgg19 の方が IoU が高く出た"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
