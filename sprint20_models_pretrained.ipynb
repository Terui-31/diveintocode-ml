{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】コードレビュー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /Users/teruitakahiro/opt/anaconda3/envs/data_science:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_tflow_select             2.3.0                       mkl  \r\n",
      "absl-py                   0.12.0           py37hecd8cb5_0  \r\n",
      "albumentations            0.5.2                    pypi_0    pypi\r\n",
      "appnope                   0.1.0                    pypi_0    pypi\r\n",
      "argon2-cffi               20.1.0           py37h9ed2024_1  \r\n",
      "astor                     0.8.1                    pypi_0    pypi\r\n",
      "async_generator           1.10             py37h28b3542_0  \r\n",
      "attrs                     20.2.0                   pypi_0    pypi\r\n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \r\n",
      "blas                      1.0                         mkl  \r\n",
      "bleach                    3.2.1                    pypi_0    pypi\r\n",
      "c-ares                    1.17.1               h9ed2024_0  \r\n",
      "ca-certificates           2021.1.19            hecd8cb5_1  \r\n",
      "cached-property           1.5.2                    pypi_0    pypi\r\n",
      "certifi                   2020.12.5        py37hecd8cb5_0  \r\n",
      "cffi                      1.14.3                   pypi_0    pypi\r\n",
      "cloudpickle               1.6.0                      py_0  \r\n",
      "cycler                    0.10.0                     py_2    conda-forge\r\n",
      "cytoolz                   0.11.0           py37haf1e3a3_0  \r\n",
      "dask-core                 2021.3.0           pyhd3eb1b0_0  \r\n",
      "decorator                 4.4.2              pyhd3eb1b0_0  \r\n",
      "defusedxml                0.6.0                    pypi_0    pypi\r\n",
      "emoji                     0.6.0                    pypi_0    pypi\r\n",
      "entrypoints               0.3                      pypi_0    pypi\r\n",
      "freetype                  2.10.4               h4cff582_1    conda-forge\r\n",
      "gast                      0.4.0                      py_0  \r\n",
      "grpcio                    1.36.1                   pypi_0    pypi\r\n",
      "h5py                      3.2.1                    pypi_0    pypi\r\n",
      "hdf5                      1.10.6               hdbbcd12_0  \r\n",
      "imageio                   2.9.0                      py_0  \r\n",
      "imgaug                    0.4.0                    pypi_0    pypi\r\n",
      "importlib-metadata        2.0.0                      py_1  \r\n",
      "importlib_metadata        2.0.0                         1  \r\n",
      "intel-openmp              2019.4                      233  \r\n",
      "ipykernel                 5.3.4            py37h5ca1d4c_0  \r\n",
      "ipython                   7.19.0                   pypi_0    pypi\r\n",
      "ipython_genutils          0.2.0              pyhd3eb1b0_1  \r\n",
      "ipywidgets                7.5.1                    pypi_0    pypi\r\n",
      "jctconv                   0.1.2                    pypi_0    pypi\r\n",
      "jedi                      0.17.2           py37hecd8cb5_1  \r\n",
      "jinja2                    2.11.2                   pypi_0    pypi\r\n",
      "joblib                    0.17.0                   pypi_0    pypi\r\n",
      "jpeg                      9d                   hbcb3906_0    conda-forge\r\n",
      "jsonschema                3.2.0                      py_2  \r\n",
      "jupyter                   1.0.0                    pypi_0    pypi\r\n",
      "jupyter-console           6.2.0                    pypi_0    pypi\r\n",
      "jupyter-core              4.6.3                    pypi_0    pypi\r\n",
      "jupyter_client            6.1.7                      py_0  \r\n",
      "jupyter_core              4.7.1            py37hecd8cb5_0  \r\n",
      "jupyterlab_pygments       0.1.2                      py_0  \r\n",
      "keras                     2.2.4                         0  \r\n",
      "keras-applications        1.0.8                      py_1  \r\n",
      "keras-base                2.2.4                    py37_0  \r\n",
      "keras-preprocessing       1.1.2              pyhd3eb1b0_0  \r\n",
      "kiwisolver                1.3.1            py37h23ab428_0  \r\n",
      "lcms2                     2.12                 h577c468_0    conda-forge\r\n",
      "libcxx                    10.0.0                        1  \r\n",
      "libedit                   3.1.20191231         h1de35cc_1  \r\n",
      "libffi                    3.2.1             h0a44026_1007  \r\n",
      "libgfortran               3.0.1                h93005f0_2  \r\n",
      "libpng                    1.6.37               h7cec526_2    conda-forge\r\n",
      "libprotobuf               3.14.0               h2842e9f_0  \r\n",
      "libsodium                 1.0.18               h1de35cc_0  \r\n",
      "libtiff                   4.2.0                h9da4c3f_0  \r\n",
      "libwebp-base              1.2.0                hbcf498f_0    conda-forge\r\n",
      "llvm-openmp               11.0.1               h7c73e74_0    conda-forge\r\n",
      "lz4-c                     1.9.2                h4a8c4bd_1    conda-forge\r\n",
      "markdown                  3.3.4            py37hecd8cb5_0  \r\n",
      "markupsafe                1.1.1            py37h1de35cc_0  \r\n",
      "matplotlib                3.3.4            py37hf985489_0    conda-forge\r\n",
      "matplotlib-base           3.3.4            py37h8b3ea08_0  \r\n",
      "mistune                   0.8.4            py37h1de35cc_0  \r\n",
      "mkl                       2019.4                      233  \r\n",
      "mkl-service               2.3.0            py37h9ed2024_0  \r\n",
      "mkl_fft                   1.3.0            py37ha059aab_0  \r\n",
      "mkl_random                1.1.1            py37h959d312_0  \r\n",
      "mock                      4.0.3                    pypi_0    pypi\r\n",
      "nbclient                  0.5.1                    pypi_0    pypi\r\n",
      "nbconvert                 6.0.7                    py37_0  \r\n",
      "nbformat                  5.0.8                    pypi_0    pypi\r\n",
      "ncurses                   6.2                  h0a44026_1  \r\n",
      "nest-asyncio              1.4.2                    pypi_0    pypi\r\n",
      "networkx                  2.5                        py_0  \r\n",
      "notebook                  6.1.4                    pypi_0    pypi\r\n",
      "numpy                     1.19.3                   pypi_0    pypi\r\n",
      "numpy-base                1.19.2           py37hcfb5961_0  \r\n",
      "olefile                   0.46               pyh9f0ad1d_1    conda-forge\r\n",
      "opencv-python             4.5.1.48                 pypi_0    pypi\r\n",
      "opencv-python-headless    4.5.1.48                 pypi_0    pypi\r\n",
      "openssl                   1.0.2u               h1de35cc_0  \r\n",
      "packaging                 20.4                     pypi_0    pypi\r\n",
      "pandas                    1.1.4                    pypi_0    pypi\r\n",
      "pandoc                    2.11                 h0dc7051_0  \r\n",
      "pandocfilters             1.4.3            py37hecd8cb5_1  \r\n",
      "parso                     0.7.1                    pypi_0    pypi\r\n",
      "pexpect                   4.8.0              pyhd3eb1b0_3  \r\n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \r\n",
      "pillow                    8.1.2            py37hd4e48bc_0    conda-forge\r\n",
      "pip                       20.2.4                   py37_0  \r\n",
      "prometheus-client         0.8.0                    pypi_0    pypi\r\n",
      "prometheus_client         0.9.0              pyhd3eb1b0_0  \r\n",
      "prompt-toolkit            3.0.8                      py_0  \r\n",
      "protobuf                  3.15.6                   pypi_0    pypi\r\n",
      "ptyprocess                0.6.0                    pypi_0    pypi\r\n",
      "pycparser                 2.20                       py_2  \r\n",
      "pygments                  2.7.2                    pypi_0    pypi\r\n",
      "pyparsing                 2.4.7              pyhd3eb1b0_0  \r\n",
      "pyrsistent                0.17.3           py37haf1e3a3_0  \r\n",
      "python                    3.7.0                hc167b69_0  \r\n",
      "python-dateutil           2.8.1              pyhd3eb1b0_0  \r\n",
      "python_abi                3.7                     1_cp37m    conda-forge\r\n",
      "pytz                      2020.1                   pypi_0    pypi\r\n",
      "pywavelets                1.1.1            py37haf1e3a3_2  \r\n",
      "pyyaml                    5.4.1                    pypi_0    pypi\r\n",
      "pyzmq                     19.0.2                   pypi_0    pypi\r\n",
      "qtconsole                 4.7.7                    pypi_0    pypi\r\n",
      "qtpy                      1.9.0                    pypi_0    pypi\r\n",
      "readline                  7.0                  h1de35cc_5  \r\n",
      "scikit-image              0.18.1                   pypi_0    pypi\r\n",
      "scikit-learn              0.23.2                   pypi_0    pypi\r\n",
      "scipy                     1.5.3                    pypi_0    pypi\r\n",
      "seaborn                   0.11.1             pyhd3eb1b0_0  \r\n",
      "send2trash                1.5.0              pyhd3eb1b0_1  \r\n",
      "setuptools                50.3.0           py37h0dc7051_1  \r\n",
      "shapely                   1.7.1                    pypi_0    pypi\r\n",
      "six                       1.15.0           py37hecd8cb5_0  \r\n",
      "sklearn                   0.0                      pypi_0    pypi\r\n",
      "sqlite                    3.33.0               hffcf06c_0  \r\n",
      "tensorboard               1.12.2                   pypi_0    pypi\r\n",
      "tensorflow                1.13.0rc1                pypi_0    pypi\r\n",
      "tensorflow-base           1.14.0          mkl_py37h5a24fda_0  \r\n",
      "tensorflow-estimator      1.13.0                   pypi_0    pypi\r\n",
      "termcolor                 1.1.0                    pypi_0    pypi\r\n",
      "terminado                 0.9.1                    pypi_0    pypi\r\n",
      "testpath                  0.4.4              pyhd3eb1b0_0  \r\n",
      "threadpoolctl             2.1.0                    pypi_0    pypi\r\n",
      "tifffile                  2021.3.17                pypi_0    pypi\r\n",
      "tk                        8.6.10               hb0a8c7a_0  \r\n",
      "toolz                     0.11.1             pyhd3eb1b0_0  \r\n",
      "torch                     1.8.1                    pypi_0    pypi\r\n",
      "tornado                   6.1              py37h9ed2024_0  \r\n",
      "tqdm                      4.59.0             pyhd3eb1b0_1  \r\n",
      "traitlets                 5.0.5              pyhd3eb1b0_0  \r\n",
      "typing-extensions         3.7.4.3                  pypi_0    pypi\r\n",
      "vision-transformer-pytorch 1.0.3                    pypi_0    pypi\r\n",
      "wcwidth                   0.2.5                      py_0  \r\n",
      "webencodings              0.5.1                    pypi_0    pypi\r\n",
      "werkzeug                  1.0.1              pyhd3eb1b0_0  \r\n",
      "wheel                     0.35.1                     py_0  \r\n",
      "widgetsnbextension        3.5.1                    pypi_0    pypi\r\n",
      "wrapt                     1.12.1           py37h1de35cc_1  \r\n",
      "xz                        5.2.5                h1de35cc_0  \r\n",
      "yaml                      0.2.5                haf1e3a3_0  \r\n",
      "zeromq                    4.3.3                hb1e8313_3  \r\n",
      "zipp                      3.4.0              pyhd3eb1b0_0  \r\n",
      "zlib                      1.2.11               h1de35cc_3  \r\n",
      "zstd                      1.4.5                h41d2c2f_0  \r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "#plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/teruitakahiro/dive/diveintocode-ml/Sprint20'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./tgs-salt-identification-challenge/train.csv')\n",
    "test = pd.read_csv('./tgs-salt-identification-challenge/sample_submission.csv')\n",
    "depth = pd.read_csv('./tgs-salt-identification-challenge/depths.csv')\n",
    "\n",
    "train_src = './tgs-salt-identification-challenge/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "                                    [cv2.imread('./tgs-salt-identification-challenge/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "                                    dtype=np.uint8) / 255.\n",
    "\n",
    "y_train = np.asarray(\n",
    "                                    [cv2.imread('./tgs-salt-identification-challenge/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "                                    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x110bf3d30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 224, 224, 3) (3200, 224, 224, 1)\n",
      "(800, 224, 224, 3) (800, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    \n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        \n",
    "        def treat_image(log_lab):\n",
    "            \n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        \n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "        \n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        \n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                           lambda: tf.reduce_sum(logits) * 0.,\n",
    "                           compute_loss,\n",
    "                           strict=True,\n",
    "                           name=\"loss\"\n",
    "                           )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    \n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    \n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    \n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    \n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    \n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "\n",
    "def decoder_block_simple(\n",
    "                                                layer_name, block_name,\n",
    "                                                num_filters=32,\n",
    "                                                conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "                                    num_filters, conv_dim,\n",
    "                                    padding='same',\n",
    "                                    name='{}_conv'.format(block_name))(layer_name)\n",
    "    \n",
    "    x_dec = BatchNormalization(\n",
    "                                                        name='{}_bn'.format(block_name))(x_dec)\n",
    "    \n",
    "    x_dec = PReLU(\n",
    "                                name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "                                                        layer_name, block_name,\n",
    "                                                        num_filters=32,\n",
    "                                                        conv_dim=(3, 3),\n",
    "                                                        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "                                    num_filters, conv_dim,\n",
    "                                    padding='same',\n",
    "                                    name='{}_conv1'.format(block_name))(layer_name)\n",
    "    \n",
    "    x_dec = BatchNormalization(\n",
    "                                                        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    \n",
    "    x_dec = PReLU(\n",
    "                                name='{}_activation1'.format(block_name))(x_dec)\n",
    "    \n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "                                    num_filters // 2, conv_dim,\n",
    "                                    padding='same',\n",
    "                                    name='{}_conv2'.format(block_name))(x_dec)\n",
    "    \n",
    "    x_dec2 = BatchNormalization(\n",
    "                                                        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    \n",
    "    x_dec2 = PReLU(\n",
    "                                  name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    \n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "                                    num_filters, conv_dim,\n",
    "                                    padding='same',\n",
    "                                    name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    \n",
    "    x_dec2 = BatchNormalization(\n",
    "                                                        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    \n",
    "    x_dec2 = PReLU(\n",
    "                                  name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    \n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "\n",
    "#def unet_resnet(input_size, decoder_block,\n",
    "def unet_vgg19(input_size, decoder_block,\n",
    "                             weights='imagenet',\n",
    "                             loss_func='binary_crossentropy',\n",
    "                             metrics_list=[my_iou_metric],\n",
    "                             use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "#    base_model = ResNet50(\n",
    "#                                                input_shape=input_size, \n",
    "#                                                include_top=False,\n",
    "#                                                weights=weights)\n",
    "    \n",
    "    base_model = VGG19(\n",
    "                                            input_shape=input_size, \n",
    "                                            include_top=False,\n",
    "                                            weights=weights)\n",
    "    \n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "#    encoder1 = base_model.get_layer('activation_1').output\n",
    "#    encoder2 = base_model.get_layer('activation_10').output\n",
    "#    encoder3 = base_model.get_layer('activation_22').output\n",
    "#    encoder4 = base_model.get_layer('activation_40').output\n",
    "#    encoder5 = base_model.get_layer('activation_49').output\n",
    "    \n",
    "    # VGG19 用\n",
    "    encoder1 = base_model.get_layer('block1_pool').output\n",
    "    encoder2 = base_model.get_layer('block2_pool').output\n",
    "    encoder3 = base_model.get_layer('block3_pool').output\n",
    "    encoder4 = base_model.get_layer('block4_pool').output\n",
    "    encoder5 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "                                                encoder5, 'center', num_filters=512)\n",
    "    \n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# VGG19\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fc1000 (Dense)                  (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ResNet50\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unet_resnet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6aaa59a024f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m model = unet_resnet(\n\u001b[0m\u001b[1;32m      8\u001b[0m     input_size, decoder_block_simple, weights='imagenet')\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unet_resnet' is not defined"
     ]
    }
   ],
   "source": [
    "# unet_resnet\n",
    "#\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From <ipython-input-11-f24ac26d6fd8>:172: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,920,897\n",
      "Trainable params: 27,918,785\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# unet_vgg19\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg19(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 33,987,185\n",
      "Trainable params: 33,981,905\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/2\n",
      "3200/3200 [==============================] - 15124s 5s/step - loss: 1.0447 - my_iou_metric: 0.1498 - val_loss: 1.2713 - val_my_iou_metric: 0.1425\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.14250, saving model to unet_resnet.h5\n",
      "Epoch 2/2\n",
      "3200/3200 [==============================] - 14612s 5s/step - loss: 0.7927 - my_iou_metric: 0.2388 - val_loss: 2.7668 - val_my_iou_metric: 0.1700\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.14250 to 0.17000, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "\n",
    "model_depth = unet_vgg19(\n",
    "                                                    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "                                                    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "                                                    use_lovash=False)\n",
    "\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "                                                                    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "                                                                    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "                                                        monitor='val_my_iou_metric',\n",
    "                                                        mode='max',\n",
    "                                                        factor=0.5, \n",
    "                                                        patience=5, \n",
    "                                                        min_lr=0.0001, \n",
    "                                                        verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                                            validation_data=[X_val, y_val], \n",
    "                                            epochs=epochs,\n",
    "                                            batch_size=batch_size,\n",
    "                                            callbacks=[model_checkpoint,reduce_lr], \n",
    "                                            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
