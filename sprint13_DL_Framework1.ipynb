{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【TensorFlow1】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "環境：\n",
    "* Python 3.7.0\n",
    "* tensorflow==1.13.0rc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow概要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# 簡単な計算\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(5)\n",
    "b = tf.constant(7)\n",
    "add = tf.add(a, b)\n",
    "sess = tf.Session()\n",
    "output = sess.run(add)\n",
    "print(output) # 12\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# 簡単な計算：別解\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(5)\n",
    "b = tf.constant(7)\n",
    "add = tf.add(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    output = sess.run(add)\n",
    "    print(output) # 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# numpyで簡単な計算\n",
    "\n",
    "import numpy as np\n",
    "a_n = np.array(5)\n",
    "b_n = np.array(7)\n",
    "output_n = np.add(a_n, b_n)\n",
    "print(output_n) # 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データフローグラフ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフローグラフの構築\n",
    "\n",
    "a = tf.constant(5)\n",
    "b = tf.constant(7)\n",
    "add = tf.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_4:0\", shape=(), dtype=int32)\n",
      "Tensor(\"Add_2:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# エッジ（Tensor）の説明を返す\n",
    "\n",
    "print(a) # Tensor(\"Const:0\", shape=(), dtype=int32)\n",
    "print(add) # Tensor(\"Add:0\", shape=(), dtype=int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sessionオブジェクトの作成\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# sess.run()の中にエッジ（Tensor）を入れると出力が返る\n",
    "\n",
    "output = sess.run(add)\n",
    "print(output) # 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# placeholder\n",
    "\n",
    "c = tf.placeholder(tf.int32)\n",
    "d = tf.placeholder(tf.int32)\n",
    "add = tf.add(c, d)\n",
    "\n",
    "sess = tf.Session()\n",
    "output = sess.run(add, feed_dict={c:5, d:7})\n",
    "print(output) # 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "# feed_dictのに辞書型で値を与える\n",
    "\n",
    "output = sess.run(add, feed_dict={c:20, d:32})\n",
    "print(output) # 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_4:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "add = a + b # tf.add(a, b)に等しい\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add_5:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "add = tf.add(a, b) # tf.add(a, b)に等しい\n",
    "print(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# セッションの終了\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with を使うとセッションのインスタンス化から終了まで行える\n",
    "\n",
    "#with tf.Session() as sess:\n",
    "#    sess.run() # ここに計算の実行コードを入れていく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【TensorFlow2】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ロジスティック回帰の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データフローの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ作成\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x_train = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y_train = np.array([[0],[0],[0],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 2]) # [データ数、次元数]\n",
    "t = tf.placeholder(tf.float32, [None, 1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Variable=学習により更新を行う値\n",
    "\n",
    "W = tf.Variable(tf.zeros([2, 1]))\n",
    "b = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ロジスティック回帰 TensorFlow Ver.\n",
    "\n",
    "y = tf.sigmoid(tf.matmul(x, W) + b) # 仮定関数をシグモイドに通した予測値\n",
    "cross_entropy = tf.reduce_sum(-t * tf.log(y) - (1 - t) * tf.log(1 - y)) #Lossの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配降下法を用いてパラメータを最適化するためのコード\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.sign(y - 0.5), tf.sign(t - 0.5)) # tf.equal()は引数の２値が等しいかの判定、tf.sign()は引数が正=1, 0=0, 負=-1\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# セッションのインスタンスを作成\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Accuracy: 0.750000\n",
      "epoch: 100, Accuracy: 1.000000\n",
      "epoch: 200, Accuracy: 1.000000\n",
      "epoch: 300, Accuracy: 1.000000\n",
      "epoch: 400, Accuracy: 1.000000\n",
      "epoch: 500, Accuracy: 1.000000\n",
      "epoch: 600, Accuracy: 1.000000\n",
      "epoch: 700, Accuracy: 1.000000\n",
      "epoch: 800, Accuracy: 1.000000\n",
      "epoch: 900, Accuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "# 学習 （sess.run()）\n",
    "\n",
    "for epoch in range(1000):\n",
    "    sess.run(train_step, feed_dict={\n",
    "        x:x_train,\n",
    "        t:y_train\n",
    "    })\n",
    "# 100回ごとに正解率を表示\n",
    "    if epoch % 100 == 0:\n",
    "        acc_val = sess.run(\n",
    "            accuracy, feed_dict={\n",
    "                x:x_train,\n",
    "                t:y_train})\n",
    "        print ('epoch: %d, Accuracy: %f'\n",
    "               %(epoch, acc_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True]\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "[[1.9651403e-04]\n",
      " [4.9049813e-02]\n",
      " [4.9049813e-02]\n",
      " [9.3120378e-01]]\n"
     ]
    }
   ],
   "source": [
    "#学習結果が正しいか確認\n",
    "classified = sess.run(correct_prediction, feed_dict={\n",
    "    x:x_train,\n",
    "    t:y_train\n",
    "})\n",
    "\n",
    "#出力yの確認\n",
    "prob = sess.run(y, feed_dict={\n",
    "    x:x_train,\n",
    "    t:y_train\n",
    "})\n",
    "\n",
    "print(classified)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[5.569955]\n",
      " [5.569955]]\n",
      "b: [-8.53458]\n"
     ]
    }
   ],
   "source": [
    "# 学習後のパラメータの確認\n",
    "\n",
    "print('W:', sess.run(W))\n",
    "print('b:', sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.      ]\n",
      " [ 5.569955]\n",
      " [ 5.569955]\n",
      " [11.13991 ]]\n"
     ]
    }
   ],
   "source": [
    "# 途中経過を見る場合\n",
    "\n",
    "mat = tf.matmul(x, W)\n",
    "y = tf.sigmoid(mat + b)\n",
    "\n",
    "print(sess.run(mat, feed_dict={\n",
    "    x:x_train,\n",
    "    t:y_train\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# セッションの終了\n",
    "\n",
    "sess.close()\n",
    "\n",
    "# with構文\n",
    "#with tf.Session() as sess:\n",
    "#    sess.run() # ここに計算の実行コードを入れていく"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【ディープラーニングフレームワーク1】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】スクラッチを振り返る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ディープラーニングを実装するためにはどのようなものが必要だったかを列挙\n",
    "  + 各処理を複数のクラスに分けてコーディングすること\n",
    "    - 構成の主幹はレイヤークラスと、各処理を統合し実行するネットワーククラス\n",
    "  + モデルに投入する入力サンプルは、ミニバッチに小分けにして投入する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】スクラッチとTensorFlowの対応を考える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    \n",
    "    \n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# データセットの読み込み\n",
    "df = pd.read_csv(\"Iris.csv\")\n",
    "\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\") | (df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "\n",
    "# NumPy 配列に変換\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "y[y == \"Iris-versicolor\"] = 0\n",
    "y[y == \"Iris-virginica\"] = 1\n",
    "y = y.astype(np.int64)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 100\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_net(x):\n",
    "    \n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.random.set_random_seed(0)\n",
    "    \n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "                    'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "                    'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "                    'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "                    }\n",
    "    \n",
    "    biases = {\n",
    "                  'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "                  'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "                  'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "                  }\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    \n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X)\n",
    "\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
    "\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 1.1735, val_loss : 11.2989, acc : 0.750\n",
      "Epoch 1, loss : 1.2348, val_loss : 9.0602, acc : 0.500\n",
      "Epoch 2, loss : 0.8924, val_loss : 10.3118, acc : 0.250\n",
      "Epoch 3, loss : 0.7302, val_loss : 7.4508, acc : 0.500\n",
      "Epoch 4, loss : 0.5668, val_loss : 6.7762, acc : 0.562\n",
      "Epoch 5, loss : 0.5021, val_loss : 6.0707, acc : 0.500\n",
      "Epoch 6, loss : 0.4315, val_loss : 5.5546, acc : 0.500\n",
      "Epoch 7, loss : 0.3628, val_loss : 4.8130, acc : 0.625\n",
      "Epoch 8, loss : 0.3143, val_loss : 4.2993, acc : 0.625\n",
      "Epoch 9, loss : 0.2723, val_loss : 3.8846, acc : 0.688\n",
      "Epoch 10, loss : 0.2389, val_loss : 3.6803, acc : 0.750\n",
      "Epoch 11, loss : 0.2151, val_loss : 3.5043, acc : 0.750\n",
      "Epoch 12, loss : 0.1950, val_loss : 3.3435, acc : 0.750\n",
      "Epoch 13, loss : 0.1788, val_loss : 3.2810, acc : 0.750\n",
      "Epoch 14, loss : 0.1685, val_loss : 3.1950, acc : 0.750\n",
      "Epoch 15, loss : 0.1608, val_loss : 3.0991, acc : 0.750\n",
      "Epoch 16, loss : 0.1526, val_loss : 3.0605, acc : 0.750\n",
      "Epoch 17, loss : 0.1460, val_loss : 3.0014, acc : 0.750\n",
      "Epoch 18, loss : 0.1394, val_loss : 2.9606, acc : 0.750\n",
      "Epoch 19, loss : 0.1331, val_loss : 2.9330, acc : 0.750\n",
      "Epoch 20, loss : 0.1272, val_loss : 2.8978, acc : 0.750\n",
      "Epoch 21, loss : 0.1212, val_loss : 2.8657, acc : 0.750\n",
      "Epoch 22, loss : 0.1154, val_loss : 2.8360, acc : 0.750\n",
      "Epoch 23, loss : 0.1099, val_loss : 2.7959, acc : 0.750\n",
      "Epoch 24, loss : 0.1049, val_loss : 2.7426, acc : 0.750\n",
      "Epoch 25, loss : 0.1003, val_loss : 2.6772, acc : 0.750\n",
      "Epoch 26, loss : 0.0960, val_loss : 2.6030, acc : 0.750\n",
      "Epoch 27, loss : 0.0919, val_loss : 2.5264, acc : 0.750\n",
      "Epoch 28, loss : 0.0880, val_loss : 2.4556, acc : 0.750\n",
      "Epoch 29, loss : 0.0843, val_loss : 2.3924, acc : 0.750\n",
      "Epoch 30, loss : 0.0807, val_loss : 2.3359, acc : 0.750\n",
      "Epoch 31, loss : 0.0771, val_loss : 2.2847, acc : 0.750\n",
      "Epoch 32, loss : 0.0736, val_loss : 2.2381, acc : 0.750\n",
      "Epoch 33, loss : 0.0701, val_loss : 2.1948, acc : 0.750\n",
      "Epoch 34, loss : 0.0668, val_loss : 2.1501, acc : 0.750\n",
      "Epoch 35, loss : 0.0635, val_loss : 2.1038, acc : 0.750\n",
      "Epoch 36, loss : 0.0604, val_loss : 2.0583, acc : 0.750\n",
      "Epoch 37, loss : 0.0574, val_loss : 2.0176, acc : 0.750\n",
      "Epoch 38, loss : 0.0546, val_loss : 1.9790, acc : 0.750\n",
      "Epoch 39, loss : 0.0519, val_loss : 1.9404, acc : 0.812\n",
      "Epoch 40, loss : 0.0494, val_loss : 1.9024, acc : 0.812\n",
      "Epoch 41, loss : 0.0471, val_loss : 1.8680, acc : 0.812\n",
      "Epoch 42, loss : 0.0449, val_loss : 1.8341, acc : 0.812\n",
      "Epoch 43, loss : 0.0428, val_loss : 1.8024, acc : 0.812\n",
      "Epoch 44, loss : 0.0409, val_loss : 1.7734, acc : 0.812\n",
      "Epoch 45, loss : 0.0391, val_loss : 1.7449, acc : 0.812\n",
      "Epoch 46, loss : 0.0376, val_loss : 1.7180, acc : 0.812\n",
      "Epoch 47, loss : 0.0362, val_loss : 1.6930, acc : 0.812\n",
      "Epoch 48, loss : 0.0349, val_loss : 1.6695, acc : 0.812\n",
      "Epoch 49, loss : 0.0338, val_loss : 1.6471, acc : 0.812\n",
      "Epoch 50, loss : 0.0327, val_loss : 1.6257, acc : 0.812\n",
      "Epoch 51, loss : 0.0316, val_loss : 1.6051, acc : 0.812\n",
      "Epoch 52, loss : 0.0307, val_loss : 1.5848, acc : 0.812\n",
      "Epoch 53, loss : 0.0297, val_loss : 1.5655, acc : 0.812\n",
      "Epoch 54, loss : 0.0289, val_loss : 1.5461, acc : 0.812\n",
      "Epoch 55, loss : 0.0280, val_loss : 1.5274, acc : 0.812\n",
      "Epoch 56, loss : 0.0272, val_loss : 1.5087, acc : 0.812\n",
      "Epoch 57, loss : 0.0265, val_loss : 1.4902, acc : 0.812\n",
      "Epoch 58, loss : 0.0258, val_loss : 1.4718, acc : 0.812\n",
      "Epoch 59, loss : 0.0251, val_loss : 1.4534, acc : 0.812\n",
      "Epoch 60, loss : 0.0244, val_loss : 1.4374, acc : 0.812\n",
      "Epoch 61, loss : 0.0238, val_loss : 1.4217, acc : 0.812\n",
      "Epoch 62, loss : 0.0232, val_loss : 1.4060, acc : 0.812\n",
      "Epoch 63, loss : 0.0226, val_loss : 1.3902, acc : 0.812\n",
      "Epoch 64, loss : 0.0220, val_loss : 1.3743, acc : 0.812\n",
      "Epoch 65, loss : 0.0214, val_loss : 1.3584, acc : 0.812\n",
      "Epoch 66, loss : 0.0209, val_loss : 1.3425, acc : 0.812\n",
      "Epoch 67, loss : 0.0204, val_loss : 1.3265, acc : 0.812\n",
      "Epoch 68, loss : 0.0198, val_loss : 1.3104, acc : 0.812\n",
      "Epoch 69, loss : 0.0194, val_loss : 1.2939, acc : 0.812\n",
      "Epoch 70, loss : 0.0189, val_loss : 1.2775, acc : 0.812\n",
      "Epoch 71, loss : 0.0184, val_loss : 1.2612, acc : 0.812\n",
      "Epoch 72, loss : 0.0180, val_loss : 1.2449, acc : 0.812\n",
      "Epoch 73, loss : 0.0175, val_loss : 1.2286, acc : 0.812\n",
      "Epoch 74, loss : 0.0171, val_loss : 1.2101, acc : 0.812\n",
      "Epoch 75, loss : 0.0166, val_loss : 1.1964, acc : 0.812\n",
      "Epoch 76, loss : 0.0162, val_loss : 1.1773, acc : 0.812\n",
      "Epoch 77, loss : 0.0158, val_loss : 1.1640, acc : 0.812\n",
      "Epoch 78, loss : 0.0154, val_loss : 1.1460, acc : 0.812\n",
      "Epoch 79, loss : 0.0150, val_loss : 1.1328, acc : 0.812\n",
      "Epoch 80, loss : 0.0146, val_loss : 1.1153, acc : 0.812\n",
      "Epoch 81, loss : 0.0142, val_loss : 1.1021, acc : 0.812\n",
      "Epoch 82, loss : 0.0138, val_loss : 1.0848, acc : 0.812\n",
      "Epoch 83, loss : 0.0134, val_loss : 1.0719, acc : 0.812\n",
      "Epoch 84, loss : 0.0131, val_loss : 1.0545, acc : 0.812\n",
      "Epoch 85, loss : 0.0127, val_loss : 1.0423, acc : 0.812\n",
      "Epoch 86, loss : 0.0124, val_loss : 1.0244, acc : 0.812\n",
      "Epoch 87, loss : 0.0120, val_loss : 1.0134, acc : 0.812\n",
      "Epoch 88, loss : 0.0117, val_loss : 0.9946, acc : 0.812\n",
      "Epoch 89, loss : 0.0113, val_loss : 0.9853, acc : 0.812\n",
      "Epoch 90, loss : 0.0110, val_loss : 0.9649, acc : 0.812\n",
      "Epoch 91, loss : 0.0106, val_loss : 0.9583, acc : 0.812\n",
      "Epoch 92, loss : 0.0104, val_loss : 0.9350, acc : 0.812\n",
      "Epoch 93, loss : 0.0099, val_loss : 0.9330, acc : 0.812\n",
      "Epoch 94, loss : 0.0099, val_loss : 0.9044, acc : 0.812\n",
      "Epoch 95, loss : 0.0093, val_loss : 0.9102, acc : 0.812\n",
      "Epoch 96, loss : 0.0094, val_loss : 0.8708, acc : 0.812\n",
      "Epoch 97, loss : 0.0086, val_loss : 0.8943, acc : 0.812\n",
      "Epoch 98, loss : 0.0090, val_loss : 0.8351, acc : 0.812\n",
      "Epoch 99, loss : 0.0079, val_loss : 0.8854, acc : 0.812\n",
      "test_acc : 0.900\n"
     ]
    }
   ],
   "source": [
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int64)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        \n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            \n",
    "        total_loss /= n_samples\n",
    "        val_loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}\".format(epoch, total_loss, val_loss, acc))\n",
    "        \n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】3種類全ての目的変数を使用したIrisのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0      1            5.1           3.5            1.4           0.2   \n",
       "1      2            4.9           3.0            1.4           0.2   \n",
       "2      3            4.7           3.2            1.3           0.2   \n",
       "3      4            4.6           3.1            1.5           0.2   \n",
       "4      5            5.0           3.6            1.4           0.2   \n",
       "..   ...            ...           ...            ...           ...   \n",
       "145  146            6.7           3.0            5.2           2.3   \n",
       "146  147            6.3           2.5            5.0           1.9   \n",
       "147  148            6.5           3.0            5.2           2.0   \n",
       "148  149            6.2           3.4            5.4           2.3   \n",
       "149  150            5.9           3.0            5.1           1.8   \n",
       "\n",
       "            Species  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "..              ...  \n",
       "145  Iris-virginica  \n",
       "146  Iris-virginica  \n",
       "147  Iris-virginica  \n",
       "148  Iris-virginica  \n",
       "149  Iris-virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを3クラス分類する\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(\"Iris.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "\n",
    "# NumPy 配列に変換\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "y[y == \"Iris-setosa\"] = 0\n",
    "y[y == \"Iris-versicolor\"] = 1\n",
    "y[y == \"Iris-virginica\"] = 2\n",
    "\n",
    "y = y.astype(np.int64)[:, np.newaxis]\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "y = enc.fit_transform(y)\n",
    "\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 100\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_net(x):\n",
    "    \n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.random.set_random_seed(0)\n",
    "    \n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "                    'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "                    'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "                    'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "                    }\n",
    "    \n",
    "    biases = {\n",
    "                  'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "                  'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "                  'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "                  }\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    \n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X) \n",
    "\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits)) \n",
    "\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(logits, 1))\n",
    "\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[608.9496, 0.2]\n",
      "[539.0508, 0.2]\n",
      "[600.528, 0.1]\n",
      "[232.42773, 0.6]\n",
      "[501.8229, 0.3]\n",
      "[422.5642, 0.3]\n",
      "[296.91458, 0.4]\n",
      "[292.49292, 0.4]\n",
      "[305.6341, 0.5]\n",
      "[346.5333, 0.16666667]\n",
      "###################################\n",
      "### Epoch 1\n",
      "###################################\n",
      "loss : 43.1971, val_loss : 364.7727, acc : 0.333\n",
      "\n",
      "[466.98502, 0.2]\n",
      "[406.08047, 0.2]\n",
      "[445.63672, 0.1]\n",
      "[164.91524, 0.6]\n",
      "[375.681, 0.3]\n",
      "[304.32355, 0.3]\n",
      "[203.12856, 0.4]\n",
      "[200.01492, 0.4]\n",
      "[223.27902, 0.5]\n",
      "[220.67456, 0.16666667]\n",
      "###################################\n",
      "### Epoch 2\n",
      "###################################\n",
      "loss : 31.3617, val_loss : 250.4902, acc : 0.333\n",
      "\n",
      "[328.27313, 0.2]\n",
      "[275.21887, 0.2]\n",
      "[292.23557, 0.1]\n",
      "[97.92427, 0.6]\n",
      "[250.68636, 0.3]\n",
      "[187.05533, 0.3]\n",
      "[110.443665, 0.4]\n",
      "[108.20325, 0.4]\n",
      "[141.50002, 0.5]\n",
      "[96.08071, 0.16666667]\n",
      "###################################\n",
      "### Epoch 3\n",
      "###################################\n",
      "loss : 19.6627, val_loss : 137.0865, acc : 0.333\n",
      "\n",
      "[189.62016, 0.2]\n",
      "[145.23221, 0.2]\n",
      "[139.5466, 0.1]\n",
      "[31.882618, 0.6]\n",
      "[129.34737, 0.3]\n",
      "[88.370056, 0.6]\n",
      "[39.08004, 0.8]\n",
      "[44.90356, 0.7]\n",
      "[87.902176, 0.5]\n",
      "[31.282057, 0.8333333]\n",
      "###################################\n",
      "### Epoch 4\n",
      "###################################\n",
      "loss : 9.6580, val_loss : 78.8855, acc : 0.417\n",
      "\n",
      "[114.0273, 0.3]\n",
      "[91.35545, 0.4]\n",
      "[90.02351, 0.4]\n",
      "[25.718252, 0.4]\n",
      "[95.27674, 0.2]\n",
      "[55.402508, 0.4]\n",
      "[21.809383, 0.7]\n",
      "[25.290773, 0.7]\n",
      "[47.040306, 0.6]\n",
      "[15.033604, 0.8333333]\n",
      "###################################\n",
      "### Epoch 5\n",
      "###################################\n",
      "loss : 6.0519, val_loss : 34.4424, acc : 0.625\n",
      "\n",
      "[43.40965, 0.4]\n",
      "[31.83324, 0.4]\n",
      "[26.264385, 0.4]\n",
      "[11.725201, 0.2]\n",
      "[29.992228, 0.1]\n",
      "[7.644452, 0.3]\n",
      "[11.723722, 0.2]\n",
      "[14.643845, 0.0]\n",
      "[13.603964, 0.1]\n",
      "[23.03006, 0.16666667]\n",
      "###################################\n",
      "### Epoch 6\n",
      "###################################\n",
      "loss : 2.2278, val_loss : 13.2417, acc : 0.292\n",
      "\n",
      "[8.8304825, 0.6]\n",
      "[9.806176, 0.5]\n",
      "[15.228955, 0.4]\n",
      "[11.157795, 0.5]\n",
      "[16.85451, 0.4]\n",
      "[7.319703, 0.7]\n",
      "[10.350075, 0.6]\n",
      "[8.847772, 0.4]\n",
      "[7.7576723, 0.6]\n",
      "[11.888446, 0.16666667]\n",
      "###################################\n",
      "### Epoch 7\n",
      "###################################\n",
      "loss : 1.1254, val_loss : 6.1732, acc : 0.625\n",
      "\n",
      "[5.195055, 0.6]\n",
      "[5.6359386, 0.4]\n",
      "[5.908083, 0.2]\n",
      "[2.5721695, 0.7]\n",
      "[16.21781, 0.4]\n",
      "[1.2428749, 0.7]\n",
      "[0.44201803, 0.8]\n",
      "[4.4275117, 0.7]\n",
      "[10.774088, 0.5]\n",
      "[4.006773, 0.5]\n",
      "###################################\n",
      "### Epoch 8\n",
      "###################################\n",
      "loss : 0.5877, val_loss : 4.3193, acc : 0.583\n",
      "\n",
      "[2.9965672, 0.7]\n",
      "[4.304515, 0.4]\n",
      "[4.071239, 0.3]\n",
      "[1.2548668, 0.7]\n",
      "[10.029608, 0.4]\n",
      "[1.7039635, 0.7]\n",
      "[4.232349, 0.6]\n",
      "[4.2023177, 0.5]\n",
      "[5.2237267, 0.7]\n",
      "[6.3216705, 0.16666667]\n",
      "###################################\n",
      "### Epoch 9\n",
      "###################################\n",
      "loss : 0.4619, val_loss : 3.9277, acc : 0.625\n",
      "\n",
      "[1.2958353, 0.6]\n",
      "[2.0503695, 0.5]\n",
      "[2.4847627, 0.6]\n",
      "[0.7540158, 0.8]\n",
      "[10.864458, 0.5]\n",
      "[0.7627922, 0.8]\n",
      "[0.17295314, 0.9]\n",
      "[1.6523691, 0.7]\n",
      "[5.6800737, 0.5]\n",
      "[1.6338657, 0.33333334]\n",
      "###################################\n",
      "### Epoch 10\n",
      "###################################\n",
      "loss : 0.2849, val_loss : 2.4304, acc : 0.667\n",
      "\n",
      "[0.6152328, 0.7]\n",
      "[0.9184674, 0.8]\n",
      "[1.5524069, 0.4]\n",
      "[0.60030943, 0.6]\n",
      "[6.441354, 0.5]\n",
      "[0.7227172, 0.8]\n",
      "[0.9037306, 0.6]\n",
      "[1.1086413, 0.6]\n",
      "[4.182532, 0.7]\n",
      "[0.35063425, 0.8333333]\n",
      "###################################\n",
      "### Epoch 11\n",
      "###################################\n",
      "loss : 0.1812, val_loss : 1.7896, acc : 0.708\n",
      "\n",
      "[0.3645449, 0.8]\n",
      "[1.2982943, 0.7]\n",
      "[1.8419361, 0.7]\n",
      "[0.48095638, 0.9]\n",
      "[5.199557, 0.6]\n",
      "[0.7557608, 0.8]\n",
      "[1.3536716, 0.6]\n",
      "[1.4832312, 0.7]\n",
      "[2.8312848, 0.7]\n",
      "[1.8578095, 0.33333334]\n",
      "###################################\n",
      "### Epoch 12\n",
      "###################################\n",
      "loss : 0.1819, val_loss : 1.7324, acc : 0.667\n",
      "\n",
      "[0.13024789, 0.9]\n",
      "[0.6622585, 0.9]\n",
      "[1.1979363, 0.7]\n",
      "[0.50407124, 0.9]\n",
      "[5.1019616, 0.7]\n",
      "[0.29496497, 0.8]\n",
      "[0.25420073, 0.9]\n",
      "[0.7474783, 0.7]\n",
      "[2.472789, 0.7]\n",
      "[0.9625678, 0.5]\n",
      "###################################\n",
      "### Epoch 13\n",
      "###################################\n",
      "loss : 0.1284, val_loss : 1.3381, acc : 0.708\n",
      "\n",
      "[0.08957854, 1.0]\n",
      "[0.4725902, 0.9]\n",
      "[0.46849686, 0.8]\n",
      "[0.2313445, 0.8]\n",
      "[3.594574, 0.7]\n",
      "[0.18458267, 0.9]\n",
      "[0.35648805, 0.9]\n",
      "[0.69442093, 0.7]\n",
      "[2.004451, 0.7]\n",
      "[0.48678434, 0.6666667]\n",
      "###################################\n",
      "### Epoch 14\n",
      "###################################\n",
      "loss : 0.0894, val_loss : 1.1140, acc : 0.708\n",
      "\n",
      "[0.057127737, 1.0]\n",
      "[0.43474883, 0.9]\n",
      "[0.3141964, 0.8]\n",
      "[0.19298227, 0.8]\n",
      "[2.929727, 0.7]\n",
      "[0.111116245, 1.0]\n",
      "[0.341417, 0.9]\n",
      "[0.6498563, 0.8]\n",
      "[1.5933383, 0.7]\n",
      "[0.40250805, 0.8333333]\n",
      "###################################\n",
      "### Epoch 15\n",
      "###################################\n",
      "loss : 0.0732, val_loss : 1.0853, acc : 0.750\n",
      "\n",
      "[0.09814637, 0.9]\n",
      "[0.33558434, 0.9]\n",
      "[0.14275232, 0.9]\n",
      "[0.18518959, 0.9]\n",
      "[2.361067, 0.7]\n",
      "[0.063183114, 1.0]\n",
      "[0.26145738, 0.9]\n",
      "[0.52835786, 0.7]\n",
      "[1.3087212, 0.7]\n",
      "[0.23161113, 0.8333333]\n",
      "###################################\n",
      "### Epoch 16\n",
      "###################################\n",
      "loss : 0.0575, val_loss : 0.8860, acc : 0.792\n",
      "\n",
      "[0.09713468, 0.9]\n",
      "[0.30786574, 0.8]\n",
      "[0.07301023, 1.0]\n",
      "[0.234742, 0.9]\n",
      "[1.5521519, 0.7]\n",
      "[0.0508102, 1.0]\n",
      "[0.33061677, 0.9]\n",
      "[0.52597725, 0.8]\n",
      "[0.94966334, 0.7]\n",
      "[0.17043501, 0.8333333]\n",
      "###################################\n",
      "### Epoch 17\n",
      "###################################\n",
      "loss : 0.0447, val_loss : 0.7640, acc : 0.792\n",
      "\n",
      "[0.07802039, 0.9]\n",
      "[0.3174923, 0.8]\n",
      "[0.07387558, 1.0]\n",
      "[0.21020278, 0.9]\n",
      "[1.1839528, 0.7]\n",
      "[0.033911575, 1.0]\n",
      "[0.32642812, 0.9]\n",
      "[0.49762973, 0.8]\n",
      "[0.6536043, 0.7]\n",
      "[0.1352032, 0.8333333]\n",
      "###################################\n",
      "### Epoch 18\n",
      "###################################\n",
      "loss : 0.0366, val_loss : 0.6831, acc : 0.792\n",
      "\n",
      "[0.08033523, 0.9]\n",
      "[0.31307355, 0.8]\n",
      "[0.0617735, 1.0]\n",
      "[0.21034777, 0.9]\n",
      "[0.78393596, 0.7]\n",
      "[0.025073785, 1.0]\n",
      "[0.3140003, 0.9]\n",
      "[0.4516158, 0.8]\n",
      "[0.4405076, 0.8]\n",
      "[0.07194898, 1.0]\n",
      "###################################\n",
      "### Epoch 19\n",
      "###################################\n",
      "loss : 0.0287, val_loss : 0.5414, acc : 0.792\n",
      "\n",
      "[0.06349834, 1.0]\n",
      "[0.32038358, 0.8]\n",
      "[0.06046304, 1.0]\n",
      "[0.20604675, 0.9]\n",
      "[0.49247122, 0.8]\n",
      "[0.020326793, 1.0]\n",
      "[0.29908544, 0.9]\n",
      "[0.4092022, 0.8]\n",
      "[0.28767857, 0.8]\n",
      "[0.03969497, 1.0]\n",
      "###################################\n",
      "### Epoch 20\n",
      "###################################\n",
      "loss : 0.0229, val_loss : 0.4414, acc : 0.833\n",
      "\n",
      "[0.05334316, 1.0]\n",
      "[0.32461205, 0.8]\n",
      "[0.057928972, 1.0]\n",
      "[0.20331523, 0.9]\n",
      "[0.37198925, 0.9]\n",
      "[0.021966979, 1.0]\n",
      "[0.23629336, 0.9]\n",
      "[0.32771388, 0.8]\n",
      "[0.19563988, 0.8]\n",
      "[0.020064855, 1.0]\n",
      "###################################\n",
      "### Epoch 21\n",
      "###################################\n",
      "loss : 0.0189, val_loss : 0.3495, acc : 0.833\n",
      "\n",
      "[0.043979935, 1.0]\n",
      "[0.32380626, 0.8]\n",
      "[0.046729483, 1.0]\n",
      "[0.22187519, 0.9]\n",
      "[0.30367026, 0.9]\n",
      "[0.024944918, 1.0]\n",
      "[0.19034559, 0.9]\n",
      "[0.27522093, 0.8]\n",
      "[0.14881964, 0.9]\n",
      "[0.010588187, 1.0]\n",
      "###################################\n",
      "### Epoch 22\n",
      "###################################\n",
      "loss : 0.0166, val_loss : 0.2831, acc : 0.917\n",
      "\n",
      "[0.03279106, 1.0]\n",
      "[0.32842156, 0.8]\n",
      "[0.04366266, 1.0]\n",
      "[0.22808377, 0.9]\n",
      "[0.26438937, 0.9]\n",
      "[0.0215529, 1.0]\n",
      "[0.19369048, 0.9]\n",
      "[0.2600795, 0.9]\n",
      "[0.117272295, 0.9]\n",
      "[0.007442633, 1.0]\n",
      "###################################\n",
      "### Epoch 23\n",
      "###################################\n",
      "loss : 0.0156, val_loss : 0.2567, acc : 0.917\n",
      "\n",
      "[0.026158115, 1.0]\n",
      "[0.3359796, 0.9]\n",
      "[0.04848988, 1.0]\n",
      "[0.2112852, 0.9]\n",
      "[0.2648587, 0.9]\n",
      "[0.021991283, 1.0]\n",
      "[0.18978469, 0.9]\n",
      "[0.24843183, 0.9]\n",
      "[0.09546189, 1.0]\n",
      "[0.006529683, 1.0]\n",
      "###################################\n",
      "### Epoch 24\n",
      "###################################\n",
      "loss : 0.0151, val_loss : 0.2525, acc : 0.917\n",
      "\n",
      "[0.025815824, 1.0]\n",
      "[0.33135396, 0.9]\n",
      "[0.04489091, 1.0]\n",
      "[0.20379779, 0.9]\n",
      "[0.25949556, 0.9]\n",
      "[0.022515412, 1.0]\n",
      "[0.18111661, 0.9]\n",
      "[0.2340416, 0.9]\n",
      "[0.08285065, 1.0]\n",
      "[0.0053949207, 1.0]\n",
      "###################################\n",
      "### Epoch 25\n",
      "###################################\n",
      "loss : 0.0145, val_loss : 0.2425, acc : 0.917\n",
      "\n",
      "[0.023543637, 1.0]\n",
      "[0.32974795, 0.9]\n",
      "[0.042700358, 1.0]\n",
      "[0.1965687, 0.9]\n",
      "[0.24958737, 0.9]\n",
      "[0.021391407, 1.0]\n",
      "[0.18110731, 0.9]\n",
      "[0.22432992, 0.9]\n",
      "[0.07274876, 1.0]\n",
      "[0.0045864168, 1.0]\n",
      "###################################\n",
      "### Epoch 26\n",
      "###################################\n",
      "loss : 0.0140, val_loss : 0.2352, acc : 0.917\n",
      "\n",
      "[0.021183258, 1.0]\n",
      "[0.32974732, 0.9]\n",
      "[0.042480584, 1.0]\n",
      "[0.18530743, 0.9]\n",
      "[0.24566582, 0.9]\n",
      "[0.021086076, 1.0]\n",
      "[0.17948292, 0.9]\n",
      "[0.21541362, 0.9]\n",
      "[0.06438916, 1.0]\n",
      "[0.0040883343, 1.0]\n",
      "###################################\n",
      "### Epoch 27\n",
      "###################################\n",
      "loss : 0.0136, val_loss : 0.2319, acc : 0.917\n",
      "\n",
      "[0.019953322, 1.0]\n",
      "[0.32709503, 0.9]\n",
      "[0.040621094, 1.0]\n",
      "[0.17623821, 0.9]\n",
      "[0.2404865, 0.9]\n",
      "[0.020804161, 1.0]\n",
      "[0.17676209, 0.9]\n",
      "[0.20587444, 0.9]\n",
      "[0.057519555, 1.0]\n",
      "[0.0036000547, 1.0]\n",
      "###################################\n",
      "### Epoch 28\n",
      "###################################\n",
      "loss : 0.0132, val_loss : 0.2288, acc : 0.917\n",
      "\n",
      "[0.018821852, 1.0]\n",
      "[0.32413808, 0.9]\n",
      "[0.03856015, 1.0]\n",
      "[0.16808401, 0.9]\n",
      "[0.23427625, 0.9]\n",
      "[0.02023973, 1.0]\n",
      "[0.17481342, 0.9]\n",
      "[0.19505158, 0.9]\n",
      "[0.051099956, 1.0]\n",
      "[0.0031367352, 1.0]\n",
      "###################################\n",
      "### Epoch 29\n",
      "###################################\n",
      "loss : 0.0128, val_loss : 0.2269, acc : 0.917\n",
      "\n",
      "[0.017995378, 1.0]\n",
      "[0.3206455, 0.9]\n",
      "[0.036367435, 1.0]\n",
      "[0.1594561, 0.9]\n",
      "[0.2281445, 0.9]\n",
      "[0.01972995, 1.0]\n",
      "[0.17264032, 0.9]\n",
      "[0.18365684, 0.9]\n",
      "[0.045563035, 1.0]\n",
      "[0.0027559556, 1.0]\n",
      "###################################\n",
      "### Epoch 30\n",
      "###################################\n",
      "loss : 0.0124, val_loss : 0.2259, acc : 0.917\n",
      "\n",
      "[0.017320428, 1.0]\n",
      "[0.3165662, 0.9]\n",
      "[0.03394265, 1.0]\n",
      "[0.15094855, 0.9]\n",
      "[0.22128668, 0.9]\n",
      "[0.019181777, 1.0]\n",
      "[0.17073286, 0.9]\n",
      "[0.17319873, 0.9]\n",
      "[0.041037805, 1.0]\n",
      "[0.0024246841, 1.0]\n",
      "###################################\n",
      "### Epoch 31\n",
      "###################################\n",
      "loss : 0.0119, val_loss : 0.2248, acc : 0.917\n",
      "\n",
      "[0.0156069845, 1.0]\n",
      "[0.31262022, 0.8]\n",
      "[0.03161284, 1.0]\n",
      "[0.14283165, 0.9]\n",
      "[0.21329209, 0.9]\n",
      "[0.01845025, 1.0]\n",
      "[0.17005333, 0.9]\n",
      "[0.16401926, 0.9]\n",
      "[0.039120447, 1.0]\n",
      "[0.0021647427, 1.0]\n",
      "###################################\n",
      "### Epoch 32\n",
      "###################################\n",
      "loss : 0.0116, val_loss : 0.2243, acc : 0.917\n",
      "\n",
      "[0.014198838, 1.0]\n",
      "[0.30874833, 0.8]\n",
      "[0.029538628, 1.0]\n",
      "[0.13534856, 0.9]\n",
      "[0.20597632, 0.9]\n",
      "[0.01790659, 1.0]\n",
      "[0.169103, 0.9]\n",
      "[0.15569782, 0.9]\n",
      "[0.03731196, 1.0]\n",
      "[0.0019461116, 1.0]\n",
      "###################################\n",
      "### Epoch 33\n",
      "###################################\n",
      "loss : 0.0112, val_loss : 0.2239, acc : 0.917\n",
      "\n",
      "[0.013028601, 1.0]\n",
      "[0.30511, 0.8]\n",
      "[0.027701091, 1.0]\n",
      "[0.12861273, 0.9]\n",
      "[0.19890316, 0.9]\n",
      "[0.017436998, 1.0]\n",
      "[0.1683149, 0.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14538088, 0.9]\n",
      "[0.034933664, 1.0]\n",
      "[0.0017554917, 1.0]\n",
      "###################################\n",
      "### Epoch 34\n",
      "###################################\n",
      "loss : 0.0108, val_loss : 0.2260, acc : 0.917\n",
      "\n",
      "[0.012473734, 1.0]\n",
      "[0.30029288, 0.8]\n",
      "[0.025420213, 1.0]\n",
      "[0.12311642, 0.9]\n",
      "[0.19246486, 0.9]\n",
      "[0.01717868, 1.0]\n",
      "[0.1655228, 0.9]\n",
      "[0.12904236, 0.9]\n",
      "[0.03215584, 1.0]\n",
      "[0.0015185393, 1.0]\n",
      "###################################\n",
      "### Epoch 35\n",
      "###################################\n",
      "loss : 0.0104, val_loss : 0.2290, acc : 0.917\n",
      "\n",
      "[0.011079549, 1.0]\n",
      "[0.294386, 0.8]\n",
      "[0.022406409, 1.0]\n",
      "[0.120365515, 0.9]\n",
      "[0.18330485, 0.9]\n",
      "[0.016554173, 1.0]\n",
      "[0.16280189, 0.9]\n",
      "[0.112563334, 0.9]\n",
      "[0.029654134, 1.0]\n",
      "[0.0012626626, 1.0]\n",
      "###################################\n",
      "### Epoch 36\n",
      "###################################\n",
      "loss : 0.0099, val_loss : 0.2307, acc : 0.917\n",
      "\n",
      "[0.009072127, 1.0]\n",
      "[0.28948194, 0.8]\n",
      "[0.019985715, 1.0]\n",
      "[0.117667876, 0.9]\n",
      "[0.17411157, 0.9]\n",
      "[0.015732301, 1.0]\n",
      "[0.16103739, 0.9]\n",
      "[0.098593056, 1.0]\n",
      "[0.027404387, 1.0]\n",
      "[0.0010572969, 1.0]\n",
      "###################################\n",
      "### Epoch 37\n",
      "###################################\n",
      "loss : 0.0095, val_loss : 0.2328, acc : 0.917\n",
      "\n",
      "[0.0074512726, 1.0]\n",
      "[0.28194326, 0.8]\n",
      "[0.017726872, 1.0]\n",
      "[0.11513275, 0.9]\n",
      "[0.16371259, 0.9]\n",
      "[0.014660595, 1.0]\n",
      "[0.16031598, 0.9]\n",
      "[0.087147735, 1.0]\n",
      "[0.02617072, 1.0]\n",
      "[0.0008365438, 1.0]\n",
      "###################################\n",
      "### Epoch 38\n",
      "###################################\n",
      "loss : 0.0091, val_loss : 0.2341, acc : 0.917\n",
      "\n",
      "[0.005985682, 1.0]\n",
      "[0.27323538, 0.8]\n",
      "[0.015987303, 1.0]\n",
      "[0.11099593, 0.9]\n",
      "[0.1534787, 0.9]\n",
      "[0.01349506, 1.0]\n",
      "[0.16093048, 0.9]\n",
      "[0.07799213, 1.0]\n",
      "[0.025329644, 1.0]\n",
      "[0.0006699583, 1.0]\n",
      "###################################\n",
      "### Epoch 39\n",
      "###################################\n",
      "loss : 0.0087, val_loss : 0.2359, acc : 0.917\n",
      "\n",
      "[0.004853172, 1.0]\n",
      "[0.2644861, 0.8]\n",
      "[0.014563972, 1.0]\n",
      "[0.106274426, 0.9]\n",
      "[0.14419684, 0.9]\n",
      "[0.012471637, 1.0]\n",
      "[0.16055813, 0.9]\n",
      "[0.07057308, 1.0]\n",
      "[0.024708917, 1.0]\n",
      "[0.00054407486, 1.0]\n",
      "###################################\n",
      "### Epoch 40\n",
      "###################################\n",
      "loss : 0.0084, val_loss : 0.2391, acc : 0.917\n",
      "\n",
      "[0.003991501, 1.0]\n",
      "[0.25336963, 0.8]\n",
      "[0.013022932, 1.0]\n",
      "[0.10054821, 0.9]\n",
      "[0.13369031, 0.9]\n",
      "[0.011386309, 1.0]\n",
      "[0.15181571, 0.9]\n",
      "[0.064545676, 1.0]\n",
      "[0.024557073, 1.0]\n",
      "[0.00044507254, 1.0]\n",
      "###################################\n",
      "### Epoch 41\n",
      "###################################\n",
      "loss : 0.0079, val_loss : 0.2435, acc : 0.917\n",
      "\n",
      "[0.0033251494, 1.0]\n",
      "[0.24095328, 0.8]\n",
      "[0.01153589, 1.0]\n",
      "[0.09477997, 0.9]\n",
      "[0.12305255, 0.9]\n",
      "[0.010370576, 1.0]\n",
      "[0.14295126, 0.9]\n",
      "[0.059419483, 1.0]\n",
      "[0.024674196, 1.0]\n",
      "[0.0003675853, 1.0]\n",
      "###################################\n",
      "### Epoch 42\n",
      "###################################\n",
      "loss : 0.0074, val_loss : 0.2464, acc : 0.917\n",
      "\n",
      "[0.002809105, 1.0]\n",
      "[0.22887313, 0.8]\n",
      "[0.010366768, 1.0]\n",
      "[0.089198366, 0.9]\n",
      "[0.1130542, 0.9]\n",
      "[0.009464425, 1.0]\n",
      "[0.1349284, 0.9]\n",
      "[0.055045944, 1.0]\n",
      "[0.024702556, 1.0]\n",
      "[0.0003094204, 1.0]\n",
      "###################################\n",
      "### Epoch 43\n",
      "###################################\n",
      "loss : 0.0070, val_loss : 0.2417, acc : 0.917\n",
      "\n",
      "[0.002432777, 1.0]\n",
      "[0.2173435, 0.8]\n",
      "[0.009563254, 1.0]\n",
      "[0.08412448, 0.9]\n",
      "[0.10395656, 0.9]\n",
      "[0.008711219, 1.0]\n",
      "[0.12744802, 0.9]\n",
      "[0.05118682, 1.0]\n",
      "[0.024662474, 1.0]\n",
      "[0.00026484564, 1.0]\n",
      "###################################\n",
      "### Epoch 44\n",
      "###################################\n",
      "loss : 0.0066, val_loss : 0.2361, acc : 0.917\n",
      "\n",
      "[0.0021554304, 1.0]\n",
      "[0.20659533, 0.8]\n",
      "[0.008996615, 1.0]\n",
      "[0.07958902, 0.9]\n",
      "[0.095705785, 0.9]\n",
      "[0.008071864, 1.0]\n",
      "[0.120596305, 0.9]\n",
      "[0.047772627, 1.0]\n",
      "[0.024524132, 1.0]\n",
      "[0.00023039938, 1.0]\n",
      "###################################\n",
      "### Epoch 45\n",
      "###################################\n",
      "loss : 0.0062, val_loss : 0.2309, acc : 0.917\n",
      "\n",
      "[0.0019524671, 1.0]\n",
      "[0.20409517, 0.9]\n",
      "[0.0088901315, 1.0]\n",
      "[0.07752198, 0.9]\n",
      "[0.08687786, 0.9]\n",
      "[0.007396303, 1.0]\n",
      "[0.11205677, 0.9]\n",
      "[0.044184003, 1.0]\n",
      "[0.02260333, 1.0]\n",
      "[0.00020148094, 1.0]\n",
      "###################################\n",
      "### Epoch 46\n",
      "###################################\n",
      "loss : 0.0059, val_loss : 0.2309, acc : 0.917\n",
      "\n",
      "[0.0017430021, 1.0]\n",
      "[0.20223081, 0.9]\n",
      "[0.008543273, 1.0]\n",
      "[0.076119155, 0.9]\n",
      "[0.081879415, 0.9]\n",
      "[0.0071857558, 1.0]\n",
      "[0.09385125, 0.9]\n",
      "[0.038486555, 1.0]\n",
      "[0.019746305, 1.0]\n",
      "[0.00017477955, 1.0]\n",
      "###################################\n",
      "### Epoch 47\n",
      "###################################\n",
      "loss : 0.0055, val_loss : 0.2279, acc : 0.917\n",
      "\n",
      "[0.0015427254, 1.0]\n",
      "[0.1983621, 0.8]\n",
      "[0.0076628933, 1.0]\n",
      "[0.07630641, 0.9]\n",
      "[0.078249834, 0.9]\n",
      "[0.0073267594, 1.0]\n",
      "[0.07428278, 0.9]\n",
      "[0.03292797, 1.0]\n",
      "[0.01773752, 1.0]\n",
      "[0.00014990206, 1.0]\n",
      "###################################\n",
      "### Epoch 48\n",
      "###################################\n",
      "loss : 0.0052, val_loss : 0.2234, acc : 0.917\n",
      "\n",
      "[0.0013614434, 1.0]\n",
      "[0.1951782, 0.8]\n",
      "[0.0068362253, 1.0]\n",
      "[0.0770181, 0.9]\n",
      "[0.07414, 0.9]\n",
      "[0.007296323, 1.0]\n",
      "[0.05948476, 1.0]\n",
      "[0.029088344, 1.0]\n",
      "[0.016059699, 1.0]\n",
      "[0.00013070079, 1.0]\n",
      "###################################\n",
      "### Epoch 49\n",
      "###################################\n",
      "loss : 0.0049, val_loss : 0.2198, acc : 0.917\n",
      "\n",
      "[0.0012171647, 1.0]\n",
      "[0.19268519, 0.8]\n",
      "[0.00619308, 1.0]\n",
      "[0.07692473, 0.9]\n",
      "[0.07241154, 1.0]\n",
      "[0.0071650185, 1.0]\n",
      "[0.048916712, 1.0]\n",
      "[0.026121369, 1.0]\n",
      "[0.014596567, 1.0]\n",
      "[0.00011602559, 1.0]\n",
      "###################################\n",
      "### Epoch 50\n",
      "###################################\n",
      "loss : 0.0046, val_loss : 0.2172, acc : 0.917\n",
      "\n",
      "[0.0011027779, 1.0]\n",
      "[0.19064596, 0.8]\n",
      "[0.0057011135, 1.0]\n",
      "[0.0760205, 0.9]\n",
      "[0.07111181, 1.0]\n",
      "[0.006978168, 1.0]\n",
      "[0.0408475, 1.0]\n",
      "[0.023890987, 1.0]\n",
      "[0.0133839995, 1.0]\n",
      "[0.00010458654, 1.0]\n",
      "###################################\n",
      "### Epoch 51\n",
      "###################################\n",
      "loss : 0.0045, val_loss : 0.2152, acc : 0.917\n",
      "\n",
      "[0.0010120845, 1.0]\n",
      "[0.18887302, 0.8]\n",
      "[0.0052754534, 1.0]\n",
      "[0.07486217, 0.9]\n",
      "[0.069869205, 1.0]\n",
      "[0.0069223396, 1.0]\n",
      "[0.034763403, 1.0]\n",
      "[0.021924058, 1.0]\n",
      "[0.012500596, 1.0]\n",
      "[9.529194e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 52\n",
      "###################################\n",
      "loss : 0.0043, val_loss : 0.2132, acc : 0.917\n",
      "\n",
      "[0.0009359671, 1.0]\n",
      "[0.18732333, 0.8]\n",
      "[0.0049398653, 1.0]\n",
      "[0.07335717, 0.9]\n",
      "[0.06858899, 1.0]\n",
      "[0.006824203, 1.0]\n",
      "[0.030286139, 1.0]\n",
      "[0.020346189, 1.0]\n",
      "[0.011765679, 1.0]\n",
      "[8.788377e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 53\n",
      "###################################\n",
      "loss : 0.0042, val_loss : 0.2118, acc : 0.917\n",
      "\n",
      "[0.0008724221, 1.0]\n",
      "[0.18581964, 0.8]\n",
      "[0.0046652528, 1.0]\n",
      "[0.07149783, 0.9]\n",
      "[0.067525044, 1.0]\n",
      "[0.0067086695, 1.0]\n",
      "[0.026765728, 1.0]\n",
      "[0.01907316, 1.0]\n",
      "[0.011190935, 1.0]\n",
      "[8.172665e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 54\n",
      "###################################\n",
      "loss : 0.0041, val_loss : 0.2105, acc : 0.917\n",
      "\n",
      "[0.0008176921, 1.0]\n",
      "[0.18435487, 0.8]\n",
      "[0.004431045, 1.0]\n",
      "[0.069522366, 1.0]\n",
      "[0.06641488, 1.0]\n",
      "[0.006459958, 1.0]\n",
      "[0.024020027, 1.0]\n",
      "[0.01823303, 1.0]\n",
      "[0.010774812, 1.0]\n",
      "[7.6641954e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 55\n",
      "###################################\n",
      "loss : 0.0040, val_loss : 0.2091, acc : 0.917\n",
      "\n",
      "[0.00077148917, 1.0]\n",
      "[0.18288188, 0.8]\n",
      "[0.004243763, 1.0]\n",
      "[0.06741581, 1.0]\n",
      "[0.06538062, 1.0]\n",
      "[0.006064881, 1.0]\n",
      "[0.021786906, 1.0]\n",
      "[0.017582083, 1.0]\n",
      "[0.010462323, 1.0]\n",
      "[7.221261e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 56\n",
      "###################################\n",
      "loss : 0.0039, val_loss : 0.2074, acc : 0.917\n",
      "\n",
      "[0.000729923, 1.0]\n",
      "[0.18194129, 0.8]\n",
      "[0.004157268, 1.0]\n",
      "[0.06440144, 1.0]\n",
      "[0.065035455, 1.0]\n",
      "[0.0058507845, 1.0]\n",
      "[0.021246765, 1.0]\n",
      "[0.01773558, 1.0]\n",
      "[0.010461856, 1.0]\n",
      "[7.243115e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 57\n",
      "###################################\n",
      "loss : 0.0039, val_loss : 0.2093, acc : 0.917\n",
      "\n",
      "[0.00073366985, 1.0]\n",
      "[0.17985028, 0.8]\n",
      "[0.003943622, 1.0]\n",
      "[0.06332981, 1.0]\n",
      "[0.06257671, 1.0]\n",
      "[0.0054725595, 1.0]\n",
      "[0.020777334, 1.0]\n",
      "[0.017520256, 1.0]\n",
      "[0.010675872, 1.0]\n",
      "[7.0047645e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 58\n",
      "###################################\n",
      "loss : 0.0038, val_loss : 0.2081, acc : 0.917\n",
      "\n",
      "[0.0007072432, 1.0]\n",
      "[0.18023273, 0.8]\n",
      "[0.0038968294, 1.0]\n",
      "[0.06062839, 1.0]\n",
      "[0.06149265, 1.0]\n",
      "[0.0052180677, 1.0]\n",
      "[0.02115452, 1.0]\n",
      "[0.017882956, 1.0]\n",
      "[0.0107747, 1.0]\n",
      "[7.1100396e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 59\n",
      "###################################\n",
      "loss : 0.0038, val_loss : 0.2112, acc : 0.917\n",
      "\n",
      "[0.0007137939, 1.0]\n",
      "[0.17659506, 0.8]\n",
      "[0.00387735, 1.0]\n",
      "[0.057402037, 1.0]\n",
      "[0.061453193, 1.0]\n",
      "[0.0051349974, 1.0]\n",
      "[0.02198841, 1.0]\n",
      "[0.018556459, 1.0]\n",
      "[0.011181399, 1.0]\n",
      "[7.2927876e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 60\n",
      "###################################\n",
      "loss : 0.0037, val_loss : 0.2130, acc : 0.917\n",
      "\n",
      "[0.00072810386, 1.0]\n",
      "[0.1750724, 0.8]\n",
      "[0.003720484, 1.0]\n",
      "[0.05665804, 1.0]\n",
      "[0.058359068, 1.0]\n",
      "[0.0047425358, 1.0]\n",
      "[0.022321116, 1.0]\n",
      "[0.018470727, 1.0]\n",
      "[0.011238197, 1.0]\n",
      "[7.106079e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 61\n",
      "###################################\n",
      "loss : 0.0037, val_loss : 0.2124, acc : 0.917\n",
      "\n",
      "[0.00070408534, 1.0]\n",
      "[0.17352772, 0.8]\n",
      "[0.0037208025, 1.0]\n",
      "[0.053902216, 1.0]\n",
      "[0.05768774, 1.0]\n",
      "[0.0045949435, 1.0]\n",
      "[0.021285247, 1.0]\n",
      "[0.017826963, 1.0]\n",
      "[0.010749685, 1.0]\n",
      "[6.855787e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 62\n",
      "###################################\n",
      "loss : 0.0036, val_loss : 0.2162, acc : 0.917\n",
      "\n",
      "[0.0006684607, 1.0]\n",
      "[0.17529316, 0.8]\n",
      "[0.0035055187, 1.0]\n",
      "[0.05201791, 1.0]\n",
      "[0.05811646, 1.0]\n",
      "[0.0047312104, 1.0]\n",
      "[0.020209648, 1.0]\n",
      "[0.017804328, 1.0]\n",
      "[0.011501189, 1.0]\n",
      "[6.8478555e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 63\n",
      "###################################\n",
      "loss : 0.0036, val_loss : 0.2141, acc : 0.917\n",
      "\n",
      "[0.00067109533, 1.0]\n",
      "[0.17134742, 0.8]\n",
      "[0.0034746218, 1.0]\n",
      "[0.050504707, 1.0]\n",
      "[0.055814177, 1.0]\n",
      "[0.004277193, 1.0]\n",
      "[0.021818299, 1.0]\n",
      "[0.01883674, 1.0]\n",
      "[0.01163931, 1.0]\n",
      "[7.034577e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 64\n",
      "###################################\n",
      "loss : 0.0035, val_loss : 0.2166, acc : 0.917\n",
      "\n",
      "[0.0006849573, 1.0]\n",
      "[0.16934313, 0.8]\n",
      "[0.003438883, 1.0]\n",
      "[0.04874384, 1.0]\n",
      "[0.054252416, 1.0]\n",
      "[0.0040542255, 1.0]\n",
      "[0.021951187, 1.0]\n",
      "[0.018729726, 1.0]\n",
      "[0.011472583, 1.0]\n",
      "[6.87368e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 65\n",
      "###################################\n",
      "loss : 0.0035, val_loss : 0.2180, acc : 0.917\n",
      "\n",
      "[0.00066153373, 1.0]\n",
      "[0.16801348, 0.8]\n",
      "[0.003457366, 1.0]\n",
      "[0.045629665, 1.0]\n",
      "[0.055178057, 1.0]\n",
      "[0.0041619926, 1.0]\n",
      "[0.021714758, 1.0]\n",
      "[0.018778775, 1.0]\n",
      "[0.011592851, 1.0]\n",
      "[6.941215e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 66\n",
      "###################################\n",
      "loss : 0.0034, val_loss : 0.2210, acc : 0.917\n",
      "\n",
      "[0.00066286355, 1.0]\n",
      "[0.16684952, 0.8]\n",
      "[0.0032440466, 1.0]\n",
      "[0.045406118, 1.0]\n",
      "[0.052947283, 1.0]\n",
      "[0.004051228, 1.0]\n",
      "[0.021093335, 1.0]\n",
      "[0.018154722, 1.0]\n",
      "[0.011792393, 1.0]\n",
      "[6.694911e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 67\n",
      "###################################\n",
      "loss : 0.0034, val_loss : 0.2183, acc : 0.917\n",
      "\n",
      "[0.0006404122, 1.0]\n",
      "[0.1662473, 0.8]\n",
      "[0.0032688018, 1.0]\n",
      "[0.043252103, 1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0521459, 1.0]\n",
      "[0.0039555305, 1.0]\n",
      "[0.021495685, 1.0]\n",
      "[0.018350197, 1.0]\n",
      "[0.0114783095, 1.0]\n",
      "[6.77436e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 68\n",
      "###################################\n",
      "loss : 0.0033, val_loss : 0.2237, acc : 0.917\n",
      "\n",
      "[0.0006398812, 1.0]\n",
      "[0.16437198, 0.8]\n",
      "[0.003124802, 1.0]\n",
      "[0.041960318, 1.0]\n",
      "[0.05183791, 1.0]\n",
      "[0.004014697, 1.0]\n",
      "[0.020325536, 1.0]\n",
      "[0.017836543, 1.0]\n",
      "[0.011817185, 1.0]\n",
      "[6.545932e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 69\n",
      "###################################\n",
      "loss : 0.0033, val_loss : 0.2212, acc : 0.917\n",
      "\n",
      "[0.0006195306, 1.0]\n",
      "[0.1652852, 0.8]\n",
      "[0.0030423545, 1.0]\n",
      "[0.041059297, 1.0]\n",
      "[0.0500189, 1.0]\n",
      "[0.0036678724, 1.0]\n",
      "[0.020666042, 1.0]\n",
      "[0.018402504, 1.0]\n",
      "[0.011930238, 1.0]\n",
      "[6.589635e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 70\n",
      "###################################\n",
      "loss : 0.0033, val_loss : 0.2224, acc : 0.917\n",
      "\n",
      "[0.00062427303, 1.0]\n",
      "[0.16180696, 0.8]\n",
      "[0.0030783725, 1.0]\n",
      "[0.03888711, 1.0]\n",
      "[0.049733065, 1.0]\n",
      "[0.0035896082, 1.0]\n",
      "[0.021629397, 1.0]\n",
      "[0.019175528, 1.0]\n",
      "[0.012115864, 1.0]\n",
      "[6.7306704e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 71\n",
      "###################################\n",
      "loss : 0.0032, val_loss : 0.2245, acc : 0.917\n",
      "\n",
      "[0.0006363602, 1.0]\n",
      "[0.1605846, 0.8]\n",
      "[0.00299352, 1.0]\n",
      "[0.038225163, 1.0]\n",
      "[0.047761362, 1.0]\n",
      "[0.003361354, 1.0]\n",
      "[0.021481523, 1.0]\n",
      "[0.01894786, 1.0]\n",
      "[0.011996406, 1.0]\n",
      "[6.532031e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 72\n",
      "###################################\n",
      "loss : 0.0032, val_loss : 0.2243, acc : 0.917\n",
      "\n",
      "[0.00061565667, 1.0]\n",
      "[0.15941553, 0.8]\n",
      "[0.0030230805, 1.0]\n",
      "[0.035975706, 1.0]\n",
      "[0.04818797, 1.0]\n",
      "[0.0034254722, 1.0]\n",
      "[0.021308102, 1.0]\n",
      "[0.01903177, 1.0]\n",
      "[0.011937643, 1.0]\n",
      "[6.559839e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 73\n",
      "###################################\n",
      "loss : 0.0032, val_loss : 0.2273, acc : 0.917\n",
      "\n",
      "[0.00061461184, 1.0]\n",
      "[0.15841505, 0.8]\n",
      "[0.0028826226, 1.0]\n",
      "[0.03550295, 1.0]\n",
      "[0.0468413, 1.0]\n",
      "[0.003300562, 1.0]\n",
      "[0.020368632, 1.0]\n",
      "[0.018567268, 1.0]\n",
      "[0.012061948, 1.0]\n",
      "[6.329416e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 74\n",
      "###################################\n",
      "loss : 0.0031, val_loss : 0.2253, acc : 0.917\n",
      "\n",
      "[0.0005953509, 1.0]\n",
      "[0.15928271, 0.8]\n",
      "[0.0028328253, 1.0]\n",
      "[0.034477547, 1.0]\n",
      "[0.045806117, 1.0]\n",
      "[0.003162799, 1.0]\n",
      "[0.020456351, 1.0]\n",
      "[0.018950928, 1.0]\n",
      "[0.012234019, 1.0]\n",
      "[6.3512685e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 75\n",
      "###################################\n",
      "loss : 0.0031, val_loss : 0.2256, acc : 0.917\n",
      "\n",
      "[0.00060180784, 1.0]\n",
      "[0.15640345, 0.8]\n",
      "[0.0028714533, 1.0]\n",
      "[0.03285907, 1.0]\n",
      "[0.04526311, 1.0]\n",
      "[0.003035128, 1.0]\n",
      "[0.021340888, 1.0]\n",
      "[0.019655067, 1.0]\n",
      "[0.012170619, 1.0]\n",
      "[6.4704545e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 76\n",
      "###################################\n",
      "loss : 0.0031, val_loss : 0.2286, acc : 0.917\n",
      "\n",
      "[0.00061098405, 1.0]\n",
      "[0.1551465, 0.8]\n",
      "[0.0027848366, 1.0]\n",
      "[0.032245256, 1.0]\n",
      "[0.04405398, 1.0]\n",
      "[0.0030121054, 1.0]\n",
      "[0.020774882, 1.0]\n",
      "[0.019097745, 1.0]\n",
      "[0.0121483235, 1.0]\n",
      "[6.263865e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 77\n",
      "###################################\n",
      "loss : 0.0030, val_loss : 0.2274, acc : 0.917\n",
      "\n",
      "[0.00059320143, 1.0]\n",
      "[0.15502964, 0.8]\n",
      "[0.0027811327, 1.0]\n",
      "[0.030845603, 1.0]\n",
      "[0.04380513, 1.0]\n",
      "[0.0029542553, 1.0]\n",
      "[0.020641472, 1.0]\n",
      "[0.019371744, 1.0]\n",
      "[0.012103992, 1.0]\n",
      "[6.275784e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 78\n",
      "###################################\n",
      "loss : 0.0030, val_loss : 0.2295, acc : 0.917\n",
      "\n",
      "[0.00059473247, 1.0]\n",
      "[0.15312266, 0.8]\n",
      "[0.0027769408, 1.0]\n",
      "[0.029484298, 1.0]\n",
      "[0.043769177, 1.0]\n",
      "[0.0028526478, 1.0]\n",
      "[0.021025043, 1.0]\n",
      "[0.020053988, 1.0]\n",
      "[0.012490588, 1.0]\n",
      "[6.377094e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 79\n",
      "###################################\n",
      "loss : 0.0030, val_loss : 0.2292, acc : 0.917\n",
      "\n",
      "[0.0006097304, 1.0]\n",
      "[0.15214042, 0.8]\n",
      "[0.00267253, 1.0]\n",
      "[0.029706245, 1.0]\n",
      "[0.04107827, 1.0]\n",
      "[0.0026810255, 1.0]\n",
      "[0.021030584, 1.0]\n",
      "[0.019661266, 1.0]\n",
      "[0.012225805, 1.0]\n",
      "[6.1625564e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 80\n",
      "###################################\n",
      "loss : 0.0029, val_loss : 0.2283, acc : 0.917\n",
      "\n",
      "[0.00059270544, 1.0]\n",
      "[0.15139633, 0.8]\n",
      "[0.002740252, 1.0]\n",
      "[0.027844477, 1.0]\n",
      "[0.041661907, 1.0]\n",
      "[0.002709829, 1.0]\n",
      "[0.0207402, 1.0]\n",
      "[0.019703511, 1.0]\n",
      "[0.011923251, 1.0]\n",
      "[6.148652e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 81\n",
      "###################################\n",
      "loss : 0.0029, val_loss : 0.2323, acc : 0.917\n",
      "\n",
      "[0.00058479514, 1.0]\n",
      "[0.15040673, 0.9]\n",
      "[0.0026292987, 1.0]\n",
      "[0.02728343, 1.0]\n",
      "[0.04140734, 1.0]\n",
      "[0.0026840318, 1.0]\n",
      "[0.0194445, 1.0]\n",
      "[0.019018382, 1.0]\n",
      "[0.011989611, 1.0]\n",
      "[5.9241804e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 82\n",
      "###################################\n",
      "loss : 0.0029, val_loss : 0.2302, acc : 0.917\n",
      "\n",
      "[0.0005665061, 1.0]\n",
      "[0.15252154, 0.8]\n",
      "[0.002536648, 1.0]\n",
      "[0.027017424, 1.0]\n",
      "[0.04003065, 1.0]\n",
      "[0.002626047, 1.0]\n",
      "[0.019234095, 1.0]\n",
      "[0.018958045, 1.0]\n",
      "[0.012194998, 1.0]\n",
      "[5.94603e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 83\n",
      "###################################\n",
      "loss : 0.0029, val_loss : 0.2297, acc : 0.917\n",
      "\n",
      "[0.00057520857, 1.0]\n",
      "[0.14975697, 0.8]\n",
      "[0.0025604889, 1.0]\n",
      "[0.025990099, 1.0]\n",
      "[0.039312873, 1.0]\n",
      "[0.0025393288, 1.0]\n",
      "[0.020170145, 1.0]\n",
      "[0.019698594, 1.0]\n",
      "[0.012301243, 1.0]\n",
      "[6.0572715e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 84\n",
      "###################################\n",
      "loss : 0.0028, val_loss : 0.2307, acc : 0.917\n",
      "\n",
      "[0.00059165346, 1.0]\n",
      "[0.14754078, 0.9]\n",
      "[0.0025608703, 1.0]\n",
      "[0.025287688, 1.0]\n",
      "[0.038246166, 1.0]\n",
      "[0.002475742, 1.0]\n",
      "[0.020000944, 1.0]\n",
      "[0.019564057, 1.0]\n",
      "[0.011804889, 1.0]\n",
      "[5.8506794e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 85\n",
      "###################################\n",
      "loss : 0.0028, val_loss : 0.2324, acc : 0.917\n",
      "\n",
      "[0.0005687485, 1.0]\n",
      "[0.14880751, 0.9]\n",
      "[0.002536603, 1.0]\n",
      "[0.024122315, 1.0]\n",
      "[0.038879894, 1.0]\n",
      "[0.0025240479, 1.0]\n",
      "[0.019191347, 1.0]\n",
      "[0.019363996, 1.0]\n",
      "[0.012041339, 1.0]\n",
      "[5.8606107e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 86\n",
      "###################################\n",
      "loss : 0.0028, val_loss : 0.2324, acc : 0.917\n",
      "\n",
      "[0.00057248515, 1.0]\n",
      "[0.14658974, 0.9]\n",
      "[0.0025059222, 1.0]\n",
      "[0.023558598, 1.0]\n",
      "[0.038099207, 1.0]\n",
      "[0.00245666, 1.0]\n",
      "[0.019723967, 1.0]\n",
      "[0.019742135, 1.0]\n",
      "[0.012274354, 1.0]\n",
      "[5.9539732e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 87\n",
      "###################################\n",
      "loss : 0.0028, val_loss : 0.2325, acc : 0.917\n",
      "\n",
      "[0.0005880856, 1.0]\n",
      "[0.14506318, 0.9]\n",
      "[0.0024650889, 1.0]\n",
      "[0.023343014, 1.0]\n",
      "[0.036503166, 1.0]\n",
      "[0.002369247, 1.0]\n",
      "[0.019600537, 1.0]\n",
      "[0.019577594, 1.0]\n",
      "[0.011899052, 1.0]\n",
      "[5.757311e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 88\n",
      "###################################\n",
      "loss : 0.0027, val_loss : 0.2324, acc : 0.917\n",
      "\n",
      "[0.00057093106, 1.0]\n",
      "[0.14593093, 0.9]\n",
      "[0.0024798026, 1.0]\n",
      "[0.022202522, 1.0]\n",
      "[0.036866665, 1.0]\n",
      "[0.0023766751, 1.0]\n",
      "[0.019103939, 1.0]\n",
      "[0.019580917, 1.0]\n",
      "[0.011877958, 1.0]\n",
      "[5.745392e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 89\n",
      "###################################\n",
      "loss : 0.0027, val_loss : 0.2339, acc : 0.917\n",
      "\n",
      "[0.0005705486, 1.0]\n",
      "[0.14391018, 0.9]\n",
      "[0.002466236, 1.0]\n",
      "[0.02140569, 1.0]\n",
      "[0.036733523, 1.0]\n",
      "[0.002371268, 1.0]\n",
      "[0.019363225, 1.0]\n",
      "[0.019777855, 1.0]\n",
      "[0.01216362, 1.0]\n",
      "[5.8347814e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 90\n",
      "###################################\n",
      "loss : 0.0027, val_loss : 0.2336, acc : 0.917\n",
      "\n",
      "[0.00058652845, 1.0]\n",
      "[0.14268722, 0.9]\n",
      "[0.0024075522, 1.0]\n",
      "[0.02139935, 1.0]\n",
      "[0.035014234, 1.0]\n",
      "[0.002198978, 1.0]\n",
      "[0.019174788, 1.0]\n",
      "[0.019669432, 1.0]\n",
      "[0.011797639, 1.0]\n",
      "[5.6361314e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 91\n",
      "###################################\n",
      "loss : 0.0027, val_loss : 0.2332, acc : 0.917\n",
      "\n",
      "[0.0005705269, 1.0]\n",
      "[0.14361301, 0.9]\n",
      "[0.0024170764, 1.0]\n",
      "[0.02040994, 1.0]\n",
      "[0.035272975, 1.0]\n",
      "[0.0022680766, 1.0]\n",
      "[0.018701427, 1.0]\n",
      "[0.01948398, 1.0]\n",
      "[0.011736466, 1.0]\n",
      "[5.618254e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 92\n",
      "###################################\n",
      "loss : 0.0027, val_loss : 0.2349, acc : 0.917\n",
      "\n",
      "[0.0005686933, 1.0]\n",
      "[0.1416411, 0.9]\n",
      "[0.0024023808, 1.0]\n",
      "[0.019644717, 1.0]\n",
      "[0.035315014, 1.0]\n",
      "[0.0023070124, 1.0]\n",
      "[0.018924836, 1.0]\n",
      "[0.01963073, 1.0]\n",
      "[0.011994911, 1.0]\n",
      "[5.7036697e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 93\n",
      "###################################\n",
      "loss : 0.0026, val_loss : 0.2348, acc : 0.917\n",
      "\n",
      "[0.00058395806, 1.0]\n",
      "[0.1404425, 0.9]\n",
      "[0.002339084, 1.0]\n",
      "[0.019652525, 1.0]\n",
      "[0.033858158, 1.0]\n",
      "[0.0021522187, 1.0]\n",
      "[0.018751219, 1.0]\n",
      "[0.019432038, 1.0]\n",
      "[0.011576014, 1.0]\n",
      "[5.5010463e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 94\n",
      "###################################\n",
      "loss : 0.0026, val_loss : 0.2347, acc : 0.917\n",
      "\n",
      "[0.0005667657, 1.0]\n",
      "[0.14145125, 0.9]\n",
      "[0.0023487685, 1.0]\n",
      "[0.018696528, 1.0]\n",
      "[0.03416393, 1.0]\n",
      "[0.0022531787, 1.0]\n",
      "[0.018141098, 1.0]\n",
      "[0.019230971, 1.0]\n",
      "[0.011673887, 1.0]\n",
      "[5.5050175e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 95\n",
      "###################################\n",
      "loss : 0.0026, val_loss : 0.2348, acc : 0.917\n",
      "\n",
      "[0.000572357, 1.0]\n",
      "[0.13958445, 0.9]\n",
      "[0.0023394376, 1.0]\n",
      "[0.018162502, 1.0]\n",
      "[0.033699304, 1.0]\n",
      "[0.002212908, 1.0]\n",
      "[0.018646393, 1.0]\n",
      "[0.01977264, 1.0]\n",
      "[0.011753727, 1.0]\n",
      "[5.5864628e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 96\n",
      "###################################\n",
      "loss : 0.0026, val_loss : 0.2358, acc : 0.917\n",
      "\n",
      "[0.0005863477, 1.0]\n",
      "[0.1382945, 0.9]\n",
      "[0.0022966554, 1.0]\n",
      "[0.017991688, 1.0]\n",
      "[0.03262728, 1.0]\n",
      "[0.0021037445, 1.0]\n",
      "[0.018086396, 1.0]\n",
      "[0.019260775, 1.0]\n",
      "[0.011509734, 1.0]\n",
      "[5.4017157e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 97\n",
      "###################################\n",
      "loss : 0.0025, val_loss : 0.2350, acc : 0.917\n",
      "\n",
      "[0.000570297, 1.0]\n",
      "[0.13952662, 0.9]\n",
      "[0.0022763694, 1.0]\n",
      "[0.017392343, 1.0]\n",
      "[0.03267455, 1.0]\n",
      "[0.0021946128, 1.0]\n",
      "[0.01769642, 1.0]\n",
      "[0.019027531, 1.0]\n",
      "[0.011451493, 1.0]\n",
      "[5.3858243e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 98\n",
      "###################################\n",
      "loss : 0.0025, val_loss : 0.2362, acc : 0.917\n",
      "\n",
      "[0.00057027244, 1.0]\n",
      "[0.13767055, 0.9]\n",
      "[0.0022753463, 1.0]\n",
      "[0.016729143, 1.0]\n",
      "[0.032810096, 1.0]\n",
      "[0.0022091104, 1.0]\n",
      "[0.018087672, 1.0]\n",
      "[0.019484542, 1.0]\n",
      "[0.011603034, 1.0]\n",
      "[5.4732274e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 99\n",
      "###################################\n",
      "loss : 0.0025, val_loss : 0.2366, acc : 0.917\n",
      "\n",
      "[0.00058634474, 1.0]\n",
      "[0.13624181, 0.9]\n",
      "[0.0022380347, 1.0]\n",
      "[0.01659912, 1.0]\n",
      "[0.03153198, 1.0]\n",
      "[0.0021002695, 1.0]\n",
      "[0.017601537, 1.0]\n",
      "[0.018969227, 1.0]\n",
      "[0.01138336, 1.0]\n",
      "[5.3063588e-05, 1.0]\n",
      "###################################\n",
      "### Epoch 100\n",
      "###################################\n",
      "loss : 0.0025, val_loss : 0.2355, acc : 0.917\n",
      "\n",
      "test_acc : 0.967\n"
     ]
    }
   ],
   "source": [
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # エポックごとにループ\n",
    "        #total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int64)\n",
    "        total_batch = np.ceil(n_samples/batch_size).astype(np.int64)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        \n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ミニバッチごとにループ\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            #print(loss, acc)\n",
    "            print(sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y}))\n",
    "            \n",
    "        total_loss /= n_samples\n",
    "        val_loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        \n",
    "        print('#'*35)\n",
    "        print('### Epoch %i'%(epoch+1))\n",
    "        print('#'*35)\n",
    "        print(\"loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}\".format(total_loss, val_loss, acc))\n",
    "        print()\n",
    "        \n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】House Pricesのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1710</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1786</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1717</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2198</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1647</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2073</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2340</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1078</td>\n",
       "      <td>1950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1256</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GrLivArea  YearBuilt\n",
       "0          1710       2003\n",
       "1          1262       1976\n",
       "2          1786       2001\n",
       "3          1717       1915\n",
       "4          2198       2000\n",
       "...         ...        ...\n",
       "1455       1647       1999\n",
       "1456       2073       1978\n",
       "1457       2340       1941\n",
       "1458       1078       1950\n",
       "1459       1256       1965\n",
       "\n",
       "[1460 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使い回帰分析を行う\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(\"house-prices-advanced-regression-techniques/train.csv\")\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = df[\"SalePrice\"]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500\n",
       "1       181500\n",
       "2       223500\n",
       "3       140000\n",
       "4       250000\n",
       "         ...  \n",
       "1455    175000\n",
       "1456    210000\n",
       "1457    266500\n",
       "1458    142125\n",
       "1459    147500\n",
       "Name: SalePrice, Length: 1460, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1710, 2003],\n",
       "        [1262, 1976],\n",
       "        [1786, 2001],\n",
       "        ...,\n",
       "        [2340, 1941],\n",
       "        [1078, 1950],\n",
       "        [1256, 1965]]),\n",
       " array([208500, 181500, 223500, ..., 266500, 142125, 147500]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy 配列に変換\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.25923135, 0.94927536],\n",
       "        [0.17483044, 0.75362319],\n",
       "        [0.27354936, 0.93478261],\n",
       "        ...,\n",
       "        [0.37792012, 0.5       ],\n",
       "        [0.14016579, 0.56521739],\n",
       "        [0.17370008, 0.67391304]]),\n",
       " (1460, 1))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 正規化\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y.reshape(-1, 1))\n",
    "X_scaled, y_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=0)\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 100\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_net(x):\n",
    "    \n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.random.set_random_seed(0)\n",
    "    \n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "        'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X) \n",
    "\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.square(logits - Y)) \n",
    "\n",
    "# 最適化手法\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果、指標値計算は無し\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Epoch 1\n",
      "#########################\n",
      "Train_loss[4.816823]\n",
      "Val_loss[6.065445]\n",
      "\n",
      "#########################\n",
      "### Epoch 2\n",
      "#########################\n",
      "Train_loss[1.8077507]\n",
      "Val_loss[1.7634455]\n",
      "\n",
      "#########################\n",
      "### Epoch 3\n",
      "#########################\n",
      "Train_loss[0.17861679]\n",
      "Val_loss[0.3171038]\n",
      "\n",
      "#########################\n",
      "### Epoch 4\n",
      "#########################\n",
      "Train_loss[0.09120981]\n",
      "Val_loss[0.19986261]\n",
      "\n",
      "#########################\n",
      "### Epoch 5\n",
      "#########################\n",
      "Train_loss[0.055273972]\n",
      "Val_loss[0.1392124]\n",
      "\n",
      "#########################\n",
      "### Epoch 6\n",
      "#########################\n",
      "Train_loss[0.03336028]\n",
      "Val_loss[0.1044071]\n",
      "\n",
      "#########################\n",
      "### Epoch 7\n",
      "#########################\n",
      "Train_loss[0.022710968]\n",
      "Val_loss[0.08332996]\n",
      "\n",
      "#########################\n",
      "### Epoch 8\n",
      "#########################\n",
      "Train_loss[0.017825974]\n",
      "Val_loss[0.07089663]\n",
      "\n",
      "#########################\n",
      "### Epoch 9\n",
      "#########################\n",
      "Train_loss[0.016420892]\n",
      "Val_loss[0.06288731]\n",
      "\n",
      "#########################\n",
      "### Epoch 10\n",
      "#########################\n",
      "Train_loss[0.016230654]\n",
      "Val_loss[0.057369225]\n",
      "\n",
      "#########################\n",
      "### Epoch 11\n",
      "#########################\n",
      "Train_loss[0.01747718]\n",
      "Val_loss[0.05331611]\n",
      "\n",
      "#########################\n",
      "### Epoch 12\n",
      "#########################\n",
      "Train_loss[0.018518351]\n",
      "Val_loss[0.050168205]\n",
      "\n",
      "#########################\n",
      "### Epoch 13\n",
      "#########################\n",
      "Train_loss[0.020714166]\n",
      "Val_loss[0.047666803]\n",
      "\n",
      "#########################\n",
      "### Epoch 14\n",
      "#########################\n",
      "Train_loss[0.022744186]\n",
      "Val_loss[0.045147523]\n",
      "\n",
      "#########################\n",
      "### Epoch 15\n",
      "#########################\n",
      "Train_loss[0.02388469]\n",
      "Val_loss[0.04215915]\n",
      "\n",
      "#########################\n",
      "### Epoch 16\n",
      "#########################\n",
      "Train_loss[0.021779072]\n",
      "Val_loss[0.0387312]\n",
      "\n",
      "#########################\n",
      "### Epoch 17\n",
      "#########################\n",
      "Train_loss[0.018553706]\n",
      "Val_loss[0.035316065]\n",
      "\n",
      "#########################\n",
      "### Epoch 18\n",
      "#########################\n",
      "Train_loss[0.014940213]\n",
      "Val_loss[0.032100536]\n",
      "\n",
      "#########################\n",
      "### Epoch 19\n",
      "#########################\n",
      "Train_loss[0.011764234]\n",
      "Val_loss[0.029812835]\n",
      "\n",
      "#########################\n",
      "### Epoch 20\n",
      "#########################\n",
      "Train_loss[0.009162674]\n",
      "Val_loss[0.027833693]\n",
      "\n",
      "#########################\n",
      "### Epoch 21\n",
      "#########################\n",
      "Train_loss[0.0071422723]\n",
      "Val_loss[0.026335059]\n",
      "\n",
      "#########################\n",
      "### Epoch 22\n",
      "#########################\n",
      "Train_loss[0.0062758033]\n",
      "Val_loss[0.024961036]\n",
      "\n",
      "#########################\n",
      "### Epoch 23\n",
      "#########################\n",
      "Train_loss[0.005420912]\n",
      "Val_loss[0.02386448]\n",
      "\n",
      "#########################\n",
      "### Epoch 24\n",
      "#########################\n",
      "Train_loss[0.0046860124]\n",
      "Val_loss[0.022695426]\n",
      "\n",
      "#########################\n",
      "### Epoch 25\n",
      "#########################\n",
      "Train_loss[0.004515448]\n",
      "Val_loss[0.021706508]\n",
      "\n",
      "#########################\n",
      "### Epoch 26\n",
      "#########################\n",
      "Train_loss[0.0046937927]\n",
      "Val_loss[0.02072708]\n",
      "\n",
      "#########################\n",
      "### Epoch 27\n",
      "#########################\n",
      "Train_loss[0.0051792827]\n",
      "Val_loss[0.019921627]\n",
      "\n",
      "#########################\n",
      "### Epoch 28\n",
      "#########################\n",
      "Train_loss[0.006002597]\n",
      "Val_loss[0.019251518]\n",
      "\n",
      "#########################\n",
      "### Epoch 29\n",
      "#########################\n",
      "Train_loss[0.0069869356]\n",
      "Val_loss[0.01838687]\n",
      "\n",
      "#########################\n",
      "### Epoch 30\n",
      "#########################\n",
      "Train_loss[0.0077565257]\n",
      "Val_loss[0.017721547]\n",
      "\n",
      "#########################\n",
      "### Epoch 31\n",
      "#########################\n",
      "Train_loss[0.008216417]\n",
      "Val_loss[0.017157907]\n",
      "\n",
      "#########################\n",
      "### Epoch 32\n",
      "#########################\n",
      "Train_loss[0.008502014]\n",
      "Val_loss[0.016582849]\n",
      "\n",
      "#########################\n",
      "### Epoch 33\n",
      "#########################\n",
      "Train_loss[0.008495345]\n",
      "Val_loss[0.016062494]\n",
      "\n",
      "#########################\n",
      "### Epoch 34\n",
      "#########################\n",
      "Train_loss[0.009150332]\n",
      "Val_loss[0.015652698]\n",
      "\n",
      "#########################\n",
      "### Epoch 35\n",
      "#########################\n",
      "Train_loss[0.009653987]\n",
      "Val_loss[0.015335525]\n",
      "\n",
      "#########################\n",
      "### Epoch 36\n",
      "#########################\n",
      "Train_loss[0.009658548]\n",
      "Val_loss[0.0148377195]\n",
      "\n",
      "#########################\n",
      "### Epoch 37\n",
      "#########################\n",
      "Train_loss[0.00981899]\n",
      "Val_loss[0.0146308895]\n",
      "\n",
      "#########################\n",
      "### Epoch 38\n",
      "#########################\n",
      "Train_loss[0.0096769]\n",
      "Val_loss[0.01416825]\n",
      "\n",
      "#########################\n",
      "### Epoch 39\n",
      "#########################\n",
      "Train_loss[0.009399739]\n",
      "Val_loss[0.013813294]\n",
      "\n",
      "#########################\n",
      "### Epoch 40\n",
      "#########################\n",
      "Train_loss[0.009249779]\n",
      "Val_loss[0.013324375]\n",
      "\n",
      "#########################\n",
      "### Epoch 41\n",
      "#########################\n",
      "Train_loss[0.009070143]\n",
      "Val_loss[0.012936139]\n",
      "\n",
      "#########################\n",
      "### Epoch 42\n",
      "#########################\n",
      "Train_loss[0.008679349]\n",
      "Val_loss[0.012607986]\n",
      "\n",
      "#########################\n",
      "### Epoch 43\n",
      "#########################\n",
      "Train_loss[0.0084945485]\n",
      "Val_loss[0.012202661]\n",
      "\n",
      "#########################\n",
      "### Epoch 44\n",
      "#########################\n",
      "Train_loss[0.007840633]\n",
      "Val_loss[0.011559856]\n",
      "\n",
      "#########################\n",
      "### Epoch 45\n",
      "#########################\n",
      "Train_loss[0.0059580756]\n",
      "Val_loss[0.01055766]\n",
      "\n",
      "#########################\n",
      "### Epoch 46\n",
      "#########################\n",
      "Train_loss[0.0035855346]\n",
      "Val_loss[0.009485015]\n",
      "\n",
      "#########################\n",
      "### Epoch 47\n",
      "#########################\n",
      "Train_loss[0.0017367139]\n",
      "Val_loss[0.009177795]\n",
      "\n",
      "#########################\n",
      "### Epoch 48\n",
      "#########################\n",
      "Train_loss[0.0011205667]\n",
      "Val_loss[0.009921031]\n",
      "\n",
      "#########################\n",
      "### Epoch 49\n",
      "#########################\n",
      "Train_loss[0.0016249614]\n",
      "Val_loss[0.011773073]\n",
      "\n",
      "#########################\n",
      "### Epoch 50\n",
      "#########################\n",
      "Train_loss[0.0026850277]\n",
      "Val_loss[0.013625192]\n",
      "\n",
      "#########################\n",
      "### Epoch 51\n",
      "#########################\n",
      "Train_loss[0.0036594067]\n",
      "Val_loss[0.014942118]\n",
      "\n",
      "#########################\n",
      "### Epoch 52\n",
      "#########################\n",
      "Train_loss[0.003967199]\n",
      "Val_loss[0.014999137]\n",
      "\n",
      "#########################\n",
      "### Epoch 53\n",
      "#########################\n",
      "Train_loss[0.0041656233]\n",
      "Val_loss[0.014887856]\n",
      "\n",
      "#########################\n",
      "### Epoch 54\n",
      "#########################\n",
      "Train_loss[0.004036681]\n",
      "Val_loss[0.014363173]\n",
      "\n",
      "#########################\n",
      "### Epoch 55\n",
      "#########################\n",
      "Train_loss[0.0034769145]\n",
      "Val_loss[0.0129762]\n",
      "\n",
      "#########################\n",
      "### Epoch 56\n",
      "#########################\n",
      "Train_loss[0.0031945768]\n",
      "Val_loss[0.011680787]\n",
      "\n",
      "#########################\n",
      "### Epoch 57\n",
      "#########################\n",
      "Train_loss[0.0032496636]\n",
      "Val_loss[0.011524493]\n",
      "\n",
      "#########################\n",
      "### Epoch 58\n",
      "#########################\n",
      "Train_loss[0.004244678]\n",
      "Val_loss[0.013208461]\n",
      "\n",
      "#########################\n",
      "### Epoch 59\n",
      "#########################\n",
      "Train_loss[0.0062348084]\n",
      "Val_loss[0.016237678]\n",
      "\n",
      "#########################\n",
      "### Epoch 60\n",
      "#########################\n",
      "Train_loss[0.00860624]\n",
      "Val_loss[0.019918315]\n",
      "\n",
      "#########################\n",
      "### Epoch 61\n",
      "#########################\n",
      "Train_loss[0.008850708]\n",
      "Val_loss[0.020974953]\n",
      "\n",
      "#########################\n",
      "### Epoch 62\n",
      "#########################\n",
      "Train_loss[0.0065625263]\n",
      "Val_loss[0.018259859]\n",
      "\n",
      "#########################\n",
      "### Epoch 63\n",
      "#########################\n",
      "Train_loss[0.003430677]\n",
      "Val_loss[0.014081828]\n",
      "\n",
      "#########################\n",
      "### Epoch 64\n",
      "#########################\n",
      "Train_loss[0.0016740207]\n",
      "Val_loss[0.01089642]\n",
      "\n",
      "#########################\n",
      "### Epoch 65\n",
      "#########################\n",
      "Train_loss[0.000968958]\n",
      "Val_loss[0.0093058]\n",
      "\n",
      "#########################\n",
      "### Epoch 66\n",
      "#########################\n",
      "Train_loss[0.0007532329]\n",
      "Val_loss[0.008473635]\n",
      "\n",
      "#########################\n",
      "### Epoch 67\n",
      "#########################\n",
      "Train_loss[0.0008065329]\n",
      "Val_loss[0.007941706]\n",
      "\n",
      "#########################\n",
      "### Epoch 68\n",
      "#########################\n",
      "Train_loss[0.00081964146]\n",
      "Val_loss[0.007724934]\n",
      "\n",
      "#########################\n",
      "### Epoch 69\n",
      "#########################\n",
      "Train_loss[0.0007244593]\n",
      "Val_loss[0.008119507]\n",
      "\n",
      "#########################\n",
      "### Epoch 70\n",
      "#########################\n",
      "Train_loss[0.0010866688]\n",
      "Val_loss[0.009195014]\n",
      "\n",
      "#########################\n",
      "### Epoch 71\n",
      "#########################\n",
      "Train_loss[0.0014341226]\n",
      "Val_loss[0.010017633]\n",
      "\n",
      "#########################\n",
      "### Epoch 72\n",
      "#########################\n",
      "Train_loss[0.0022173233]\n",
      "Val_loss[0.011843082]\n",
      "\n",
      "#########################\n",
      "### Epoch 73\n",
      "#########################\n",
      "Train_loss[0.0025102063]\n",
      "Val_loss[0.012392589]\n",
      "\n",
      "#########################\n",
      "### Epoch 74\n",
      "#########################\n",
      "Train_loss[0.0025758715]\n",
      "Val_loss[0.012650241]\n",
      "\n",
      "#########################\n",
      "### Epoch 75\n",
      "#########################\n",
      "Train_loss[0.0011488509]\n",
      "Val_loss[0.010307371]\n",
      "\n",
      "#########################\n",
      "### Epoch 76\n",
      "#########################\n",
      "Train_loss[0.0006611966]\n",
      "Val_loss[0.009351347]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Epoch 77\n",
      "#########################\n",
      "Train_loss[0.00036801153]\n",
      "Val_loss[0.008534794]\n",
      "\n",
      "#########################\n",
      "### Epoch 78\n",
      "#########################\n",
      "Train_loss[0.00028591097]\n",
      "Val_loss[0.008323734]\n",
      "\n",
      "#########################\n",
      "### Epoch 79\n",
      "#########################\n",
      "Train_loss[0.00059692934]\n",
      "Val_loss[0.009463899]\n",
      "\n",
      "#########################\n",
      "### Epoch 80\n",
      "#########################\n",
      "Train_loss[0.0016068676]\n",
      "Val_loss[0.011411827]\n",
      "\n",
      "#########################\n",
      "### Epoch 81\n",
      "#########################\n",
      "Train_loss[0.004102755]\n",
      "Val_loss[0.015774058]\n",
      "\n",
      "#########################\n",
      "### Epoch 82\n",
      "#########################\n",
      "Train_loss[0.00596621]\n",
      "Val_loss[0.018051976]\n",
      "\n",
      "#########################\n",
      "### Epoch 83\n",
      "#########################\n",
      "Train_loss[0.008488861]\n",
      "Val_loss[0.021664822]\n",
      "\n",
      "#########################\n",
      "### Epoch 84\n",
      "#########################\n",
      "Train_loss[0.009003629]\n",
      "Val_loss[0.021794397]\n",
      "\n",
      "#########################\n",
      "### Epoch 85\n",
      "#########################\n",
      "Train_loss[0.009448786]\n",
      "Val_loss[0.022263892]\n",
      "\n",
      "#########################\n",
      "### Epoch 86\n",
      "#########################\n",
      "Train_loss[0.010994322]\n",
      "Val_loss[0.024695784]\n",
      "\n",
      "#########################\n",
      "### Epoch 87\n",
      "#########################\n",
      "Train_loss[0.009006759]\n",
      "Val_loss[0.021075351]\n",
      "\n",
      "#########################\n",
      "### Epoch 88\n",
      "#########################\n",
      "Train_loss[0.010581059]\n",
      "Val_loss[0.023494044]\n",
      "\n",
      "#########################\n",
      "### Epoch 89\n",
      "#########################\n",
      "Train_loss[0.010109664]\n",
      "Val_loss[0.022697683]\n",
      "\n",
      "#########################\n",
      "### Epoch 90\n",
      "#########################\n",
      "Train_loss[0.010689858]\n",
      "Val_loss[0.023260746]\n",
      "\n",
      "#########################\n",
      "### Epoch 91\n",
      "#########################\n",
      "Train_loss[0.011963296]\n",
      "Val_loss[0.025012914]\n",
      "\n",
      "#########################\n",
      "### Epoch 92\n",
      "#########################\n",
      "Train_loss[0.012081972]\n",
      "Val_loss[0.025119202]\n",
      "\n",
      "#########################\n",
      "### Epoch 93\n",
      "#########################\n",
      "Train_loss[0.012414441]\n",
      "Val_loss[0.025258418]\n",
      "\n",
      "#########################\n",
      "### Epoch 94\n",
      "#########################\n",
      "Train_loss[0.012243419]\n",
      "Val_loss[0.025015341]\n",
      "\n",
      "#########################\n",
      "### Epoch 95\n",
      "#########################\n",
      "Train_loss[0.01250471]\n",
      "Val_loss[0.025507662]\n",
      "\n",
      "#########################\n",
      "### Epoch 96\n",
      "#########################\n",
      "Train_loss[0.009551295]\n",
      "Val_loss[0.022574322]\n",
      "\n",
      "#########################\n",
      "### Epoch 97\n",
      "#########################\n",
      "Train_loss[0.005948403]\n",
      "Val_loss[0.01780318]\n",
      "\n",
      "#########################\n",
      "### Epoch 98\n",
      "#########################\n",
      "Train_loss[0.0003719671]\n",
      "Val_loss[0.011392451]\n",
      "\n",
      "#########################\n",
      "### Epoch 99\n",
      "#########################\n",
      "Train_loss[0.0029737744]\n",
      "Val_loss[0.010776869]\n",
      "\n",
      "#########################\n",
      "### Epoch 100\n",
      "#########################\n",
      "Train_loss[0.0023141732]\n",
      "Val_loss[0.009501078]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    train_loss_history = [] # lossを１エポック毎に保存するリスト\n",
    "    val_loss_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int64)\n",
    "        \n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "\n",
    "        train_loss = sess.run([loss_op], feed_dict={X: mini_batch_x, Y: mini_batch_y}) # 分類問題の時に有ったaccuracyは消去\n",
    "        train_loss_history.append(train_loss) # lossを１エポック毎に保存\n",
    "            \n",
    "        total_loss /= n_samples\n",
    "        val_loss = sess.run([loss_op], feed_dict={X: X_val, Y: y_val})\n",
    "        val_loss_history.append(val_loss)\n",
    "        \n",
    "        print('#'*25)\n",
    "        print('### Epoch %i'%(epoch+1))\n",
    "        print('#'*25)\n",
    "        \n",
    "        print(\"Train_loss\" + str(train_loss))\n",
    "        print(\"Val_loss\" + str(val_loss))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeTUlEQVR4nO3deZBcdd3v8ff3LNM9kz0hQkiUhGJTEwkyQHhQnis8F8MiWKAYBVnq0RTiErnCA9zn6iMU3rLutXCpi6FQkVvCRRBEEXlAZRFBWSYaIUAWwGgGlEwCgWwzvZzv/eOcWZJMmJ5kOn0y/XlVdfV2+pzvr3v6M7/+nc3cHRERya+g0QWIiMhbU1CLiOScglpEJOcU1CIiOaegFhHJuageM91nn3185syZ9Zi1iMiotGTJknXuPnWw5+oS1DNnzqSjo6MesxYRGZXM7K87e05DHyIiOaegFhHJOQW1iEjO1WWMWkRGn3K5TGdnJ93d3Y0uZa9WLBaZMWMGcRzX/BoFtYjUpLOzk3HjxjFz5kzMrNHl7JXcnfXr19PZ2cmsWbNqfp2GPkSkJt3d3UyZMkUhvRvMjClTpgz7V4mCWkRqppDefbvyHtYU1GY20czuMLPlZva8mR077CXV4rf/C174TV1mLSKyt6q1R/1t4D53Pww4HHi+LtU8+i148aG6zFpEZG81ZFCb2XjgeOAHAO5ecvcNdakmjKBarsusRWTvtmHDBr773e8O+3WnnHIKGzZsGPbrLrjgAu64445hv64eaulRHwh0AT80sz+Z2ffNbMz2E5nZQjPrMLOOrq6uXasmbIFqaddeKyKj2s6CulqtvuXr7r33XiZOnFinqvaMWjbPi4D3Ap939yfM7NvAFcCXB07k7jcANwC0t7fv2vm9whZI1KMWyburfvEsz73y5ojO8137j+c/PvTunT5/xRVX8OKLLzJ37lziOGbs2LFMmzaNpUuX8txzz/HhD3+YNWvW0N3dzaJFi1i4cCHQf+yhTZs2cfLJJ/O+972P3//+90yfPp2f//zntLa2DlnbAw88wKWXXkqlUuGoo45i8eLFFAoFrrjiCu6++26iKOKkk07iG9/4Bj/5yU+46qqrCMOQCRMm8Mgjj+z2e1NLUHcCne7+RHb/DtKgHnmBhj5EZHBf//rXWbZsGUuXLuXhhx/m1FNPZdmyZX3bI994441MnjyZrVu3ctRRR3HWWWcxZcqUbeaxatUqbr31Vr73ve9x9tlnc+edd3Luuee+5XK7u7u54IILeOCBBzjkkEM477zzWLx4Meeddx533XUXy5cvx8z6hleuvvpq7r//fqZPn75LQy6DGTKo3f0fZrbGzA519xXAicBzI7L07YUtCmqRvcBb9Xz3lKOPPnqbnUa+853vcNdddwGwZs0aVq1atUNQz5o1i7lz5wJw5JFHsnr16iGXs2LFCmbNmsUhhxwCwPnnn891113H5z73OYrFIp/61Kc49dRTOe200wA47rjjuOCCCzj77LM588wzR6CltW/18XngFjN7GpgL/M8RWfr2NEYtIjUaM6Z/VdnDDz/Mb37zG/7whz/w5z//mSOOOGLQnUoKhULf7TAMqVQqQy7HffCR3CiKePLJJznrrLP42c9+xvz58wG4/vrrueaaa1izZg1z585l/fr1w23ajsuqZSJ3Xwq07/bShqKtPkRkJ8aNG8fGjRsHfe6NN95g0qRJtLW1sXz5ch5//PERW+5hhx3G6tWreeGFFzjooIP40Y9+xD//8z+zadMmtmzZwimnnMK8efM46KCDAHjxxRc55phjOOaYY/jFL37BmjVrdujZD1e+jvWhlYkishNTpkzhuOOOY/bs2bS2trLvvvv2PTd//nyuv/563vOe93DooYcyb968EVtusVjkhz/8IR/96Ef7ViZedNFFvPbaa5xxxhl0d3fj7nzzm98E4LLLLmPVqlW4OyeeeCKHH374btdgO+vW74729nbfpTO83HgyBCFccM+I1yQiu+f555/nne98Z6PLGBUGey/NbIm7Dzpyka9jfYSxxqhFRLaTv6GPnsHHoERE6uGzn/0sjz322DaPLVq0iAsvvLBBFe0oZ0Eda2WiiOxR1113XaNLGFL+hj60MlFEZBv5CupAY9QiItvLV1Brz0QRkR3kLKg1Ri0isr0cBrWGPkRk940dO3anz61evZrZs2fvwWp2T86CugWSofe9FxFpJvnaPC+I1KMW2Rv85xXwj2dGdp77zYGTv77Tpy+//HIOOOAALr74YgC++tWvYmY88sgjvP7665TLZa655hrOOOOMYS22u7ubz3zmM3R0dBBFEddeey0f+MAHePbZZ7nwwgsplUokScKdd97J/vvvz9lnn01nZyfVapUvf/nLfOxjH9utZtciX0Gto+eJyE4sWLCAL37xi31Bffvtt3PfffdxySWXMH78eNatW8e8efM4/fTTh3Wm797tqJ955hmWL1/OSSedxMqVK7n++utZtGgR55xzDqVSiWq1yr333sv+++/PL3/5SyA9GNSekL+g9gSSanrMDxHJp7fo+dbLEUccwdq1a3nllVfo6upi0qRJTJs2jUsuuYRHHnmEIAh4+eWXefXVV9lvv/1qnu+jjz7K5z//eSA9Ut4BBxzAypUrOfbYY/na175GZ2cnZ555JgcffDBz5szh0ksv5fLLL+e0007j/e9/f72au42cjVFn/ze05YeIDOIjH/kId9xxB7fddhsLFizglltuoauriyVLlrB06VL23XffQY9D/VZ2dmC6T3ziE9x99920trbywQ9+kAcffJBDDjmEJUuWMGfOHK688kquvvrqkWjWkPLXo4Z0+CMuNrYWEcmdBQsW8OlPf5p169bx29/+lttvv523ve1txHHMQw89xF//+tdhz/P444/nlltu4YQTTmDlypX87W9/49BDD+Wll17iwAMP5Atf+AIvvfQSTz/9NIcddhiTJ0/m3HPPZezYsdx0000j38hB5DOoteWHiAzi3e9+Nxs3bmT69OlMmzaNc845hw996EO0t7czd+5cDjvssGHP8+KLL+aiiy5izpw5RFHETTfdRKFQ4LbbbuPmm28mjmP2228/vvKVr/DUU09x2WWXEQQBcRyzePHiOrRyR/k6HvVTP4Bf/jf40goYV/sYk4jUn45HPXL28uNR9w59aIxaRKRXzoY+4vRam+iJyAh45pln+OQnP7nNY4VCgSeeeKJBFe2anAa1etQieeTuw9pGudHmzJnD0qVLG13GNnZluDmfQx86JrVI7hSLRdavX79LQSMpd2f9+vUUi8Pbqi1fPepAQx8ieTVjxgw6Ozvp6upqdCl7tWKxyIwZM4b1mnwFdd/QhzbPE8mbOI6ZNWtWo8toSjUFtZmtBjYCVaCys01IdptWJoqI7GA4PeoPuPu6ulUC2+6ZKCIiQO5WJmY9au2ZKCLSp9agduBXZrbEzBYONoGZLTSzDjPr2OWVDVqZKCKyg1qD+jh3fy9wMvBZMzt++wnc/QZ3b3f39qlTp+5aNdozUURkBzUFtbu/kl2vBe4Cjq5LNdrhRURkB0MGtZmNMbNxvbeBk4BldalGW32IiOyglq0+9gXuynYbjYD/5+731aUa7ZkoIrKDIYPa3V8CDt8DtfDJm/7Ij0BDHyIiA+Rq87xV63rSGxr6EBHpk6ugDiJt9SEisr1cBXWooBYR2UGugjqOYxICrUwUERkgV0HdEgVULdQYtYjIALkK6kIcUiHW0IeIyAD5CuoooGyRglpEZIDcBXUFDX2IiAyUs6AOqRDpMKciIgPkK6jjgLKrRy0iMlC+gjoKKBEpqEVEBshZUIeUPNLJbUVEBshZUAeUtTJRRGQb+QrqOKDHQ+2ZKCIyQL6COgope4irRy0i0idnQR1Q8givKKhFRHrlLqjLRCTaM1FEpE++gjoO0z0T1aMWEemTr6DOetQaoxYR6Ze7oE53eNF21CIivXIW1CEV7UIuIrKNfAV1nA59aDtqEZF++QrqbM9E01YfIiJ9ag5qMwvN7E9mdk+9iilEIWUiTD1qEZE+w+lRLwKer1ch0L/Vh4JaRKRfTUFtZjOAU4Hv17OYYpwOfQRJGdzruSgRkb1GrT3qbwH/BiT1K6X3WB9Reiep1nNRIiJ7jSGD2sxOA9a6+5IhpltoZh1m1tHV1bVLxfSdMxG0iZ6ISKaWHvVxwOlmthr4MXCCmd28/UTufoO7t7t7+9SpU3epmN6ViYCCWkQkM2RQu/uV7j7D3WcCC4AH3f3cehRTiLM9E0EnuBURyeRuO2oNfYiIbCsazsTu/jDwcF0qAcyMJIjTOwpqEREgZz1qAAt7g1pDHyIikMOg9qAlvaEetYgIkMOgprdHrb0TRUSAHAZ1EPUOfSioRUQgh0FNWEivNfQhIgLkMKj7VyaqRy0iAjkMag19iIhsK39BHWdDH1qZKCIC5DGoQ+3wIiIyUO6COuztUWvoQ0QEyGFQB5GCWkRkoNwFdRRr6ENEZKDcBXWolYkiItvIXVBHce+xPhTUIiKQy6BOe9Re0dCHiAjkMahb0qCuKKhFRIAcBnWc9air5Z4GVyIikg+5C+pCHFL2UEEtIpLJX1Bn502sVrQyUUQE8hjUcUiZiEQ9ahERYJgnt90TClFAiQhTj1pEBMhjjzob+tDmeSIiqRwGdUjZI5Kqhj5ERCCPQR2nQx+uoQ8REaCGoDazopk9aWZ/NrNnzeyqehbUN/ShXchFRIDaVib2ACe4+yYzi4FHzew/3f3xehRUiEK6iRTUIiKZIXvUntqU3Y2zi9eroN4etQ5zKiKSqmmM2sxCM1sKrAV+7e5PDDLNQjPrMLOOrq6uXS6od4zaFNQiIkCNQe3uVXefC8wAjjaz2YNMc4O7t7t7+9SpU3e5oN6tPqhWdnkeIiKjybC2+nD3DcDDwPx6FAP9Qx+WqEctIgK1bfUx1cwmZrdbgX8BlteroL49E3WGFxERoLatPqYB/9fMQtJgv93d76lXQWZGYhGWaOhDRARqCGp3fxo4Yg/U0qcaRATqUYuIADncMxEgsRb1qEVEMrkMag8iQlePWkQEchrUSRATKKhFRICcBnXao9bQh4gI5DaoWxTUIiKZnAZ1rKAWEcnkMqgtjImoQpI0uhQRkYbLZVATxum1tqUWEclpUEct6bWOSS0iks+gtt4etQ51KiKS16DOetTaO1FEJJ9BHfQNfahHLSKSy6A2BbWISJ9cBnVvjzqpaGWiiEgugzrMgrpc6mlwJSIijZfLoO7tUZd7uhtciYhI4+UyqMM43TyvVFaPWkQkp0FdAKCioQ8RkXwGdRSlQV0ua6sPEZF8BnWslYkiIr3yGdQt2dCHxqhFRHIa1FmPulrR0IeISC6DOs561FX1qEVE8hrURQCqZe2ZKCIyZFCb2dvN7CEze97MnjWzRfUuKm7pHfpQj1pEJKphmgrwJXf/o5mNA5aY2a/d/bl6FdWSDX0k2jxPRGToHrW7/93d/5jd3gg8D0yvZ1EthVYAEq1MFBEZ3hi1mc0EjgCeGOS5hWbWYWYdXV1du1VUS6H36HkKahGRmoPazMYCdwJfdPc3t3/e3W9w93Z3b586depuFVUopCsTE50zUUSktqA2s5g0pG9x95/WtyRoibJzJqpHLSJS01YfBvwAeN7dr61/SWBBQMkjXGd4ERGpqUd9HPBJ4AQzW5pdTqlzXZQtwjX0ISIy9OZ57v4oYHuglm1UiHTORBERcrpnIkDFIlznTBQRyW9QVy3GtWeiiEh+g7o7GEtLZWOjyxARabjcBvXWaBzFyg6ba4uINJ3cBnUpHk9rsrnRZYiINFxug7oaj2esa+hDRCS/QV0YzzjfTJJ4o0sREWmo3Aa1Fycy1rrZ0qMtP0SkueU2qClOBGDTG+saW4eISIPlNqjDtokAbH1jfWMLERFpsNwGdTRmEgDdGxXUItLcchvU8dgpAPRser3BlYiINFZug7p1XNqjrm5WUItIc8tvUI/fB4Dqlg2NLUREpMFyG9RtE9KhD9+6obGFiIg0WG6DekzbGHo8wro3NLoUEZGGym1QWxCw0cYQ9LzR6FJERBoqt0ENsMnGEpV0BD0RaW65DuqtwVhadKhTEWly+Q7qcBwFnTxARJpcroO6Jx5PW1VBLSLNLddBXY7H06aTB4hIk8t1UCeF8YxlEyRJo0sREWmYIYPazG40s7VmtmxPFDRQUphIiOM9WqEoIs2rlh71TcD8OtcxuNaJAPRs3tCQxYuI5MGQQe3ujwCv7YFadhC0TgBgi04eICJNbMTGqM1soZl1mFlHV1fXiMwzapsMwNY3dUxqEWleIxbU7n6Du7e7e/vUqVNHZJ7x2PRQpyUdk1pEmliut/oojEuPoFfe3JCRFxGRXMh1ULeOS4c+dPIAEWlmtWyedyvwB+BQM+s0s3+tf1mptnETqbrpmNQi0tSioSZw94/viUIGM761wJuMwbt1qFMRaV65HvoYW4x409sIdPIAEWliuQ7qMDA26pjUItLkch3UAFuCscRlBbWINK/cB7WOSS0izS73Qd0TjaNVx6QWkSaW+6AuxeNpSzY1ugwRkYbJfVBXChNooQzlrY0uRUSkIXIf1F4Yn97QTi8i0qRyH9QUJ6bX2pZaRJpU7oPaWtMj6FW26HgfItKcch/UYdtEALa+qSPoiUhzyn1Qx2PSI+j1bNTJA0SkOeU+qFvG6eQBItLcch/Uxd5jUmuMWkSaVO6DenxbK5u8SKKgFpEmlfugHluIeEPHpBaRJpb7oB5XjFjv45n42tPaO1FEmtJeENQx36qcxYTNf4FfLAL3RpckIrJH5T6oW6KAx4J2Hpn+aXj6Nnh8caNLEhHZo3If1JD2qu+ffC6880Pwq/8BLz7Y6JJERPaYvSSoI7o2l+HDi2GfQ+Dmj8BvvqoxaxFpCntFUM87cDK/fu5Vrvv9q/iF98Lcj8Oj34TFx8GqX0OSNLpEEZG6iRpdQC2uPmM2W0tV/vf9K9iwZRb//fT/g835aLpy8ZaPwPgZ8J6zYfaZ8LZ3QRA2umQRkRGzVwR1HAZce/ZcJra18L3f/YVVazdx/j+9i+M/8zjhynvhzz+Gx74Nj14LLeNgxpGw/3th8oEwaSZMfAeMmQotbY1uiojIsJnXsLmbmc0Hvg2EwPfd/etvNX17e7t3dHSMTIUDuDvf+91LXP/bl3htc4l9xxc4dc7+HD1rEu37lNnnH49B55Ow5ilY+xx4ddsZxGNgzBQoTIDieCiMT8M77r0UIWqFqJBewpbsugBh3P94NGC6uDW9RMX+a7MRb7uIjG5mtsTd2wd9bqigNrMQWAn8V6ATeAr4uLs/t7PX1Cuoe5UqCQ8uf5WfdHTyuxfWUaqkY9TTJhTZf2Ir0yYU2W9sxH62nv2qf2dyZS1t5ddpLb9OsfQ6LZWNxOVNRJWNhJWthJWtRNWthEkPYVLa7foqQYEkLJCERZIwC/wwhrAFy25bFGNBhIVR3zVBhAUhFoQQhJiF6eOW3sfC9J9A3+0gux30PecW4BiOkWC4heltC4AgfQxwAhzAAtwCwNL5YGCk83DDzUjSCbPX9U/nRjZ9+o9p4HNm6ePW+7wF2XTW/xoDswAzw/qWnb42fR8CwiAgCEOiKCYKQ8Iwytps2ywbT9Jt7JMqJGWoliGpZNe996vpP+9ku3/gA9mA9yH7HAjSzyb9HKJt/xG7p/NPKlDpwSvdJKVuqqWtVHs2Uy1twcvdeFLFso5DEBcJ4iJRSythcQxBYWzaiej9xx8VIIiz5W7/OQ/4rPrqMMCzfQx823Z60n8Z+N70Pe7bvhaDqCX9mw3iwZc/4LMCBiyvAtVK/zLKW6C0GUqboFJK35tKKX1vSltISlvwaiXbNcJxz+pwx5MKVEt4pSddRtyGtbRiQYRXSni1lC7LAggMCLOOmeNJgvd+/kllwL4X3veRbf+ZW7Z8c0+/n9lnFBTGEBXHEbWNJ2qdgLVNTk9mErf2fwYDv59hDJMO2Pnf11t4q6CuZejjaOAFd38pm9mPgTOAnQZ1vbVEAfNnT2P+7Gn0VKose/lNOla/xopXN/L3Dd0se/kNHtrYw+ZSFZiQXWpjJLRQoUCZFiq0UKY1qNAaVhkTVCkGFVqtTNHKtHiJKOkmTrqJkh4KXqJgJYqUKFBOr61MTIUWKsRUiOimxTYRUyEgISIhpEpIQkhCRJXQEoLs/sBLgPc9br2Pm29Xf3qB9OeP7FlZZOi9H8T2703FAyoD3qneDoYDVUJ6iChnEVWkRCslIqqUsscrhBje991IejsnGBVCykRUPe2cDFzGtjV577+5vuVHVClY+v1toYeCVWpu4+s2kUn/8ddden/eSi1BPR1YM+B+J3DM9hOZ2UJgIcA73vGOESmuFoUo5MgDJnHkAZN2eC5JnM2lCltLVaruVKpONXH6/r+6EwUBYWiEZgQBhGaEgRGHAVFoxEFAENQ2lFGuJnSXq3SXe6+rbB1wv6eSsLWaUKqkl3KSUKk65WpC4k41gcTT/+zVBKpZ7yLx9PFeWb+nj2WBHXqCWfZlsITAnMggtCohTmBGSJXA+v9Ag74/7bQ30dtvxp3AnICsE28Q4JilzxkJONt+Bfp6Z0l/72jA/PCkbzqH7Drp78mkH0rfY1QruDueVKkmVZJKlSSpUK1WSKoJiSdUEydJnCRrSYKRWEQSRCQWQRCTBBEepL9cPIj6evHQ2ylMbwf9vxmy3mbaKzWvEHiSXVf72+yOBwFYBGFMEsRYVMyGwYpYyxiCQhtBVOjriSYOSaWHSmkrSbkb79mMl7bgpc0ElW6s2oNVu7GkQuhV8ApB9t71xlDQ+/73vu/09hWt79dT+ssqTH8tWYBbGmkeRHgQp8/3/TLq//fuDkFSwpISQdbzNk8wqtnnmaTvBf2fV2IhiaXLSuedvf9RG0nchkdt0NJKELZgUQtBSyvEbcQtBaLA0s6Fkf6SIr0OA4iCgCj77pUTp1xJqLoTh5b+0urt0Hv6XQ7MCMzS70BgRIERZPPv+65Y//J627v996maOD2V9HvbU6nS091NuftNki1vkmxZj2/ZQFjtJgqNliD9rpmnv17ilgJn7iwgdkMtQT1YSu0wXuLuNwA3QDr0sZt1jYggMMYVY8YV4z2yvDgMiMOAccU9sjgRaRK1bEfdCbx9wP0ZwCv1KUdERLZXS1A/BRxsZrPMrAVYANxd37JERKTXkEMf7l4xs88B95MOf97o7s/WvTIREQFq3OHF3e8F7q1zLSIiMoi94lgfIiLNTEEtIpJzCmoRkZxTUIuI5FxNB2Ua9kzNuoBd3Y9yH2DdCJazN2jGNkNztrsZ2wzN2e7htvkAd5862BN1CerdYWYdOzswyWjVjG2G5mx3M7YZmrPdI9lmDX2IiOScglpEJOfyGNQ3NLqABmjGNkNztrsZ2wzN2e4Ra3PuxqhFRGRbeexRi4jIAApqEZGcy01Qm9l8M1thZi+Y2RWNrqdezOztZvaQmT1vZs+a2aLs8clm9mszW5Vd73jKmr2cmYVm9iczuye73wxtnmhmd5jZ8uwzP3a0t9vMLsn+tpeZ2a1mVhyNbTazG81srZktG/DYTttpZldm+bbCzD44nGXlIqizE+heB5wMvAv4uJm9q7FV1U0F+JK7vxOYB3w2a+sVwAPufjDwQHZ/tFkEPD/gfjO0+dvAfe5+GHA4aftHbbvNbDrwBaDd3WeTHhp5AaOzzTcB87d7bNB2Zt/xBcC7s9d8N8u92nh2jr5GXoBjgfsH3L8SuLLRde2htv+c9AzvK4Bp2WPTgBWNrm2E2zkj+8M9Abgne2y0t3k88BeylfYDHh+17ab/HKuTSQ+jfA9w0mhtMzATWDbUZ7t9ppEe3//YWpeTix41g59Ad3qDatljzGwmcATwBLCvu/8dILt+WwNLq4dvAf8GfWdlhdHf5gOBLuCH2ZDP981sDKO43e7+MvAN4G/A34E33P1XjOI2b2dn7dytjMtLUNd0At3RxMzGAncCX3T3NxtdTz2Z2WnAWndf0uha9rAIeC+w2N2PADYzOn7y71Q2JnsGMAvYHxhjZuc2tqpc2K2My0tQN9UJdM0sJg3pW9z9p9nDr5rZtOz5acDaRtVXB8cBp5vZauDHwAlmdjOju82Q/l13uvsT2f07SIN7NLf7X4C/uHuXu5eBnwL/xOhu80A7a+duZVxegrppTqBrZgb8AHje3a8d8NTdwPnZ7fNJx65HBXe/0t1nuPtM0s/2QXc/l1HcZgB3/wewxswOzR46EXiO0d3uvwHzzKwt+1s/kXQF6mhu80A7a+fdwAIzK5jZLOBg4Mma59rowfgBg+unACuBF4F/b3Q9dWzn+0h/8jwNLM0upwBTSFe2rcquJze61jq1/7/QvzJx1LcZmAt0ZJ/3z4BJo73dwFXAcmAZ8COgMBrbDNxKOg5fJu0x/+tbtRP49yzfVgAnD2dZ2oVcRCTn8jL0ISIiO6GgFhHJOQW1iEjOKahFRHJOQS0iknMKahGRnFNQi4jk3P8Ht9rTeo40OqgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(num_epochs), train_loss_history, label=\"train_loss\")\n",
    "plt.plot(np.arange(num_epochs), val_loss_history, label=\"val_loss\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】MNISTのモデルを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 平滑化\n",
    "    \n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# 正規化\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# One-Hot 表現に符号化\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 784), (48000, 10))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8:2にtrain_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# trainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teruitakahiro/opt/anaconda3/envs/data_science/lib/python3.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01 # 0.001 → 0.01\n",
    "batch_size = 20 # 10 → 20\n",
    "num_epochs = 20 # 100 → 20\n",
    "n_hidden1 = 400 # 50 → 400\n",
    "n_hidden2 = 100 # 100 → 200\n",
    "n_input = X_train.shape[1] # 784\n",
    "n_samples = X_train.shape[0] # 48000\n",
    "n_classes = 10 # 3 → 10\n",
    "\n",
    "# 計算グラフに渡す引数の形を決める\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_net(x):\n",
    "    \n",
    "    \"\"\"\n",
    "    単純な3層ニューラルネットワーク\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.random.set_random_seed(0)\n",
    "    \n",
    "    # 重みとバイアスの宣言\n",
    "    weights = {\n",
    "                     'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n",
    "                     'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n",
    "                     'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n",
    "                     }\n",
    "    \n",
    "    biases = {\n",
    "                   'b1': tf.Variable(tf.random_normal([n_hidden1])),\n",
    "                   'b2': tf.Variable(tf.random_normal([n_hidden2])),\n",
    "                   'b3': tf.Variable(tf.random_normal([n_classes]))\n",
    "                   }\n",
    "    \n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.keras.activations.sigmoid(layer_1) # tf.nn.relu() → sigmoid()\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.keras.activations.sigmoid(layer_2) # tf.nn.relu() → sigmoid()\n",
    "    \n",
    "    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3']\n",
    "    \n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワーク構造の読み込み                               \n",
    "logits = example_net(X) \n",
    "\n",
    "# 目的関数\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=Y, logits=logits)) \n",
    "\n",
    "# 最適化手法\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate) #Adam → GD\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 推定結果\n",
    "correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(logits, 1))\n",
    "\n",
    "# 指標値計算\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# variableの初期化\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################\n",
      "### Epoch 1\n",
      "###################################\n",
      "loss : 0.1153, val_loss : 1.4030, acc : 0.571\n",
      "\n",
      "###################################\n",
      "### Epoch 2\n",
      "###################################\n",
      "loss : 0.0552, val_loss : 0.9986, acc : 0.677\n",
      "\n",
      "###################################\n",
      "### Epoch 3\n",
      "###################################\n",
      "loss : 0.0428, val_loss : 0.8297, acc : 0.730\n",
      "\n",
      "###################################\n",
      "### Epoch 4\n",
      "###################################\n",
      "loss : 0.0367, val_loss : 0.7332, acc : 0.760\n",
      "\n",
      "###################################\n",
      "### Epoch 5\n",
      "###################################\n",
      "loss : 0.0329, val_loss : 0.6692, acc : 0.782\n",
      "\n",
      "###################################\n",
      "### Epoch 6\n",
      "###################################\n",
      "loss : 0.0303, val_loss : 0.6229, acc : 0.798\n",
      "\n",
      "###################################\n",
      "### Epoch 7\n",
      "###################################\n",
      "loss : 0.0282, val_loss : 0.5872, acc : 0.810\n",
      "\n",
      "###################################\n",
      "### Epoch 8\n",
      "###################################\n",
      "loss : 0.0266, val_loss : 0.5586, acc : 0.820\n",
      "\n",
      "###################################\n",
      "### Epoch 9\n",
      "###################################\n",
      "loss : 0.0253, val_loss : 0.5349, acc : 0.827\n",
      "\n",
      "###################################\n",
      "### Epoch 10\n",
      "###################################\n",
      "loss : 0.0241, val_loss : 0.5148, acc : 0.835\n",
      "\n",
      "###################################\n",
      "### Epoch 11\n",
      "###################################\n",
      "loss : 0.0232, val_loss : 0.4975, acc : 0.840\n",
      "\n",
      "###################################\n",
      "### Epoch 12\n",
      "###################################\n",
      "loss : 0.0223, val_loss : 0.4825, acc : 0.846\n",
      "\n",
      "###################################\n",
      "### Epoch 13\n",
      "###################################\n",
      "loss : 0.0215, val_loss : 0.4693, acc : 0.850\n",
      "\n",
      "###################################\n",
      "### Epoch 14\n",
      "###################################\n",
      "loss : 0.0208, val_loss : 0.4575, acc : 0.855\n",
      "\n",
      "###################################\n",
      "### Epoch 15\n",
      "###################################\n",
      "loss : 0.0202, val_loss : 0.4468, acc : 0.857\n",
      "\n",
      "###################################\n",
      "### Epoch 16\n",
      "###################################\n",
      "loss : 0.0196, val_loss : 0.4372, acc : 0.859\n",
      "\n",
      "###################################\n",
      "### Epoch 17\n",
      "###################################\n",
      "loss : 0.0191, val_loss : 0.4284, acc : 0.863\n",
      "\n",
      "###################################\n",
      "### Epoch 18\n",
      "###################################\n",
      "loss : 0.0186, val_loss : 0.4204, acc : 0.865\n",
      "\n",
      "###################################\n",
      "### Epoch 19\n",
      "###################################\n",
      "loss : 0.0181, val_loss : 0.4129, acc : 0.867\n",
      "\n",
      "###################################\n",
      "### Epoch 20\n",
      "###################################\n",
      "loss : 0.0177, val_loss : 0.4060, acc : 0.869\n",
      "\n",
      "test_acc : 0.872\n"
     ]
    }
   ],
   "source": [
    "# 計算グラフの実行\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    train_loss_history2 = [] # train_lossを１エポック毎に保存するリスト\n",
    "    val_loss_history2 = [] # val_lossを１エポック毎に保存するリスト\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_batch = np.ceil(n_samples/batch_size).astype(np.int64)\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "        \n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "            total_loss += loss\n",
    "            \n",
    "        total_loss /= n_samples\n",
    "        val_loss, acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        \n",
    "        train_loss_history2.append(total_loss) #リストにappend\n",
    "        val_loss_history2.append(val_loss)\n",
    "        \n",
    "        print('#'*35)\n",
    "        print('### Epoch %i'%(epoch+1))\n",
    "        print('#'*35)\n",
    "        print(\"loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}\".format(total_loss, val_loss, acc))\n",
    "        print()\n",
    "        \n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "\n",
    "plt.plot(np.arange(num_epochs), train_loss_history2, label=\"train_loss\")\n",
    "plt.plot(np.arange(num_epochs), val_loss_history2, label=\"val_loss\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
